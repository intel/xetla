<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "https://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" lang="en-US">
<head>
<meta http-equiv="Content-Type" content="text/xhtml;charset=UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=11"/>
<meta name="generator" content="Doxygen 1.9.7"/>
<meta name="viewport" content="width=device-width, initial-scale=1"/>
<title>XeTLA: include/experimental/group/fused_op/layer_norm_fused_op_bwd_xe.hpp Source File</title>
<link href="tabs.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="jquery.js"></script>
<script type="text/javascript" src="dynsections.js"></script>
<link href="navtree.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="resize.js"></script>
<script type="text/javascript" src="navtreedata.js"></script>
<script type="text/javascript" src="navtree.js"></script>
<link href="search/search.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="search/searchdata.js"></script>
<script type="text/javascript" src="search/search.js"></script>
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:d3d9a9a6595521f9666a5e94cc830dab83b65699&amp;dn=expat.txt MIT */
  $(document).ready(function() { init_search(); });
/* @license-end */
</script>
<script type="text/x-mathjax-config">
MathJax.Hub.Config({
  extensions: ["tex2jax.js"],
  jax: ["input/TeX","output/HTML-CSS"],
});
</script>
<script type="text/javascript" async="async" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js"></script>
<link href="doxygen.css" rel="stylesheet" type="text/css" />
</head>
<body>
<div id="top"><!-- do not remove this div, it is closed by doxygen! -->
<div id="titlearea">
<table cellspacing="0" cellpadding="0">
 <tbody>
 <tr id="projectrow">
  <td id="projectalign">
   <div id="projectname">XeTLA<span id="projectnumber">&#160;v0.3.6</span>
   </div>
   <div id="projectbrief">IntelÂ® Xe Templates for Linear Algebra - API Definition Document</div>
  </td>
    <td>        <div id="MSearchBox" class="MSearchBoxInactive">
        <span class="left">
          <span id="MSearchSelect"                onmouseover="return searchBox.OnSearchSelectShow()"                onmouseout="return searchBox.OnSearchSelectHide()">&#160;</span>
          <input type="text" id="MSearchField" value="" placeholder="Search" accesskey="S"
               onfocus="searchBox.OnSearchFieldFocus(true)" 
               onblur="searchBox.OnSearchFieldFocus(false)" 
               onkeyup="searchBox.OnSearchFieldChange(event)"/>
          </span><span class="right">
            <a id="MSearchClose" href="javascript:searchBox.CloseResultsWindow()"><img id="MSearchCloseImg" border="0" src="search/close.svg" alt=""/></a>
          </span>
        </div>
</td>
 </tr>
 </tbody>
</table>
</div>
<!-- end header part -->
<!-- Generated by Doxygen 1.9.7 -->
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:d3d9a9a6595521f9666a5e94cc830dab83b65699&amp;dn=expat.txt MIT */
var searchBox = new SearchBox("searchBox", "search/",'.html');
/* @license-end */
</script>
</div><!-- top -->
<div id="side-nav" class="ui-resizable side-nav-resizable">
  <div id="nav-tree">
    <div id="nav-tree-contents">
      <div id="nav-sync" class="sync"></div>
    </div>
  </div>
  <div id="splitbar" style="-moz-user-select:none;" 
       class="ui-resizable-handle">
  </div>
</div>
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:d3d9a9a6595521f9666a5e94cc830dab83b65699&amp;dn=expat.txt MIT */
$(document).ready(function(){initNavTree('layer__norm__fused__op__bwd__xe_8hpp_source.html',''); initResizable(); });
/* @license-end */
</script>
<div id="doc-content">
<!-- window showing the filter options -->
<div id="MSearchSelectWindow"
     onmouseover="return searchBox.OnSearchSelectShow()"
     onmouseout="return searchBox.OnSearchSelectHide()"
     onkeydown="return searchBox.OnSearchSelectKey(event)">
</div>

<!-- iframe showing the search results (closed by default) -->
<div id="MSearchResultsWindow">
<div id="MSearchResults">
<div class="SRPage">
<div id="SRIndex">
<div id="SRResults"></div>
<div class="SRStatus" id="Loading">Loading...</div>
<div class="SRStatus" id="Searching">Searching...</div>
<div class="SRStatus" id="NoMatches">No Matches</div>
</div>
</div>
</div>
</div>

<div class="header">
  <div class="headertitle"><div class="title">layer_norm_fused_op_bwd_xe.hpp</div></div>
</div><!--header-->
<div class="contents">
<a href="layer__norm__fused__op__bwd__xe_8hpp.html">Go to the documentation of this file.</a><div class="fragment"><div class="line"><a id="l00001" name="l00001"></a><span class="lineno">    1</span><span class="comment">/*******************************************************************************</span></div>
<div class="line"><a id="l00002" name="l00002"></a><span class="lineno">    2</span><span class="comment">* Copyright (c) 2022-2023 Intel Corporation</span></div>
<div class="line"><a id="l00003" name="l00003"></a><span class="lineno">    3</span><span class="comment">*</span></div>
<div class="line"><a id="l00004" name="l00004"></a><span class="lineno">    4</span><span class="comment">* Licensed under the Apache License, Version 2.0 (the &quot;License&quot;);</span></div>
<div class="line"><a id="l00005" name="l00005"></a><span class="lineno">    5</span><span class="comment">* you may not use this file except in compliance with the License.</span></div>
<div class="line"><a id="l00006" name="l00006"></a><span class="lineno">    6</span><span class="comment">* You may obtain a copy of the License at</span></div>
<div class="line"><a id="l00007" name="l00007"></a><span class="lineno">    7</span><span class="comment">*</span></div>
<div class="line"><a id="l00008" name="l00008"></a><span class="lineno">    8</span><span class="comment">*     http://www.apache.org/licenses/LICENSE-2.0</span></div>
<div class="line"><a id="l00009" name="l00009"></a><span class="lineno">    9</span><span class="comment">*</span></div>
<div class="line"><a id="l00010" name="l00010"></a><span class="lineno">   10</span><span class="comment">* Unless required by applicable law or agreed to in writing, software</span></div>
<div class="line"><a id="l00011" name="l00011"></a><span class="lineno">   11</span><span class="comment">* distributed under the License is distributed on an &quot;AS IS&quot; BASIS,</span></div>
<div class="line"><a id="l00012" name="l00012"></a><span class="lineno">   12</span><span class="comment">* WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.</span></div>
<div class="line"><a id="l00013" name="l00013"></a><span class="lineno">   13</span><span class="comment">* See the License for the specific language governing permissions and</span></div>
<div class="line"><a id="l00014" name="l00014"></a><span class="lineno">   14</span><span class="comment">* limitations under the License.</span></div>
<div class="line"><a id="l00015" name="l00015"></a><span class="lineno">   15</span><span class="comment">*******************************************************************************/</span></div>
<div class="line"><a id="l00016" name="l00016"></a><span class="lineno">   16</span> </div>
<div class="line"><a id="l00019" name="l00019"></a><span class="lineno">   19</span> </div>
<div class="line"><a id="l00020" name="l00020"></a><span class="lineno">   20</span><span class="preprocessor">#pragma once</span></div>
<div class="line"><a id="l00021" name="l00021"></a><span class="lineno">   21</span> </div>
<div class="line"><a id="l00022" name="l00022"></a><span class="lineno">   22</span><span class="preprocessor">#include &quot;<a class="code" href="layer__norm__fused__op__api_8hpp.html">experimental/group/fused_op/layer_norm_fused_op_api.hpp</a>&quot;</span></div>
<div class="line"><a id="l00023" name="l00023"></a><span class="lineno">   23</span> </div>
<div class="line"><a id="l00024" name="l00024"></a><span class="lineno">   24</span><span class="keyword">namespace </span><a class="code hl_namespace" href="namespacegpu_1_1xetla_1_1group.html">gpu::xetla::group</a> {</div>
<div class="line"><a id="l00025" name="l00025"></a><span class="lineno">   25</span> </div>
<div class="line"><a id="l00031" name="l00031"></a><span class="lineno">   31</span><span class="keyword">template</span> &lt;<span class="keyword">typename</span> dtype_in, <span class="keyword">typename</span> dtype_out, <span class="keyword">typename</span> dtype_acc&gt;</div>
<div class="line"><a id="l00032" name="l00032"></a><span class="lineno"><a class="line" href="structgpu_1_1xetla_1_1group_1_1ln__bwd__fused__op__arguments__t.html">   32</a></span><span class="keyword">struct </span><a class="code hl_struct" href="structgpu_1_1xetla_1_1group_1_1ln__bwd__fused__op__arguments__t.html">ln_bwd_fused_op_arguments_t</a> {</div>
<div class="line"><a id="l00033" name="l00033"></a><span class="lineno"><a class="line" href="structgpu_1_1xetla_1_1group_1_1ln__bwd__fused__op__arguments__t.html#a07f0aac4809adc196e41750ded851a6f">   33</a></span>    dtype_acc *<a class="code hl_variable" href="structgpu_1_1xetla_1_1group_1_1ln__bwd__fused__op__arguments__t.html#a07f0aac4809adc196e41750ded851a6f">dbias_acc_ptr</a>;</div>
<div class="line"><a id="l00034" name="l00034"></a><span class="lineno"><a class="line" href="structgpu_1_1xetla_1_1group_1_1ln__bwd__fused__op__arguments__t.html#a2083f0ac3d8eee8ebcfe0d4df2c9b550">   34</a></span>    dtype_out *<a class="code hl_variable" href="structgpu_1_1xetla_1_1group_1_1ln__bwd__fused__op__arguments__t.html#a2083f0ac3d8eee8ebcfe0d4df2c9b550">dx_resAdd_ptr</a>;</div>
<div class="line"><a id="l00035" name="l00035"></a><span class="lineno"><a class="line" href="structgpu_1_1xetla_1_1group_1_1ln__bwd__fused__op__arguments__t.html#aca4e27dedde6f8ecd2aa0462c147344c">   35</a></span>    dtype_in *<a class="code hl_variable" href="structgpu_1_1xetla_1_1group_1_1ln__bwd__fused__op__arguments__t.html#aca4e27dedde6f8ecd2aa0462c147344c">gradAdd_ptr</a>;</div>
<div class="line"><a id="l00036" name="l00036"></a><span class="lineno"><a class="line" href="structgpu_1_1xetla_1_1group_1_1ln__bwd__fused__op__arguments__t.html#a96bc53f94fb970b26468b219769c0968">   36</a></span>    uint8_t *<a class="code hl_variable" href="structgpu_1_1xetla_1_1group_1_1ln__bwd__fused__op__arguments__t.html#a96bc53f94fb970b26468b219769c0968">mask_ptr</a>;</div>
<div class="line"><a id="l00037" name="l00037"></a><span class="lineno"><a class="line" href="structgpu_1_1xetla_1_1group_1_1ln__bwd__fused__op__arguments__t.html#a2bbf0067cd8d0c85039237d7c505c5d6">   37</a></span>    uint32_t <a class="code hl_variable" href="structgpu_1_1xetla_1_1group_1_1ln__bwd__fused__op__arguments__t.html#a2bbf0067cd8d0c85039237d7c505c5d6">matrix_m</a>;</div>
<div class="line"><a id="l00038" name="l00038"></a><span class="lineno"><a class="line" href="structgpu_1_1xetla_1_1group_1_1ln__bwd__fused__op__arguments__t.html#a5ca6fd69a759b2b68a6f1e047a4486fa">   38</a></span>    uint32_t <a class="code hl_variable" href="structgpu_1_1xetla_1_1group_1_1ln__bwd__fused__op__arguments__t.html#a5ca6fd69a759b2b68a6f1e047a4486fa">matrix_n</a>;</div>
<div class="line"><a id="l00039" name="l00039"></a><span class="lineno"><a class="line" href="structgpu_1_1xetla_1_1group_1_1ln__bwd__fused__op__arguments__t.html#ac624f186f20fe9a5689e1328ab5693d0">   39</a></span>    uint32_t <a class="code hl_variable" href="structgpu_1_1xetla_1_1group_1_1ln__bwd__fused__op__arguments__t.html#ac624f186f20fe9a5689e1328ab5693d0">mat_ld</a>;</div>
<div class="line"><a id="l00040" name="l00040"></a><span class="lineno"><a class="line" href="structgpu_1_1xetla_1_1group_1_1ln__bwd__fused__op__arguments__t.html#a378369421fe42c7b51b5f9a9e833e916">   40</a></span>    uint32_t <a class="code hl_variable" href="structgpu_1_1xetla_1_1group_1_1ln__bwd__fused__op__arguments__t.html#a378369421fe42c7b51b5f9a9e833e916">mask_ld</a>;</div>
<div class="line"><a id="l00041" name="l00041"></a><span class="lineno">   41</span>    <span class="comment">// dropout_scale_inv =  (1-dropout_prob)</span></div>
<div class="line"><a id="l00042" name="l00042"></a><span class="lineno"><a class="line" href="structgpu_1_1xetla_1_1group_1_1ln__bwd__fused__op__arguments__t.html#ada068c26ced84797f9772fe202d746f0">   42</a></span>    <span class="keywordtype">float</span> <a class="code hl_variable" href="structgpu_1_1xetla_1_1group_1_1ln__bwd__fused__op__arguments__t.html#ada068c26ced84797f9772fe202d746f0">dropout_prob</a>;</div>
<div class="line"><a id="l00043" name="l00043"></a><span class="lineno"><a class="line" href="structgpu_1_1xetla_1_1group_1_1ln__bwd__fused__op__arguments__t.html#a70a67b387d3dd8dfe8fa33ae09716dd0">   43</a></span>    <span class="keywordtype">float</span> <a class="code hl_variable" href="structgpu_1_1xetla_1_1group_1_1ln__bwd__fused__op__arguments__t.html#a70a67b387d3dd8dfe8fa33ae09716dd0">dropout_scale_inv</a>;</div>
<div class="line"><a id="l00044" name="l00044"></a><span class="lineno">   44</span>};</div>
<div class="line"><a id="l00045" name="l00045"></a><span class="lineno">   45</span> </div>
<div class="line"><a id="l00053" name="l00053"></a><span class="lineno">   53</span><span class="keyword">template</span> &lt;<a class="code hl_enumeration" href="namespacegpu_1_1xetla.html#aacf5f0d7a8241d58320b4a95e0f7592b">ln_bwd_fused_kind</a> ln_fused_op_kind_, <span class="keyword">typename</span> dtype_in_,</div>
<div class="line"><a id="l00054" name="l00054"></a><span class="lineno">   54</span>        <span class="keyword">typename</span> dtype_out_, <span class="keyword">typename</span> dtype_acc_, <span class="keyword">typename</span> layer_norm_attr_&gt;</div>
<div class="line"><a id="l00055" name="l00055"></a><span class="lineno"><a class="line" href="structgpu_1_1xetla_1_1group_1_1ln__bwd__fused__op__t_3_01ln__fused__op__kind___00_01dtype__in___b59b7c4dd4da8b28b7c493261d10e46c.html">   55</a></span><span class="keyword">struct </span><a class="code hl_struct" href="structgpu_1_1xetla_1_1group_1_1ln__bwd__fused__op__t.html">ln_bwd_fused_op_t</a>&lt;ln_fused_op_kind_, dtype_in_, dtype_out_, dtype_acc_,</div>
<div class="line"><a id="l00056" name="l00056"></a><span class="lineno">   56</span>        layer_norm_attr_, <a class="code hl_enumeration" href="namespacegpu_1_1xetla.html#aa5a2713edb27d6fed88a3c61673556f1">gpu_arch</a>::<a class="code hl_enumvalue" href="namespacegpu_1_1xetla.html#aa5a2713edb27d6fed88a3c61673556f1a8fde9df1bf2567b76160d1beedca3130">Xe</a>&gt; {</div>
<div class="line"><a id="l00057" name="l00057"></a><span class="lineno"><a class="line" href="structgpu_1_1xetla_1_1group_1_1ln__bwd__fused__op__t_3_01ln__fused__op__kind___00_01dtype__in___b59b7c4dd4da8b28b7c493261d10e46c.html#af5e85a9e1b56a30964ea242d0dd2dc45">   57</a></span>    <span class="keyword">static</span> <span class="keyword">constexpr</span> <a class="code hl_enumeration" href="namespacegpu_1_1xetla.html#aacf5f0d7a8241d58320b4a95e0f7592b">ln_bwd_fused_kind</a> fused_op_kind = ln_fused_op_kind_;</div>
<div class="line"><a id="l00058" name="l00058"></a><span class="lineno"><a class="line" href="structgpu_1_1xetla_1_1group_1_1ln__bwd__fused__op__t_3_01ln__fused__op__kind___00_01dtype__in___b59b7c4dd4da8b28b7c493261d10e46c.html#a4cc029084f87bccafbf897bdb7b47186">   58</a></span>    <span class="keyword">using </span><a class="code hl_typedef" href="structgpu_1_1xetla_1_1group_1_1ln__bwd__fused__op__t_3_01ln__fused__op__kind___00_01dtype__in___b59b7c4dd4da8b28b7c493261d10e46c.html#a4cc029084f87bccafbf897bdb7b47186">dtype_acc</a> = dtype_acc_;</div>
<div class="line"><a id="l00059" name="l00059"></a><span class="lineno"><a class="line" href="structgpu_1_1xetla_1_1group_1_1ln__bwd__fused__op__t_3_01ln__fused__op__kind___00_01dtype__in___b59b7c4dd4da8b28b7c493261d10e46c.html#adaafd4f82e71bf4fd958c543a336f77c">   59</a></span>    <span class="keyword">using </span><a class="code hl_typedef" href="structgpu_1_1xetla_1_1group_1_1ln__bwd__fused__op__t_3_01ln__fused__op__kind___00_01dtype__in___b59b7c4dd4da8b28b7c493261d10e46c.html#adaafd4f82e71bf4fd958c543a336f77c">dtype_in</a> = dtype_in_;</div>
<div class="line"><a id="l00060" name="l00060"></a><span class="lineno"><a class="line" href="structgpu_1_1xetla_1_1group_1_1ln__bwd__fused__op__t_3_01ln__fused__op__kind___00_01dtype__in___b59b7c4dd4da8b28b7c493261d10e46c.html#a3dc25d7c5cb27ae71b87487f439a0819">   60</a></span>    <span class="keyword">using </span><a class="code hl_typedef" href="structgpu_1_1xetla_1_1group_1_1ln__bwd__fused__op__t_3_01ln__fused__op__kind___00_01dtype__in___b59b7c4dd4da8b28b7c493261d10e46c.html#a3dc25d7c5cb27ae71b87487f439a0819">dtype_out</a> = dtype_out_;</div>
<div class="line"><a id="l00061" name="l00061"></a><span class="lineno"><a class="line" href="structgpu_1_1xetla_1_1group_1_1ln__bwd__fused__op__t_3_01ln__fused__op__kind___00_01dtype__in___b59b7c4dd4da8b28b7c493261d10e46c.html#a320d7e318df13eeb46f233c28ff45c00">   61</a></span>    <span class="keyword">using </span><a class="code hl_struct" href="structgpu_1_1xetla_1_1group_1_1ln__bwd__fused__op__arguments__t.html">arguments_t</a></div>
<div class="line"><a id="l00062" name="l00062"></a><span class="lineno">   62</span>            = <a class="code hl_struct" href="structgpu_1_1xetla_1_1group_1_1ln__bwd__fused__op__arguments__t.html">ln_bwd_fused_op_arguments_t&lt;dtype_in, dtype_out, dtype_acc&gt;</a>;</div>
<div class="line"><a id="l00063" name="l00063"></a><span class="lineno"><a class="line" href="structgpu_1_1xetla_1_1group_1_1ln__bwd__fused__op__t_3_01ln__fused__op__kind___00_01dtype__in___b59b7c4dd4da8b28b7c493261d10e46c.html#a0d6b49c178bb0f0ce39a9b01ce5167bf">   63</a></span>    <span class="keyword">static</span> <span class="keyword">constexpr</span> uint32_t wg_tile_m = layer_norm_attr_::wg_tile_m;</div>
<div class="line"><a id="l00064" name="l00064"></a><span class="lineno"><a class="line" href="structgpu_1_1xetla_1_1group_1_1ln__bwd__fused__op__t_3_01ln__fused__op__kind___00_01dtype__in___b59b7c4dd4da8b28b7c493261d10e46c.html#a4dddb931025364d1b549742199dfb02f">   64</a></span>    <span class="keyword">static</span> <span class="keyword">constexpr</span> uint32_t wg_tile_n = layer_norm_attr_::wg_tile_n;</div>
<div class="line"><a id="l00065" name="l00065"></a><span class="lineno"><a class="line" href="structgpu_1_1xetla_1_1group_1_1ln__bwd__fused__op__t_3_01ln__fused__op__kind___00_01dtype__in___b59b7c4dd4da8b28b7c493261d10e46c.html#a5444dd7b3368a63b60a5e7a705cf9a4d">   65</a></span>    <span class="keyword">static</span> <span class="keyword">constexpr</span> uint32_t sg_tile_m = layer_norm_attr_::sg_tile_m;</div>
<div class="line"><a id="l00066" name="l00066"></a><span class="lineno"><a class="line" href="structgpu_1_1xetla_1_1group_1_1ln__bwd__fused__op__t_3_01ln__fused__op__kind___00_01dtype__in___b59b7c4dd4da8b28b7c493261d10e46c.html#a5040c707d4a14c1a13f4917e060cb336">   66</a></span>    <span class="keyword">static</span> <span class="keyword">constexpr</span> uint32_t sg_tile_n = layer_norm_attr_::sg_tile_n;</div>
<div class="line"><a id="l00067" name="l00067"></a><span class="lineno"><a class="line" href="structgpu_1_1xetla_1_1group_1_1ln__bwd__fused__op__t_3_01ln__fused__op__kind___00_01dtype__in___b59b7c4dd4da8b28b7c493261d10e46c.html#ad822a559e5d9db20b1910497d322e266">   67</a></span>    <span class="keyword">static</span> <span class="keyword">constexpr</span> uint32_t wg_num_m = layer_norm_attr_::wg_num_m;</div>
<div class="line"><a id="l00068" name="l00068"></a><span class="lineno"><a class="line" href="structgpu_1_1xetla_1_1group_1_1ln__bwd__fused__op__t_3_01ln__fused__op__kind___00_01dtype__in___b59b7c4dd4da8b28b7c493261d10e46c.html#a5588c663f9ed79bf5f72414ba0db0fe4">   68</a></span>    <span class="keyword">static</span> <span class="keyword">constexpr</span> uint32_t wg_num_n = layer_norm_attr_::wg_num_n;</div>
<div class="line"><a id="l00069" name="l00069"></a><span class="lineno">   69</span> </div>
<div class="line"><a id="l00078" name="l00078"></a><span class="lineno"><a class="line" href="structgpu_1_1xetla_1_1group_1_1ln__bwd__fused__op__t_3_01ln__fused__op__kind___00_01dtype__in___b59b7c4dd4da8b28b7c493261d10e46c.html#abb2181bf89db8eb4f5db03d72f38a33e">   78</a></span>    <a class="code hl_define" href="common_2core_2common_8hpp.html#a9ed53999886ec13b86a4fe2e0fc16765">__XETLA_API</a> <span class="keywordtype">void</span> <a class="code hl_function" href="structgpu_1_1xetla_1_1group_1_1ln__bwd__fused__op__t_3_01ln__fused__op__kind___00_01dtype__in___b59b7c4dd4da8b28b7c493261d10e46c.html#abb2181bf89db8eb4f5db03d72f38a33e">init</a>(<a class="code hl_struct" href="structgpu_1_1xetla_1_1group_1_1ln__bwd__fused__op__arguments__t.html">arguments_t</a> *args, uint32_t wg_idx, uint32_t wg_idy,</div>
<div class="line"><a id="l00079" name="l00079"></a><span class="lineno">   79</span>            uint32_t sg_idx, uint32_t sg_idy) {}</div>
<div class="line"><a id="l00080" name="l00080"></a><span class="lineno">   80</span> </div>
<div class="line"><a id="l00085" name="l00085"></a><span class="lineno"><a class="line" href="structgpu_1_1xetla_1_1group_1_1ln__bwd__fused__op__t_3_01ln__fused__op__kind___00_01dtype__in___b59b7c4dd4da8b28b7c493261d10e46c.html#acc4b5834c43d8fea62f2f48f9fab1481">   85</a></span>    <a class="code hl_define" href="common_2core_2common_8hpp.html#a9ed53999886ec13b86a4fe2e0fc16765">__XETLA_API</a> <a class="code hl_typedef" href="group__xetla__core__base__types.html#ga8cf5d016d24c8870706e20c376287e04">xetla_vector&lt;dtype_acc, sg_tile_n&gt;</a> <a class="code hl_function" href="structgpu_1_1xetla_1_1group_1_1ln__bwd__fused__op__t_3_01ln__fused__op__kind___00_01dtype__in___b59b7c4dd4da8b28b7c493261d10e46c.html#acc4b5834c43d8fea62f2f48f9fab1481">pre_op</a>(</div>
<div class="line"><a id="l00086" name="l00086"></a><span class="lineno">   86</span>            <a class="code hl_typedef" href="group__xetla__core__base__types.html#ga8cf5d016d24c8870706e20c376287e04">xetla_vector&lt;dtype_acc, sg_tile_n&gt;</a> input) {</div>
<div class="line"><a id="l00087" name="l00087"></a><span class="lineno">   87</span>        <span class="keywordflow">return</span> input;</div>
<div class="line"><a id="l00088" name="l00088"></a><span class="lineno">   88</span>    }</div>
<div class="line"><a id="l00089" name="l00089"></a><span class="lineno">   89</span> </div>
<div class="line"><a id="l00094" name="l00094"></a><span class="lineno"><a class="line" href="structgpu_1_1xetla_1_1group_1_1ln__bwd__fused__op__t_3_01ln__fused__op__kind___00_01dtype__in___b59b7c4dd4da8b28b7c493261d10e46c.html#a423fd986fc4426e9715af652e2cdae04">   94</a></span>    <a class="code hl_define" href="common_2core_2common_8hpp.html#a9ed53999886ec13b86a4fe2e0fc16765">__XETLA_API</a> <a class="code hl_typedef" href="group__xetla__core__base__types.html#ga8cf5d016d24c8870706e20c376287e04">xetla_vector&lt;dtype_acc, sg_tile_n&gt;</a> <a class="code hl_function" href="structgpu_1_1xetla_1_1group_1_1ln__bwd__fused__op__t_3_01ln__fused__op__kind___00_01dtype__in___b59b7c4dd4da8b28b7c493261d10e46c.html#a423fd986fc4426e9715af652e2cdae04">post_op</a>(</div>
<div class="line"><a id="l00095" name="l00095"></a><span class="lineno">   95</span>            <a class="code hl_typedef" href="group__xetla__core__base__types.html#ga8cf5d016d24c8870706e20c376287e04">xetla_vector&lt;dtype_acc, sg_tile_n&gt;</a> input) {</div>
<div class="line"><a id="l00096" name="l00096"></a><span class="lineno">   96</span>        <span class="keywordflow">return</span> input;</div>
<div class="line"><a id="l00097" name="l00097"></a><span class="lineno">   97</span>    }</div>
<div class="line"><a id="l00098" name="l00098"></a><span class="lineno">   98</span> </div>
<div class="line"><a id="l00104" name="l00104"></a><span class="lineno">  104</span>    <span class="keyword">template</span> &lt;<span class="keyword">typename</span> reduce_t&gt;</div>
<div class="line"><a id="l00105" name="l00105"></a><span class="lineno"><a class="line" href="structgpu_1_1xetla_1_1group_1_1ln__bwd__fused__op__t_3_01ln__fused__op__kind___00_01dtype__in___b59b7c4dd4da8b28b7c493261d10e46c.html#ad76e6922044a1343887b9bcca414ecbb">  105</a></span>    <a class="code hl_define" href="common_2core_2common_8hpp.html#a9ed53999886ec13b86a4fe2e0fc16765">__XETLA_API</a> <span class="keywordtype">void</span> <a class="code hl_function" href="structgpu_1_1xetla_1_1group_1_1ln__bwd__fused__op__t_3_01ln__fused__op__kind___00_01dtype__in___b59b7c4dd4da8b28b7c493261d10e46c.html#ad76e6922044a1343887b9bcca414ecbb">final_op</a>(reduce_t &amp;ln_group_row_reduce) {}</div>
<div class="line"><a id="l00106" name="l00106"></a><span class="lineno">  106</span>};</div>
<div class="line"><a id="l00107" name="l00107"></a><span class="lineno">  107</span> </div>
<div class="line"><a id="l00114" name="l00114"></a><span class="lineno">  114</span><span class="keyword">template</span> &lt;<span class="keyword">typename</span> dtype_in_, <span class="keyword">typename</span> dtype_out_, <span class="keyword">typename</span> dtype_acc_,</div>
<div class="line"><a id="l00115" name="l00115"></a><span class="lineno">  115</span>        <span class="keyword">typename</span> layer_norm_attr_&gt;</div>
<div class="line"><a id="l00116" name="l00116"></a><span class="lineno"><a class="line" href="structgpu_1_1xetla_1_1group_1_1ln__bwd__fused__op__t_3_01ln__bwd__fused__kind_1_1bias__dropout__cb4d0474e0a28c140fa444d1da09a494.html">  116</a></span><span class="keyword">struct </span><a class="code hl_struct" href="structgpu_1_1xetla_1_1group_1_1ln__bwd__fused__op__t.html">ln_bwd_fused_op_t</a>&lt;<a class="code hl_enumeration" href="namespacegpu_1_1xetla.html#aacf5f0d7a8241d58320b4a95e0f7592b">ln_bwd_fused_kind</a>::<a class="code hl_enumvalue" href="namespacegpu_1_1xetla.html#a71633e89354f0f1d0badcd0d90dea7eca50054c633c718e5b1c128c96ba1853ee">bias_dropout_resAdd_ln</a>, dtype_in_,</div>
<div class="line"><a id="l00117" name="l00117"></a><span class="lineno">  117</span>        dtype_out_, dtype_acc_, layer_norm_attr_, <a class="code hl_enumvalue" href="namespacegpu_1_1xetla.html#aa5a2713edb27d6fed88a3c61673556f1a8fde9df1bf2567b76160d1beedca3130">gpu_arch::Xe</a>&gt; {</div>
<div class="line"><a id="l00118" name="l00118"></a><span class="lineno"><a class="line" href="structgpu_1_1xetla_1_1group_1_1ln__bwd__fused__op__t_3_01ln__bwd__fused__kind_1_1bias__dropout__cb4d0474e0a28c140fa444d1da09a494.html#ae44c49d838daea0fdf9b808597f42426">  118</a></span>    <span class="keyword">static</span> <span class="keyword">constexpr</span> <a class="code hl_enumeration" href="namespacegpu_1_1xetla.html#aacf5f0d7a8241d58320b4a95e0f7592b">ln_bwd_fused_kind</a> fused_op_kind</div>
<div class="line"><a id="l00119" name="l00119"></a><span class="lineno">  119</span>            = <a class="code hl_enumvalue" href="namespacegpu_1_1xetla.html#aacf5f0d7a8241d58320b4a95e0f7592ba50054c633c718e5b1c128c96ba1853ee">ln_bwd_fused_kind::bias_dropout_resAdd_ln</a>;</div>
<div class="line"><a id="l00120" name="l00120"></a><span class="lineno"><a class="line" href="structgpu_1_1xetla_1_1group_1_1ln__bwd__fused__op__t_3_01ln__bwd__fused__kind_1_1bias__dropout__cb4d0474e0a28c140fa444d1da09a494.html#aa415f946f85a23532905c9e04899d27e">  120</a></span>    <span class="keyword">using </span><a class="code hl_typedef" href="structgpu_1_1xetla_1_1group_1_1ln__bwd__fused__op__t_3_01ln__bwd__fused__kind_1_1bias__dropout__cb4d0474e0a28c140fa444d1da09a494.html#aa415f946f85a23532905c9e04899d27e">dtype_acc</a> = dtype_acc_;</div>
<div class="line"><a id="l00121" name="l00121"></a><span class="lineno"><a class="line" href="structgpu_1_1xetla_1_1group_1_1ln__bwd__fused__op__t_3_01ln__bwd__fused__kind_1_1bias__dropout__cb4d0474e0a28c140fa444d1da09a494.html#a5b396e89e1a4518120cc347db1150850">  121</a></span>    <span class="keyword">using </span><a class="code hl_typedef" href="structgpu_1_1xetla_1_1group_1_1ln__bwd__fused__op__t_3_01ln__bwd__fused__kind_1_1bias__dropout__cb4d0474e0a28c140fa444d1da09a494.html#a5b396e89e1a4518120cc347db1150850">dtype_in</a> = dtype_in_;</div>
<div class="line"><a id="l00122" name="l00122"></a><span class="lineno"><a class="line" href="structgpu_1_1xetla_1_1group_1_1ln__bwd__fused__op__t_3_01ln__bwd__fused__kind_1_1bias__dropout__cb4d0474e0a28c140fa444d1da09a494.html#afc4fceff36cc8b08fa046678f7849cd3">  122</a></span>    <span class="keyword">using </span><a class="code hl_typedef" href="structgpu_1_1xetla_1_1group_1_1ln__bwd__fused__op__t_3_01ln__bwd__fused__kind_1_1bias__dropout__cb4d0474e0a28c140fa444d1da09a494.html#afc4fceff36cc8b08fa046678f7849cd3">dtype_out</a> = dtype_out_;</div>
<div class="line"><a id="l00123" name="l00123"></a><span class="lineno"><a class="line" href="structgpu_1_1xetla_1_1group_1_1ln__bwd__fused__op__t_3_01ln__bwd__fused__kind_1_1bias__dropout__cb4d0474e0a28c140fa444d1da09a494.html#a283bf429132072c6b0bae5ba92f4ebdf">  123</a></span>    <span class="keyword">using </span><a class="code hl_typedef" href="structgpu_1_1xetla_1_1group_1_1ln__bwd__fused__op__t_3_01ln__bwd__fused__kind_1_1bias__dropout__cb4d0474e0a28c140fa444d1da09a494.html#a283bf429132072c6b0bae5ba92f4ebdf">dtype_mask</a> = uint8_t;</div>
<div class="line"><a id="l00124" name="l00124"></a><span class="lineno"><a class="line" href="structgpu_1_1xetla_1_1group_1_1ln__bwd__fused__op__t_3_01ln__bwd__fused__kind_1_1bias__dropout__cb4d0474e0a28c140fa444d1da09a494.html#a29952e902134254bb0e8a993eaa8cb55">  124</a></span>    <span class="keyword">using </span><a class="code hl_struct" href="structgpu_1_1xetla_1_1group_1_1ln__bwd__fused__op__arguments__t.html">arguments_t</a></div>
<div class="line"><a id="l00125" name="l00125"></a><span class="lineno">  125</span>            = <a class="code hl_struct" href="structgpu_1_1xetla_1_1group_1_1ln__bwd__fused__op__arguments__t.html">ln_bwd_fused_op_arguments_t&lt;dtype_in, dtype_out, dtype_acc&gt;</a>;</div>
<div class="line"><a id="l00126" name="l00126"></a><span class="lineno"><a class="line" href="structgpu_1_1xetla_1_1group_1_1ln__bwd__fused__op__t_3_01ln__bwd__fused__kind_1_1bias__dropout__cb4d0474e0a28c140fa444d1da09a494.html#a6e1d71772403e8e06f5110d17a3199d1">  126</a></span>    <span class="keyword">static</span> <span class="keyword">constexpr</span> uint32_t wg_tile_m = layer_norm_attr_::wg_tile_m;</div>
<div class="line"><a id="l00127" name="l00127"></a><span class="lineno"><a class="line" href="structgpu_1_1xetla_1_1group_1_1ln__bwd__fused__op__t_3_01ln__bwd__fused__kind_1_1bias__dropout__cb4d0474e0a28c140fa444d1da09a494.html#a501963f1bbb00f3c2e0521246b15cc55">  127</a></span>    <span class="keyword">static</span> <span class="keyword">constexpr</span> uint32_t wg_tile_n = layer_norm_attr_::wg_tile_n;</div>
<div class="line"><a id="l00128" name="l00128"></a><span class="lineno"><a class="line" href="structgpu_1_1xetla_1_1group_1_1ln__bwd__fused__op__t_3_01ln__bwd__fused__kind_1_1bias__dropout__cb4d0474e0a28c140fa444d1da09a494.html#a1779c914a6cdcb491cc1aa0cf7d33565">  128</a></span>    <span class="keyword">static</span> <span class="keyword">constexpr</span> uint32_t sg_tile_m = layer_norm_attr_::sg_tile_m;</div>
<div class="line"><a id="l00129" name="l00129"></a><span class="lineno"><a class="line" href="structgpu_1_1xetla_1_1group_1_1ln__bwd__fused__op__t_3_01ln__bwd__fused__kind_1_1bias__dropout__cb4d0474e0a28c140fa444d1da09a494.html#a33c9468dd9f6db70ea91800bdcfdbcaa">  129</a></span>    <span class="keyword">static</span> <span class="keyword">constexpr</span> uint32_t sg_tile_n = layer_norm_attr_::sg_tile_n;</div>
<div class="line"><a id="l00130" name="l00130"></a><span class="lineno"><a class="line" href="structgpu_1_1xetla_1_1group_1_1ln__bwd__fused__op__t_3_01ln__bwd__fused__kind_1_1bias__dropout__cb4d0474e0a28c140fa444d1da09a494.html#ad6e044a725fce46c9f946d6e941b62c2">  130</a></span>    <span class="keyword">static</span> <span class="keyword">constexpr</span> uint32_t wg_num_m = layer_norm_attr_::wg_num_m;</div>
<div class="line"><a id="l00131" name="l00131"></a><span class="lineno"><a class="line" href="structgpu_1_1xetla_1_1group_1_1ln__bwd__fused__op__t_3_01ln__bwd__fused__kind_1_1bias__dropout__cb4d0474e0a28c140fa444d1da09a494.html#a97c77d8d67718283e084484abd1f39f6">  131</a></span>    <span class="keyword">static</span> <span class="keyword">constexpr</span> uint32_t wg_num_n = layer_norm_attr_::wg_num_n;</div>
<div class="line"><a id="l00132" name="l00132"></a><span class="lineno">  132</span> </div>
<div class="line"><a id="l00133" name="l00133"></a><span class="lineno"><a class="line" href="structgpu_1_1xetla_1_1group_1_1ln__bwd__fused__op__t_3_01ln__bwd__fused__kind_1_1bias__dropout__cb4d0474e0a28c140fa444d1da09a494.html#aaf55fa157b24e9207e639b52649ff87f">  133</a></span>    <span class="keyword">static</span> <span class="keyword">constexpr</span> uint32_t wg_size_x</div>
<div class="line"><a id="l00134" name="l00134"></a><span class="lineno">  134</span>            = (wg_tile_n + sg_tile_n - 1) / sg_tile_n;</div>
<div class="line"><a id="l00135" name="l00135"></a><span class="lineno"><a class="line" href="structgpu_1_1xetla_1_1group_1_1ln__bwd__fused__op__t_3_01ln__bwd__fused__kind_1_1bias__dropout__cb4d0474e0a28c140fa444d1da09a494.html#a6514dc9d24c94935fb648ec68d1f0919">  135</a></span>    <span class="keyword">static</span> <span class="keyword">constexpr</span> uint32_t wg_size_y</div>
<div class="line"><a id="l00136" name="l00136"></a><span class="lineno">  136</span>            = (wg_tile_m + sg_tile_m - 1) / sg_tile_m;</div>
<div class="line"><a id="l00137" name="l00137"></a><span class="lineno">  137</span> </div>
<div class="line"><a id="l00138" name="l00138"></a><span class="lineno">  138</span>    <span class="keyword">static_assert</span>((sg_tile_n % (<span class="keyword">sizeof</span>(uint32_t) / <span class="keyword">sizeof</span>(<a class="code hl_typedef" href="structgpu_1_1xetla_1_1group_1_1ln__bwd__fused__op__t_3_01ln__bwd__fused__kind_1_1bias__dropout__cb4d0474e0a28c140fa444d1da09a494.html#a283bf429132072c6b0bae5ba92f4ebdf">dtype_mask</a>)) == 0),</div>
<div class="line"><a id="l00139" name="l00139"></a><span class="lineno">  139</span>            <span class="stringliteral">&quot;sg_tile_n need to be DW aligned&quot;</span>);</div>
<div class="line"><a id="l00140" name="l00140"></a><span class="lineno"><a class="line" href="structgpu_1_1xetla_1_1group_1_1ln__bwd__fused__op__t_3_01ln__bwd__fused__kind_1_1bias__dropout__cb4d0474e0a28c140fa444d1da09a494.html#a571d461c5e55b8bec450544943d6a736">  140</a></span>    <span class="keyword">using </span><a class="code hl_struct" href="structgpu_1_1xetla_1_1subgroup_1_1tile__desc__t.html">ln_bwd_tile_desc_t</a> = <a class="code hl_struct" href="structgpu_1_1xetla_1_1subgroup_1_1tile__desc__t.html">subgroup::tile_desc_t</a>&lt;sg_tile_n, 1, sg_tile_n, 1,</div>
<div class="line"><a id="l00141" name="l00141"></a><span class="lineno">  141</span>            <a class="code hl_enumvalue" href="namespacegpu_1_1xetla.html#a51137fd81d0d9d2156525a1e279432aaa78506882d645395a052df8b01a927395">reg_layout::tiled</a>&gt;;</div>
<div class="line"><a id="l00142" name="l00142"></a><span class="lineno"><a class="line" href="structgpu_1_1xetla_1_1group_1_1ln__bwd__fused__op__t_3_01ln__bwd__fused__kind_1_1bias__dropout__cb4d0474e0a28c140fa444d1da09a494.html#a6f8aec35b035a05c0ece8934690d588a">  142</a></span>    <span class="keyword">using </span><a class="code hl_class" href="structgpu_1_1xetla_1_1subgroup_1_1tile__t.html">dx_resAdd_out_t</a> = <a class="code hl_struct" href="structgpu_1_1xetla_1_1subgroup_1_1tile__t.html">subgroup::tile_t&lt;dtype_out, ln_bwd_tile_desc_t&gt;</a>;</div>
<div class="line"><a id="l00143" name="l00143"></a><span class="lineno"><a class="line" href="structgpu_1_1xetla_1_1group_1_1ln__bwd__fused__op__t_3_01ln__bwd__fused__kind_1_1bias__dropout__cb4d0474e0a28c140fa444d1da09a494.html#a71716a1c10a405d4fbb31bbe4a128216">  143</a></span>    <span class="keyword">using </span><a class="code hl_class" href="structgpu_1_1xetla_1_1subgroup_1_1mem__payload__t.html">dx_resAdd_out_payload_t</a> = <a class="code hl_struct" href="structgpu_1_1xetla_1_1subgroup_1_1mem__payload__t.html">subgroup::mem_payload_t</a>&lt;</div>
<div class="line"><a id="l00144" name="l00144"></a><span class="lineno">  144</span>            <a class="code hl_struct" href="structgpu_1_1xetla_1_1mem__desc__t.html">mem_desc_t&lt;dtype_out, mem_layout::row_major, mem_space::global&gt;</a>,</div>
<div class="line"><a id="l00145" name="l00145"></a><span class="lineno">  145</span>            <a class="code hl_struct" href="structgpu_1_1xetla_1_1subgroup_1_1tile__desc__t.html">ln_bwd_tile_desc_t</a>, <a class="code hl_enumvalue" href="namespacegpu_1_1xetla.html#aa8afe1d12e7777419fb6ea09534a0aa7a5baf9a1aba8e4b6fa44c20aafacc4233">msg_type::block_1d</a>, <a class="code hl_enumvalue" href="namespacegpu_1_1xetla.html#aa5a2713edb27d6fed88a3c61673556f1a8fde9df1bf2567b76160d1beedca3130">gpu_arch::Xe</a>&gt;;</div>
<div class="line"><a id="l00146" name="l00146"></a><span class="lineno"><a class="line" href="structgpu_1_1xetla_1_1group_1_1ln__bwd__fused__op__t_3_01ln__bwd__fused__kind_1_1bias__dropout__cb4d0474e0a28c140fa444d1da09a494.html#ac0175e5ec8dd147f0e0aaa137022ce62">  146</a></span>    <span class="keyword">using </span><a class="code hl_class" href="structgpu_1_1xetla_1_1subgroup_1_1tile__t.html">mask_in_t</a> = <a class="code hl_struct" href="structgpu_1_1xetla_1_1subgroup_1_1tile__t.html">subgroup::tile_t&lt;dtype_mask, ln_bwd_tile_desc_t&gt;</a>;</div>
<div class="line"><a id="l00147" name="l00147"></a><span class="lineno"><a class="line" href="structgpu_1_1xetla_1_1group_1_1ln__bwd__fused__op__t_3_01ln__bwd__fused__kind_1_1bias__dropout__cb4d0474e0a28c140fa444d1da09a494.html#aeea981244fb749c202d0b9ead6c00b5d">  147</a></span>    <span class="keyword">using </span><a class="code hl_class" href="structgpu_1_1xetla_1_1subgroup_1_1mem__payload__t.html">mask_in_payload_t</a> = <a class="code hl_struct" href="structgpu_1_1xetla_1_1subgroup_1_1mem__payload__t.html">subgroup::mem_payload_t</a>&lt;</div>
<div class="line"><a id="l00148" name="l00148"></a><span class="lineno">  148</span>            <a class="code hl_struct" href="structgpu_1_1xetla_1_1mem__desc__t.html">mem_desc_t&lt;dtype_mask, mem_layout::row_major, mem_space::global&gt;</a>,</div>
<div class="line"><a id="l00149" name="l00149"></a><span class="lineno">  149</span>            <a class="code hl_struct" href="structgpu_1_1xetla_1_1subgroup_1_1tile__desc__t.html">ln_bwd_tile_desc_t</a>, <a class="code hl_enumvalue" href="namespacegpu_1_1xetla.html#aa8afe1d12e7777419fb6ea09534a0aa7a5baf9a1aba8e4b6fa44c20aafacc4233">msg_type::block_1d</a>, <a class="code hl_enumvalue" href="namespacegpu_1_1xetla.html#aa5a2713edb27d6fed88a3c61673556f1a8fde9df1bf2567b76160d1beedca3130">gpu_arch::Xe</a>&gt;;</div>
<div class="line"><a id="l00150" name="l00150"></a><span class="lineno"><a class="line" href="structgpu_1_1xetla_1_1group_1_1ln__bwd__fused__op__t_3_01ln__bwd__fused__kind_1_1bias__dropout__cb4d0474e0a28c140fa444d1da09a494.html#a85c84e2078286888a96539a2fd766828">  150</a></span>    <a class="code hl_class" href="structgpu_1_1xetla_1_1subgroup_1_1tile__t.html">dx_resAdd_out_t</a> <a class="code hl_variable" href="structgpu_1_1xetla_1_1group_1_1ln__bwd__fused__op__t_3_01ln__bwd__fused__kind_1_1bias__dropout__cb4d0474e0a28c140fa444d1da09a494.html#a85c84e2078286888a96539a2fd766828">dx_resAdd_out</a>;</div>
<div class="line"><a id="l00151" name="l00151"></a><span class="lineno"><a class="line" href="structgpu_1_1xetla_1_1group_1_1ln__bwd__fused__op__t_3_01ln__bwd__fused__kind_1_1bias__dropout__cb4d0474e0a28c140fa444d1da09a494.html#a5e2f9acbb985391eb3de920e1b25446d">  151</a></span>    <a class="code hl_class" href="structgpu_1_1xetla_1_1subgroup_1_1mem__payload__t.html">dx_resAdd_out_payload_t</a> <a class="code hl_variable" href="structgpu_1_1xetla_1_1group_1_1ln__bwd__fused__op__t_3_01ln__bwd__fused__kind_1_1bias__dropout__cb4d0474e0a28c140fa444d1da09a494.html#a5e2f9acbb985391eb3de920e1b25446d">dx_resAdd_out_payload</a>;</div>
<div class="line"><a id="l00152" name="l00152"></a><span class="lineno"><a class="line" href="structgpu_1_1xetla_1_1group_1_1ln__bwd__fused__op__t_3_01ln__bwd__fused__kind_1_1bias__dropout__cb4d0474e0a28c140fa444d1da09a494.html#a32cfc1c564ac6f08944e6febd9723144">  152</a></span>    <a class="code hl_class" href="structgpu_1_1xetla_1_1subgroup_1_1tile__t.html">mask_in_t</a> <a class="code hl_variable" href="structgpu_1_1xetla_1_1group_1_1ln__bwd__fused__op__t_3_01ln__bwd__fused__kind_1_1bias__dropout__cb4d0474e0a28c140fa444d1da09a494.html#a32cfc1c564ac6f08944e6febd9723144">mask_in</a>;</div>
<div class="line"><a id="l00153" name="l00153"></a><span class="lineno"><a class="line" href="structgpu_1_1xetla_1_1group_1_1ln__bwd__fused__op__t_3_01ln__bwd__fused__kind_1_1bias__dropout__cb4d0474e0a28c140fa444d1da09a494.html#afa3aa816243af994b255f7db3dfe5ebf">  153</a></span>    <a class="code hl_class" href="structgpu_1_1xetla_1_1subgroup_1_1mem__payload__t.html">mask_in_payload_t</a> <a class="code hl_variable" href="structgpu_1_1xetla_1_1group_1_1ln__bwd__fused__op__t_3_01ln__bwd__fused__kind_1_1bias__dropout__cb4d0474e0a28c140fa444d1da09a494.html#afa3aa816243af994b255f7db3dfe5ebf">mask_in_payload</a>;</div>
<div class="line"><a id="l00154" name="l00154"></a><span class="lineno"><a class="line" href="structgpu_1_1xetla_1_1group_1_1ln__bwd__fused__op__t_3_01ln__bwd__fused__kind_1_1bias__dropout__cb4d0474e0a28c140fa444d1da09a494.html#a9eaaef007309e360560adb033951828a">  154</a></span>    uint32_t <a class="code hl_variable" href="structgpu_1_1xetla_1_1group_1_1ln__bwd__fused__op__t_3_01ln__bwd__fused__kind_1_1bias__dropout__cb4d0474e0a28c140fa444d1da09a494.html#a9eaaef007309e360560adb033951828a">mat_ld</a>;</div>
<div class="line"><a id="l00155" name="l00155"></a><span class="lineno"><a class="line" href="structgpu_1_1xetla_1_1group_1_1ln__bwd__fused__op__t_3_01ln__bwd__fused__kind_1_1bias__dropout__cb4d0474e0a28c140fa444d1da09a494.html#a3ac5572563f98d4f4e2e399a9d350521">  155</a></span>    uint32_t <a class="code hl_variable" href="structgpu_1_1xetla_1_1group_1_1ln__bwd__fused__op__t_3_01ln__bwd__fused__kind_1_1bias__dropout__cb4d0474e0a28c140fa444d1da09a494.html#a3ac5572563f98d4f4e2e399a9d350521">mask_ld</a>;</div>
<div class="line"><a id="l00156" name="l00156"></a><span class="lineno"><a class="line" href="structgpu_1_1xetla_1_1group_1_1ln__bwd__fused__op__t_3_01ln__bwd__fused__kind_1_1bias__dropout__cb4d0474e0a28c140fa444d1da09a494.html#ae8a78de73ef74bb0085bb83b7f280672">  156</a></span>    uint32_t <a class="code hl_variable" href="structgpu_1_1xetla_1_1group_1_1ln__bwd__fused__op__t_3_01ln__bwd__fused__kind_1_1bias__dropout__cb4d0474e0a28c140fa444d1da09a494.html#ae8a78de73ef74bb0085bb83b7f280672">matrix_n</a>;</div>
<div class="line"><a id="l00157" name="l00157"></a><span class="lineno"><a class="line" href="structgpu_1_1xetla_1_1group_1_1ln__bwd__fused__op__t_3_01ln__bwd__fused__kind_1_1bias__dropout__cb4d0474e0a28c140fa444d1da09a494.html#a4c06961e53485b61c198c291948f7739">  157</a></span>    uint32_t <a class="code hl_variable" href="structgpu_1_1xetla_1_1group_1_1ln__bwd__fused__op__t_3_01ln__bwd__fused__kind_1_1bias__dropout__cb4d0474e0a28c140fa444d1da09a494.html#a4c06961e53485b61c198c291948f7739">matrix_m</a>;</div>
<div class="line"><a id="l00158" name="l00158"></a><span class="lineno"><a class="line" href="structgpu_1_1xetla_1_1group_1_1ln__bwd__fused__op__t_3_01ln__bwd__fused__kind_1_1bias__dropout__cb4d0474e0a28c140fa444d1da09a494.html#a481ebaacacf9221118c83867a28f06d5">  158</a></span>    int32_t <a class="code hl_variable" href="structgpu_1_1xetla_1_1group_1_1ln__bwd__fused__op__t_3_01ln__bwd__fused__kind_1_1bias__dropout__cb4d0474e0a28c140fa444d1da09a494.html#a481ebaacacf9221118c83867a28f06d5">dbias_n</a>;</div>
<div class="line"><a id="l00159" name="l00159"></a><span class="lineno"><a class="line" href="structgpu_1_1xetla_1_1group_1_1ln__bwd__fused__op__t_3_01ln__bwd__fused__kind_1_1bias__dropout__cb4d0474e0a28c140fa444d1da09a494.html#ae8a281a43fc61eeb1f5417c35b07b56c">  159</a></span>    int32_t <a class="code hl_variable" href="structgpu_1_1xetla_1_1group_1_1ln__bwd__fused__op__t_3_01ln__bwd__fused__kind_1_1bias__dropout__cb4d0474e0a28c140fa444d1da09a494.html#ae8a281a43fc61eeb1f5417c35b07b56c">dbias_m</a>;</div>
<div class="line"><a id="l00160" name="l00160"></a><span class="lineno"><a class="line" href="structgpu_1_1xetla_1_1group_1_1ln__bwd__fused__op__t_3_01ln__bwd__fused__kind_1_1bias__dropout__cb4d0474e0a28c140fa444d1da09a494.html#a4e7174742a86817a326117cce9ce7d3e">  160</a></span>    <a class="code hl_typedef" href="structgpu_1_1xetla_1_1group_1_1ln__bwd__fused__op__t_3_01ln__bwd__fused__kind_1_1bias__dropout__cb4d0474e0a28c140fa444d1da09a494.html#aa415f946f85a23532905c9e04899d27e">dtype_acc</a> *<a class="code hl_variable" href="structgpu_1_1xetla_1_1group_1_1ln__bwd__fused__op__t_3_01ln__bwd__fused__kind_1_1bias__dropout__cb4d0474e0a28c140fa444d1da09a494.html#a4e7174742a86817a326117cce9ce7d3e">dbias_acc_ptr</a>;</div>
<div class="line"><a id="l00161" name="l00161"></a><span class="lineno"><a class="line" href="structgpu_1_1xetla_1_1group_1_1ln__bwd__fused__op__t_3_01ln__bwd__fused__kind_1_1bias__dropout__cb4d0474e0a28c140fa444d1da09a494.html#a89258990a57f99c0607ae5b193c7dce8">  161</a></span>    <a class="code hl_typedef" href="group__xetla__core__base__types.html#ga8cf5d016d24c8870706e20c376287e04">xetla_vector&lt;dtype_acc, sg_tile_n&gt;</a> <a class="code hl_variable" href="structgpu_1_1xetla_1_1group_1_1ln__bwd__fused__op__t_3_01ln__bwd__fused__kind_1_1bias__dropout__cb4d0474e0a28c140fa444d1da09a494.html#a89258990a57f99c0607ae5b193c7dce8">dbias</a>;</div>
<div class="line"><a id="l00162" name="l00162"></a><span class="lineno"><a class="line" href="structgpu_1_1xetla_1_1group_1_1ln__bwd__fused__op__t_3_01ln__bwd__fused__kind_1_1bias__dropout__cb4d0474e0a28c140fa444d1da09a494.html#a3eb9cf04e6df4438fc3c2806da3e7d17">  162</a></span>    <span class="keywordtype">float</span> <a class="code hl_variable" href="structgpu_1_1xetla_1_1group_1_1ln__bwd__fused__op__t_3_01ln__bwd__fused__kind_1_1bias__dropout__cb4d0474e0a28c140fa444d1da09a494.html#a3eb9cf04e6df4438fc3c2806da3e7d17">dropout_prob</a>;</div>
<div class="line"><a id="l00163" name="l00163"></a><span class="lineno"><a class="line" href="structgpu_1_1xetla_1_1group_1_1ln__bwd__fused__op__t_3_01ln__bwd__fused__kind_1_1bias__dropout__cb4d0474e0a28c140fa444d1da09a494.html#a3d1cabec35d2bcf87eb2e650e7e97ea4">  163</a></span>    <span class="keywordtype">float</span> <a class="code hl_variable" href="structgpu_1_1xetla_1_1group_1_1ln__bwd__fused__op__t_3_01ln__bwd__fused__kind_1_1bias__dropout__cb4d0474e0a28c140fa444d1da09a494.html#a3d1cabec35d2bcf87eb2e650e7e97ea4">dropout_scale_inv</a>;</div>
<div class="line"><a id="l00164" name="l00164"></a><span class="lineno">  164</span> </div>
<div class="line"><a id="l00173" name="l00173"></a><span class="lineno"><a class="line" href="structgpu_1_1xetla_1_1group_1_1ln__bwd__fused__op__t_3_01ln__bwd__fused__kind_1_1bias__dropout__cb4d0474e0a28c140fa444d1da09a494.html#a4425e8c8f622411a463520c79a916165">  173</a></span>    <a class="code hl_define" href="common_2core_2common_8hpp.html#a9ed53999886ec13b86a4fe2e0fc16765">__XETLA_API</a> <span class="keywordtype">void</span> <a class="code hl_function" href="structgpu_1_1xetla_1_1group_1_1ln__bwd__fused__op__t_3_01ln__bwd__fused__kind_1_1bias__dropout__cb4d0474e0a28c140fa444d1da09a494.html#a4425e8c8f622411a463520c79a916165">init</a>(<a class="code hl_struct" href="structgpu_1_1xetla_1_1group_1_1ln__bwd__fused__op__arguments__t.html">arguments_t</a> *args, uint32_t wg_idx, uint32_t wg_idy,</div>
<div class="line"><a id="l00174" name="l00174"></a><span class="lineno">  174</span>            uint32_t sg_idx, uint32_t sg_idy) {</div>
<div class="line"><a id="l00175" name="l00175"></a><span class="lineno">  175</span>        <span class="keywordtype">int</span> start_n = wg_idx * wg_tile_n + sg_idx * sg_tile_n;</div>
<div class="line"><a id="l00176" name="l00176"></a><span class="lineno">  176</span>        <span class="keywordtype">int</span> start_m = wg_idy * wg_tile_m + sg_idy * sg_tile_m;</div>
<div class="line"><a id="l00177" name="l00177"></a><span class="lineno">  177</span>        dbias = 0;</div>
<div class="line"><a id="l00178" name="l00178"></a><span class="lineno">  178</span>        mat_ld = args-&gt;<a class="code hl_variable" href="structgpu_1_1xetla_1_1group_1_1ln__bwd__fused__op__arguments__t.html#ac624f186f20fe9a5689e1328ab5693d0">mat_ld</a>;</div>
<div class="line"><a id="l00179" name="l00179"></a><span class="lineno">  179</span>        mask_ld = args-&gt;<a class="code hl_variable" href="structgpu_1_1xetla_1_1group_1_1ln__bwd__fused__op__arguments__t.html#a378369421fe42c7b51b5f9a9e833e916">mask_ld</a>;</div>
<div class="line"><a id="l00180" name="l00180"></a><span class="lineno">  180</span>        matrix_n = args-&gt;<a class="code hl_variable" href="structgpu_1_1xetla_1_1group_1_1ln__bwd__fused__op__arguments__t.html#a5ca6fd69a759b2b68a6f1e047a4486fa">matrix_n</a>;</div>
<div class="line"><a id="l00181" name="l00181"></a><span class="lineno">  181</span>        matrix_m = args-&gt;<a class="code hl_variable" href="structgpu_1_1xetla_1_1group_1_1ln__bwd__fused__op__arguments__t.html#a2bbf0067cd8d0c85039237d7c505c5d6">matrix_m</a>;</div>
<div class="line"><a id="l00182" name="l00182"></a><span class="lineno">  182</span>        dx_resAdd_out_payload.init(args-&gt;<a class="code hl_variable" href="structgpu_1_1xetla_1_1group_1_1ln__bwd__fused__op__arguments__t.html#a2083f0ac3d8eee8ebcfe0d4df2c9b550">dx_resAdd_ptr</a>, matrix_n, matrix_m,</div>
<div class="line"><a id="l00183" name="l00183"></a><span class="lineno">  183</span>                mat_ld, start_n, start_m);</div>
<div class="line"><a id="l00184" name="l00184"></a><span class="lineno">  184</span>        mask_in_payload.init(</div>
<div class="line"><a id="l00185" name="l00185"></a><span class="lineno">  185</span>                args-&gt;<a class="code hl_variable" href="structgpu_1_1xetla_1_1group_1_1ln__bwd__fused__op__arguments__t.html#a96bc53f94fb970b26468b219769c0968">mask_ptr</a>, matrix_n, matrix_m, mask_ld, start_n, start_m);</div>
<div class="line"><a id="l00186" name="l00186"></a><span class="lineno">  186</span>        dbias_acc_ptr = args-&gt;<a class="code hl_variable" href="structgpu_1_1xetla_1_1group_1_1ln__bwd__fused__op__arguments__t.html#a07f0aac4809adc196e41750ded851a6f">dbias_acc_ptr</a>;</div>
<div class="line"><a id="l00187" name="l00187"></a><span class="lineno">  187</span>        dropout_scale_inv = args-&gt;<a class="code hl_variable" href="structgpu_1_1xetla_1_1group_1_1ln__bwd__fused__op__arguments__t.html#a70a67b387d3dd8dfe8fa33ae09716dd0">dropout_scale_inv</a>;</div>
<div class="line"><a id="l00188" name="l00188"></a><span class="lineno">  188</span>        dropout_prob = args-&gt;<a class="code hl_variable" href="structgpu_1_1xetla_1_1group_1_1ln__bwd__fused__op__arguments__t.html#ada068c26ced84797f9772fe202d746f0">dropout_prob</a>;</div>
<div class="line"><a id="l00189" name="l00189"></a><span class="lineno">  189</span>        dbias_n = start_n;</div>
<div class="line"><a id="l00190" name="l00190"></a><span class="lineno">  190</span>        dbias_m = wg_idy;</div>
<div class="line"><a id="l00191" name="l00191"></a><span class="lineno">  191</span>    }</div>
<div class="line"><a id="l00192" name="l00192"></a><span class="lineno">  192</span> </div>
<div class="line"><a id="l00197" name="l00197"></a><span class="lineno"><a class="line" href="structgpu_1_1xetla_1_1group_1_1ln__bwd__fused__op__t_3_01ln__bwd__fused__kind_1_1bias__dropout__cb4d0474e0a28c140fa444d1da09a494.html#a0f467fb7bf34ac7236adee6e29a31396">  197</a></span>    <a class="code hl_define" href="common_2core_2common_8hpp.html#a9ed53999886ec13b86a4fe2e0fc16765">__XETLA_API</a> <a class="code hl_typedef" href="group__xetla__core__base__types.html#ga8cf5d016d24c8870706e20c376287e04">xetla_vector&lt;dtype_acc, sg_tile_n&gt;</a> <a class="code hl_function" href="structgpu_1_1xetla_1_1group_1_1ln__bwd__fused__op__t_3_01ln__bwd__fused__kind_1_1bias__dropout__cb4d0474e0a28c140fa444d1da09a494.html#a0f467fb7bf34ac7236adee6e29a31396">pre_op</a>(</div>
<div class="line"><a id="l00198" name="l00198"></a><span class="lineno">  198</span>            <a class="code hl_typedef" href="group__xetla__core__base__types.html#ga8cf5d016d24c8870706e20c376287e04">xetla_vector&lt;dtype_acc, sg_tile_n&gt;</a> input) {</div>
<div class="line"><a id="l00199" name="l00199"></a><span class="lineno">  199</span>        <span class="keywordflow">return</span> input;</div>
<div class="line"><a id="l00200" name="l00200"></a><span class="lineno">  200</span>    }</div>
<div class="line"><a id="l00201" name="l00201"></a><span class="lineno">  201</span> </div>
<div class="line"><a id="l00206" name="l00206"></a><span class="lineno"><a class="line" href="structgpu_1_1xetla_1_1group_1_1ln__bwd__fused__op__t_3_01ln__bwd__fused__kind_1_1bias__dropout__cb4d0474e0a28c140fa444d1da09a494.html#a2467782c8f21f74bca275f84c211ca27">  206</a></span>    <a class="code hl_define" href="common_2core_2common_8hpp.html#a9ed53999886ec13b86a4fe2e0fc16765">__XETLA_API</a> <a class="code hl_typedef" href="group__xetla__core__base__types.html#ga8cf5d016d24c8870706e20c376287e04">xetla_vector&lt;dtype_acc, sg_tile_n&gt;</a> <a class="code hl_function" href="structgpu_1_1xetla_1_1group_1_1ln__bwd__fused__op__t_3_01ln__bwd__fused__kind_1_1bias__dropout__cb4d0474e0a28c140fa444d1da09a494.html#a2467782c8f21f74bca275f84c211ca27">post_op</a>(</div>
<div class="line"><a id="l00207" name="l00207"></a><span class="lineno">  207</span>            <a class="code hl_typedef" href="group__xetla__core__base__types.html#ga8cf5d016d24c8870706e20c376287e04">xetla_vector&lt;dtype_acc, sg_tile_n&gt;</a> input) {</div>
<div class="line"><a id="l00208" name="l00208"></a><span class="lineno">  208</span>        <a class="code hl_typedef" href="group__xetla__core__base__types.html#ga8cf5d016d24c8870706e20c376287e04">xetla_vector&lt;dtype_acc, sg_tile_n&gt;</a> output = input;</div>
<div class="line"><a id="l00209" name="l00209"></a><span class="lineno">  209</span>        dx_resAdd_out.<a class="code hl_variable" href="structgpu_1_1xetla_1_1subgroup_1_1tile__t.html#a7985ceac15e399ebf3000e5693d8801e">reg</a> = xetla_cvt&lt;dtype_out, dtype_acc&gt;(input);</div>
<div class="line"><a id="l00210" name="l00210"></a><span class="lineno">  210</span>        subgroup::tile_store&lt;cache_hint::uncached&gt;(</div>
<div class="line"><a id="l00211" name="l00211"></a><span class="lineno">  211</span>                dx_resAdd_out, dx_resAdd_out_payload);</div>
<div class="line"><a id="l00212" name="l00212"></a><span class="lineno">  212</span>        dx_resAdd_out_payload.update_tdesc(wg_num_m * wg_tile_m * mat_ld);</div>
<div class="line"><a id="l00213" name="l00213"></a><span class="lineno">  213</span>        <span class="keywordflow">if</span> (dropout_prob != 0) {</div>
<div class="line"><a id="l00214" name="l00214"></a><span class="lineno">  214</span>            <a class="code hl_function" href="namespacegpu_1_1xetla_1_1subgroup.html#ae110043dd5332ce2a7ef91d2c8ae79ef">subgroup::tile_load</a>(mask_in, mask_in_payload);</div>
<div class="line"><a id="l00215" name="l00215"></a><span class="lineno">  215</span>            <a class="code hl_define" href="common_2core_2common_8hpp.html#a4894ef2f787a454434527ed8416177d9">SW_BARRIER</a>();</div>
<div class="line"><a id="l00216" name="l00216"></a><span class="lineno">  216</span>            mask_in_payload.update_tdesc(wg_num_m * wg_tile_m * mask_ld);</div>
<div class="line"><a id="l00217" name="l00217"></a><span class="lineno">  217</span>            output = drop_out&lt;dtype_acc, sg_tile_n&gt;(</div>
<div class="line"><a id="l00218" name="l00218"></a><span class="lineno">  218</span>                    output, mask_in.<a class="code hl_variable" href="structgpu_1_1xetla_1_1subgroup_1_1tile__t.html#a7985ceac15e399ebf3000e5693d8801e">reg</a>, dropout_scale_inv);</div>
<div class="line"><a id="l00219" name="l00219"></a><span class="lineno">  219</span>        }</div>
<div class="line"><a id="l00220" name="l00220"></a><span class="lineno">  220</span>        dbias += output;</div>
<div class="line"><a id="l00221" name="l00221"></a><span class="lineno">  221</span>        <span class="keywordflow">return</span> output;</div>
<div class="line"><a id="l00222" name="l00222"></a><span class="lineno">  222</span>    }</div>
<div class="line"><a id="l00223" name="l00223"></a><span class="lineno">  223</span> </div>
<div class="line"><a id="l00229" name="l00229"></a><span class="lineno">  229</span>    <span class="keyword">template</span> &lt;<span class="keyword">typename</span> reduce_t&gt;</div>
<div class="line"><a id="l00230" name="l00230"></a><span class="lineno"><a class="line" href="structgpu_1_1xetla_1_1group_1_1ln__bwd__fused__op__t_3_01ln__bwd__fused__kind_1_1bias__dropout__cb4d0474e0a28c140fa444d1da09a494.html#ae7950f281f39706d668deb99e2d946a5">  230</a></span>    <a class="code hl_define" href="common_2core_2common_8hpp.html#a9ed53999886ec13b86a4fe2e0fc16765">__XETLA_API</a> <span class="keywordtype">void</span> <a class="code hl_function" href="structgpu_1_1xetla_1_1group_1_1ln__bwd__fused__op__t_3_01ln__bwd__fused__kind_1_1bias__dropout__cb4d0474e0a28c140fa444d1da09a494.html#ae7950f281f39706d668deb99e2d946a5">final_op</a>(reduce_t &amp;ln_group_row_reduce) {</div>
<div class="line"><a id="l00231" name="l00231"></a><span class="lineno">  231</span>        ln_group_row_reduce(dbias_acc_ptr, matrix_n, wg_num_m, matrix_n,</div>
<div class="line"><a id="l00232" name="l00232"></a><span class="lineno">  232</span>                dbias_n, dbias_m, dbias);</div>
<div class="line"><a id="l00233" name="l00233"></a><span class="lineno">  233</span>    }</div>
<div class="line"><a id="l00234" name="l00234"></a><span class="lineno">  234</span>};</div>
<div class="line"><a id="l00235" name="l00235"></a><span class="lineno">  235</span> </div>
<div class="line"><a id="l00242" name="l00242"></a><span class="lineno">  242</span><span class="keyword">template</span> &lt;<span class="keyword">typename</span> dtype_in_, <span class="keyword">typename</span> dtype_out_, <span class="keyword">typename</span> dtype_acc_,</div>
<div class="line"><a id="l00243" name="l00243"></a><span class="lineno">  243</span>        <span class="keyword">typename</span> layer_norm_attr_&gt;</div>
<div class="line"><a id="l00244" name="l00244"></a><span class="lineno"><a class="line" href="structgpu_1_1xetla_1_1group_1_1ln__bwd__fused__op__t_3_01ln__bwd__fused__kind_1_1ln__dropout__gra92c7b1e7d0db3d047617e99aa09b9df.html">  244</a></span><span class="keyword">struct </span><a class="code hl_struct" href="structgpu_1_1xetla_1_1group_1_1ln__bwd__fused__op__t.html">ln_bwd_fused_op_t</a>&lt;<a class="code hl_enumeration" href="namespacegpu_1_1xetla.html#aacf5f0d7a8241d58320b4a95e0f7592b">ln_bwd_fused_kind</a>::<a class="code hl_enumvalue" href="namespacegpu_1_1xetla.html#aacf5f0d7a8241d58320b4a95e0f7592ba8f9524126712534cd132e17944140f04">ln_dropout_gradAdd</a>, dtype_in_,</div>
<div class="line"><a id="l00245" name="l00245"></a><span class="lineno">  245</span>        dtype_out_, dtype_acc_, layer_norm_attr_, <a class="code hl_enumvalue" href="namespacegpu_1_1xetla.html#aa5a2713edb27d6fed88a3c61673556f1a8fde9df1bf2567b76160d1beedca3130">gpu_arch::Xe</a>&gt; {</div>
<div class="line"><a id="l00246" name="l00246"></a><span class="lineno"><a class="line" href="structgpu_1_1xetla_1_1group_1_1ln__bwd__fused__op__t_3_01ln__bwd__fused__kind_1_1ln__dropout__gra92c7b1e7d0db3d047617e99aa09b9df.html#a9b4c05e5279b9fa0d36315b6272fa66c">  246</a></span>    <span class="keyword">static</span> <span class="keyword">constexpr</span> <a class="code hl_enumeration" href="namespacegpu_1_1xetla.html#aacf5f0d7a8241d58320b4a95e0f7592b">ln_bwd_fused_kind</a> fused_op_kind</div>
<div class="line"><a id="l00247" name="l00247"></a><span class="lineno">  247</span>            = <a class="code hl_enumvalue" href="namespacegpu_1_1xetla.html#aacf5f0d7a8241d58320b4a95e0f7592ba8f9524126712534cd132e17944140f04">ln_bwd_fused_kind::ln_dropout_gradAdd</a>;</div>
<div class="line"><a id="l00248" name="l00248"></a><span class="lineno"><a class="line" href="structgpu_1_1xetla_1_1group_1_1ln__bwd__fused__op__t_3_01ln__bwd__fused__kind_1_1ln__dropout__gra92c7b1e7d0db3d047617e99aa09b9df.html#abfe8bc45d22c8d44102eb42b82140007">  248</a></span>    <span class="keyword">using </span><a class="code hl_typedef" href="structgpu_1_1xetla_1_1group_1_1ln__bwd__fused__op__t_3_01ln__bwd__fused__kind_1_1ln__dropout__gra92c7b1e7d0db3d047617e99aa09b9df.html#abfe8bc45d22c8d44102eb42b82140007">dtype_acc</a> = dtype_acc_;</div>
<div class="line"><a id="l00249" name="l00249"></a><span class="lineno"><a class="line" href="structgpu_1_1xetla_1_1group_1_1ln__bwd__fused__op__t_3_01ln__bwd__fused__kind_1_1ln__dropout__gra92c7b1e7d0db3d047617e99aa09b9df.html#aae312d3b6e98182efda44dc5b3b4566f">  249</a></span>    <span class="keyword">using </span><a class="code hl_typedef" href="structgpu_1_1xetla_1_1group_1_1ln__bwd__fused__op__t_3_01ln__bwd__fused__kind_1_1ln__dropout__gra92c7b1e7d0db3d047617e99aa09b9df.html#aae312d3b6e98182efda44dc5b3b4566f">dtype_in</a> = dtype_in_;</div>
<div class="line"><a id="l00250" name="l00250"></a><span class="lineno"><a class="line" href="structgpu_1_1xetla_1_1group_1_1ln__bwd__fused__op__t_3_01ln__bwd__fused__kind_1_1ln__dropout__gra92c7b1e7d0db3d047617e99aa09b9df.html#a75ff13c7a726900f0eafbb6bffeb99d8">  250</a></span>    <span class="keyword">using </span><a class="code hl_typedef" href="structgpu_1_1xetla_1_1group_1_1ln__bwd__fused__op__t_3_01ln__bwd__fused__kind_1_1ln__dropout__gra92c7b1e7d0db3d047617e99aa09b9df.html#a75ff13c7a726900f0eafbb6bffeb99d8">dtype_out</a> = dtype_out_;</div>
<div class="line"><a id="l00251" name="l00251"></a><span class="lineno"><a class="line" href="structgpu_1_1xetla_1_1group_1_1ln__bwd__fused__op__t_3_01ln__bwd__fused__kind_1_1ln__dropout__gra92c7b1e7d0db3d047617e99aa09b9df.html#a5a9649b65ac3248ff435a6e5ab140eeb">  251</a></span>    <span class="keyword">using </span><a class="code hl_typedef" href="structgpu_1_1xetla_1_1group_1_1ln__bwd__fused__op__t_3_01ln__bwd__fused__kind_1_1ln__dropout__gra92c7b1e7d0db3d047617e99aa09b9df.html#a5a9649b65ac3248ff435a6e5ab140eeb">dtype_mask</a> = uint8_t;</div>
<div class="line"><a id="l00252" name="l00252"></a><span class="lineno"><a class="line" href="structgpu_1_1xetla_1_1group_1_1ln__bwd__fused__op__t_3_01ln__bwd__fused__kind_1_1ln__dropout__gra92c7b1e7d0db3d047617e99aa09b9df.html#aaacb1b764be54b5ae7873ba54f2a5f08">  252</a></span>    <span class="keyword">using </span><a class="code hl_struct" href="structgpu_1_1xetla_1_1group_1_1ln__bwd__fused__op__arguments__t.html">arguments_t</a></div>
<div class="line"><a id="l00253" name="l00253"></a><span class="lineno">  253</span>            = <a class="code hl_struct" href="structgpu_1_1xetla_1_1group_1_1ln__bwd__fused__op__arguments__t.html">ln_bwd_fused_op_arguments_t&lt;dtype_in, dtype_out, dtype_acc&gt;</a>;</div>
<div class="line"><a id="l00254" name="l00254"></a><span class="lineno"><a class="line" href="structgpu_1_1xetla_1_1group_1_1ln__bwd__fused__op__t_3_01ln__bwd__fused__kind_1_1ln__dropout__gra92c7b1e7d0db3d047617e99aa09b9df.html#ac1cf979f7288951a2d69cc9fe45e677d">  254</a></span>    <span class="keyword">static</span> <span class="keyword">constexpr</span> uint32_t wg_tile_m = layer_norm_attr_::wg_tile_m;</div>
<div class="line"><a id="l00255" name="l00255"></a><span class="lineno"><a class="line" href="structgpu_1_1xetla_1_1group_1_1ln__bwd__fused__op__t_3_01ln__bwd__fused__kind_1_1ln__dropout__gra92c7b1e7d0db3d047617e99aa09b9df.html#ade5316cb6274f1cb4fd5e694c8faa28e">  255</a></span>    <span class="keyword">static</span> <span class="keyword">constexpr</span> uint32_t wg_tile_n = layer_norm_attr_::wg_tile_n;</div>
<div class="line"><a id="l00256" name="l00256"></a><span class="lineno"><a class="line" href="structgpu_1_1xetla_1_1group_1_1ln__bwd__fused__op__t_3_01ln__bwd__fused__kind_1_1ln__dropout__gra92c7b1e7d0db3d047617e99aa09b9df.html#ac85a8ad07efac2b7b5ef0d959a4db420">  256</a></span>    <span class="keyword">static</span> <span class="keyword">constexpr</span> uint32_t sg_tile_m = layer_norm_attr_::sg_tile_m;</div>
<div class="line"><a id="l00257" name="l00257"></a><span class="lineno"><a class="line" href="structgpu_1_1xetla_1_1group_1_1ln__bwd__fused__op__t_3_01ln__bwd__fused__kind_1_1ln__dropout__gra92c7b1e7d0db3d047617e99aa09b9df.html#a9a0ce2fc50402bbb29e9749ce779cf6b">  257</a></span>    <span class="keyword">static</span> <span class="keyword">constexpr</span> uint32_t sg_tile_n = layer_norm_attr_::sg_tile_n;</div>
<div class="line"><a id="l00258" name="l00258"></a><span class="lineno"><a class="line" href="structgpu_1_1xetla_1_1group_1_1ln__bwd__fused__op__t_3_01ln__bwd__fused__kind_1_1ln__dropout__gra92c7b1e7d0db3d047617e99aa09b9df.html#a2de80f94e7994a4b9db261c27cf72f9a">  258</a></span>    <span class="keyword">static</span> <span class="keyword">constexpr</span> uint32_t wg_num_m = layer_norm_attr_::wg_num_m;</div>
<div class="line"><a id="l00259" name="l00259"></a><span class="lineno"><a class="line" href="structgpu_1_1xetla_1_1group_1_1ln__bwd__fused__op__t_3_01ln__bwd__fused__kind_1_1ln__dropout__gra92c7b1e7d0db3d047617e99aa09b9df.html#aec1f081c304e1ce78cdd8058ee7a5a53">  259</a></span>    <span class="keyword">static</span> <span class="keyword">constexpr</span> uint32_t wg_num_n = layer_norm_attr_::wg_num_n;</div>
<div class="line"><a id="l00260" name="l00260"></a><span class="lineno">  260</span> </div>
<div class="line"><a id="l00261" name="l00261"></a><span class="lineno"><a class="line" href="structgpu_1_1xetla_1_1group_1_1ln__bwd__fused__op__t_3_01ln__bwd__fused__kind_1_1ln__dropout__gra92c7b1e7d0db3d047617e99aa09b9df.html#adc7991ac34841dab777ba64c00a0b5fa">  261</a></span>    <span class="keyword">static</span> <span class="keyword">constexpr</span> uint32_t wg_size_x</div>
<div class="line"><a id="l00262" name="l00262"></a><span class="lineno">  262</span>            = (wg_tile_n + sg_tile_n - 1) / sg_tile_n;</div>
<div class="line"><a id="l00263" name="l00263"></a><span class="lineno"><a class="line" href="structgpu_1_1xetla_1_1group_1_1ln__bwd__fused__op__t_3_01ln__bwd__fused__kind_1_1ln__dropout__gra92c7b1e7d0db3d047617e99aa09b9df.html#afbfdb52e50f0525badbc775da1188c94">  263</a></span>    <span class="keyword">static</span> <span class="keyword">constexpr</span> uint32_t wg_size_y</div>
<div class="line"><a id="l00264" name="l00264"></a><span class="lineno">  264</span>            = (wg_tile_m + sg_tile_m - 1) / sg_tile_m;</div>
<div class="line"><a id="l00265" name="l00265"></a><span class="lineno">  265</span> </div>
<div class="line"><a id="l00266" name="l00266"></a><span class="lineno">  266</span>    <span class="keyword">static_assert</span>((sg_tile_n % (<span class="keyword">sizeof</span>(uint32_t) / <span class="keyword">sizeof</span>(<a class="code hl_typedef" href="structgpu_1_1xetla_1_1group_1_1ln__bwd__fused__op__t_3_01ln__bwd__fused__kind_1_1ln__dropout__gra92c7b1e7d0db3d047617e99aa09b9df.html#a5a9649b65ac3248ff435a6e5ab140eeb">dtype_mask</a>)) == 0),</div>
<div class="line"><a id="l00267" name="l00267"></a><span class="lineno">  267</span>            <span class="stringliteral">&quot;sg_tile_n need to be DW aligned&quot;</span>);</div>
<div class="line"><a id="l00268" name="l00268"></a><span class="lineno"><a class="line" href="structgpu_1_1xetla_1_1group_1_1ln__bwd__fused__op__t_3_01ln__bwd__fused__kind_1_1ln__dropout__gra92c7b1e7d0db3d047617e99aa09b9df.html#a3a28af36a9436e0c3f7015d71d2955c0">  268</a></span>    <span class="keyword">using </span><a class="code hl_struct" href="structgpu_1_1xetla_1_1subgroup_1_1tile__desc__t.html">ln_bwd_tile_desc_t</a> = <a class="code hl_struct" href="structgpu_1_1xetla_1_1subgroup_1_1tile__desc__t.html">subgroup::tile_desc_t</a>&lt;sg_tile_n, 1, sg_tile_n, 1,</div>
<div class="line"><a id="l00269" name="l00269"></a><span class="lineno">  269</span>            <a class="code hl_enumvalue" href="namespacegpu_1_1xetla.html#a51137fd81d0d9d2156525a1e279432aaa78506882d645395a052df8b01a927395">reg_layout::tiled</a>&gt;;</div>
<div class="line"><a id="l00270" name="l00270"></a><span class="lineno"><a class="line" href="structgpu_1_1xetla_1_1group_1_1ln__bwd__fused__op__t_3_01ln__bwd__fused__kind_1_1ln__dropout__gra92c7b1e7d0db3d047617e99aa09b9df.html#a0073089961b25a3deed6bb9280152d8e">  270</a></span>    <span class="keyword">using </span><a class="code hl_class" href="structgpu_1_1xetla_1_1subgroup_1_1tile__t.html">grad_in_t</a> = <a class="code hl_struct" href="structgpu_1_1xetla_1_1subgroup_1_1tile__t.html">subgroup::tile_t&lt;dtype_out, ln_bwd_tile_desc_t&gt;</a>;</div>
<div class="line"><a id="l00271" name="l00271"></a><span class="lineno"><a class="line" href="structgpu_1_1xetla_1_1group_1_1ln__bwd__fused__op__t_3_01ln__bwd__fused__kind_1_1ln__dropout__gra92c7b1e7d0db3d047617e99aa09b9df.html#a88b12d2ac5020647a08630d45d8f9e01">  271</a></span>    <span class="keyword">using </span><a class="code hl_class" href="structgpu_1_1xetla_1_1subgroup_1_1mem__payload__t.html">grad_in_payload_t</a> = <a class="code hl_struct" href="structgpu_1_1xetla_1_1subgroup_1_1mem__payload__t.html">subgroup::mem_payload_t</a>&lt;</div>
<div class="line"><a id="l00272" name="l00272"></a><span class="lineno">  272</span>            <a class="code hl_struct" href="structgpu_1_1xetla_1_1mem__desc__t.html">mem_desc_t&lt;dtype_out, mem_layout::row_major, mem_space::global&gt;</a>,</div>
<div class="line"><a id="l00273" name="l00273"></a><span class="lineno">  273</span>            <a class="code hl_struct" href="structgpu_1_1xetla_1_1subgroup_1_1tile__desc__t.html">ln_bwd_tile_desc_t</a>, <a class="code hl_enumvalue" href="namespacegpu_1_1xetla.html#aa8afe1d12e7777419fb6ea09534a0aa7a5baf9a1aba8e4b6fa44c20aafacc4233">msg_type::block_1d</a>, <a class="code hl_enumvalue" href="namespacegpu_1_1xetla.html#aa5a2713edb27d6fed88a3c61673556f1a8fde9df1bf2567b76160d1beedca3130">gpu_arch::Xe</a>&gt;;</div>
<div class="line"><a id="l00274" name="l00274"></a><span class="lineno"><a class="line" href="structgpu_1_1xetla_1_1group_1_1ln__bwd__fused__op__t_3_01ln__bwd__fused__kind_1_1ln__dropout__gra92c7b1e7d0db3d047617e99aa09b9df.html#ad023efd52399fd5f93a7e18066bc4079">  274</a></span>    <span class="keyword">using </span><a class="code hl_class" href="structgpu_1_1xetla_1_1subgroup_1_1tile__t.html">mask_in_t</a> = <a class="code hl_struct" href="structgpu_1_1xetla_1_1subgroup_1_1tile__t.html">subgroup::tile_t&lt;dtype_mask, ln_bwd_tile_desc_t&gt;</a>;</div>
<div class="line"><a id="l00275" name="l00275"></a><span class="lineno"><a class="line" href="structgpu_1_1xetla_1_1group_1_1ln__bwd__fused__op__t_3_01ln__bwd__fused__kind_1_1ln__dropout__gra92c7b1e7d0db3d047617e99aa09b9df.html#a91d1269ce1f8b2a1e70ba9913971af97">  275</a></span>    <span class="keyword">using </span><a class="code hl_class" href="structgpu_1_1xetla_1_1subgroup_1_1mem__payload__t.html">mask_in_payload_t</a> = <a class="code hl_struct" href="structgpu_1_1xetla_1_1subgroup_1_1mem__payload__t.html">subgroup::mem_payload_t</a>&lt;</div>
<div class="line"><a id="l00276" name="l00276"></a><span class="lineno">  276</span>            <a class="code hl_struct" href="structgpu_1_1xetla_1_1mem__desc__t.html">mem_desc_t&lt;dtype_mask, mem_layout::row_major, mem_space::global&gt;</a>,</div>
<div class="line"><a id="l00277" name="l00277"></a><span class="lineno">  277</span>            <a class="code hl_struct" href="structgpu_1_1xetla_1_1subgroup_1_1tile__desc__t.html">ln_bwd_tile_desc_t</a>, <a class="code hl_enumvalue" href="namespacegpu_1_1xetla.html#aa8afe1d12e7777419fb6ea09534a0aa7a5baf9a1aba8e4b6fa44c20aafacc4233">msg_type::block_1d</a>, <a class="code hl_enumvalue" href="namespacegpu_1_1xetla.html#aa5a2713edb27d6fed88a3c61673556f1a8fde9df1bf2567b76160d1beedca3130">gpu_arch::Xe</a>&gt;;</div>
<div class="line"><a id="l00278" name="l00278"></a><span class="lineno">  278</span> </div>
<div class="line"><a id="l00279" name="l00279"></a><span class="lineno"><a class="line" href="structgpu_1_1xetla_1_1group_1_1ln__bwd__fused__op__t_3_01ln__bwd__fused__kind_1_1ln__dropout__gra92c7b1e7d0db3d047617e99aa09b9df.html#a792ec301a9e080568bd3602461fe84c1">  279</a></span>    <a class="code hl_class" href="structgpu_1_1xetla_1_1subgroup_1_1tile__t.html">grad_in_t</a> <a class="code hl_variable" href="structgpu_1_1xetla_1_1group_1_1ln__bwd__fused__op__t_3_01ln__bwd__fused__kind_1_1ln__dropout__gra92c7b1e7d0db3d047617e99aa09b9df.html#a792ec301a9e080568bd3602461fe84c1">grad_in</a>;</div>
<div class="line"><a id="l00280" name="l00280"></a><span class="lineno"><a class="line" href="structgpu_1_1xetla_1_1group_1_1ln__bwd__fused__op__t_3_01ln__bwd__fused__kind_1_1ln__dropout__gra92c7b1e7d0db3d047617e99aa09b9df.html#aacc702fde978a0d71dca4d3d18c48353">  280</a></span>    <a class="code hl_class" href="structgpu_1_1xetla_1_1subgroup_1_1mem__payload__t.html">grad_in_payload_t</a> <a class="code hl_variable" href="structgpu_1_1xetla_1_1group_1_1ln__bwd__fused__op__t_3_01ln__bwd__fused__kind_1_1ln__dropout__gra92c7b1e7d0db3d047617e99aa09b9df.html#aacc702fde978a0d71dca4d3d18c48353">grad_in_payload</a>;</div>
<div class="line"><a id="l00281" name="l00281"></a><span class="lineno"><a class="line" href="structgpu_1_1xetla_1_1group_1_1ln__bwd__fused__op__t_3_01ln__bwd__fused__kind_1_1ln__dropout__gra92c7b1e7d0db3d047617e99aa09b9df.html#a8e779e9623c98e1eca8e970df691bf4d">  281</a></span>    <a class="code hl_class" href="structgpu_1_1xetla_1_1subgroup_1_1tile__t.html">mask_in_t</a> <a class="code hl_variable" href="structgpu_1_1xetla_1_1group_1_1ln__bwd__fused__op__t_3_01ln__bwd__fused__kind_1_1ln__dropout__gra92c7b1e7d0db3d047617e99aa09b9df.html#a8e779e9623c98e1eca8e970df691bf4d">mask_in</a>;</div>
<div class="line"><a id="l00282" name="l00282"></a><span class="lineno"><a class="line" href="structgpu_1_1xetla_1_1group_1_1ln__bwd__fused__op__t_3_01ln__bwd__fused__kind_1_1ln__dropout__gra92c7b1e7d0db3d047617e99aa09b9df.html#a6c76a53d67534dcfd520bf632407e769">  282</a></span>    <a class="code hl_class" href="structgpu_1_1xetla_1_1subgroup_1_1mem__payload__t.html">mask_in_payload_t</a> <a class="code hl_variable" href="structgpu_1_1xetla_1_1group_1_1ln__bwd__fused__op__t_3_01ln__bwd__fused__kind_1_1ln__dropout__gra92c7b1e7d0db3d047617e99aa09b9df.html#a6c76a53d67534dcfd520bf632407e769">mask_in_payload</a>;</div>
<div class="line"><a id="l00283" name="l00283"></a><span class="lineno">  283</span> </div>
<div class="line"><a id="l00284" name="l00284"></a><span class="lineno"><a class="line" href="structgpu_1_1xetla_1_1group_1_1ln__bwd__fused__op__t_3_01ln__bwd__fused__kind_1_1ln__dropout__gra92c7b1e7d0db3d047617e99aa09b9df.html#aac13aca6669fa3a5f200da168d3d9403">  284</a></span>    uint32_t <a class="code hl_variable" href="structgpu_1_1xetla_1_1group_1_1ln__bwd__fused__op__t_3_01ln__bwd__fused__kind_1_1ln__dropout__gra92c7b1e7d0db3d047617e99aa09b9df.html#aac13aca6669fa3a5f200da168d3d9403">mat_ld</a>;</div>
<div class="line"><a id="l00285" name="l00285"></a><span class="lineno"><a class="line" href="structgpu_1_1xetla_1_1group_1_1ln__bwd__fused__op__t_3_01ln__bwd__fused__kind_1_1ln__dropout__gra92c7b1e7d0db3d047617e99aa09b9df.html#a45bb083ed20f8f40d9e9eb0f1dd88332">  285</a></span>    uint32_t <a class="code hl_variable" href="structgpu_1_1xetla_1_1group_1_1ln__bwd__fused__op__t_3_01ln__bwd__fused__kind_1_1ln__dropout__gra92c7b1e7d0db3d047617e99aa09b9df.html#a45bb083ed20f8f40d9e9eb0f1dd88332">mask_ld</a>;</div>
<div class="line"><a id="l00286" name="l00286"></a><span class="lineno"><a class="line" href="structgpu_1_1xetla_1_1group_1_1ln__bwd__fused__op__t_3_01ln__bwd__fused__kind_1_1ln__dropout__gra92c7b1e7d0db3d047617e99aa09b9df.html#a7649a2529901a761152df1edf82afa84">  286</a></span>    uint32_t <a class="code hl_variable" href="structgpu_1_1xetla_1_1group_1_1ln__bwd__fused__op__t_3_01ln__bwd__fused__kind_1_1ln__dropout__gra92c7b1e7d0db3d047617e99aa09b9df.html#a7649a2529901a761152df1edf82afa84">matrix_n</a>;</div>
<div class="line"><a id="l00287" name="l00287"></a><span class="lineno"><a class="line" href="structgpu_1_1xetla_1_1group_1_1ln__bwd__fused__op__t_3_01ln__bwd__fused__kind_1_1ln__dropout__gra92c7b1e7d0db3d047617e99aa09b9df.html#a39cef2885bb55a37e7c765f8c9c74bd8">  287</a></span>    uint32_t <a class="code hl_variable" href="structgpu_1_1xetla_1_1group_1_1ln__bwd__fused__op__t_3_01ln__bwd__fused__kind_1_1ln__dropout__gra92c7b1e7d0db3d047617e99aa09b9df.html#a39cef2885bb55a37e7c765f8c9c74bd8">matrix_m</a>;</div>
<div class="line"><a id="l00288" name="l00288"></a><span class="lineno"><a class="line" href="structgpu_1_1xetla_1_1group_1_1ln__bwd__fused__op__t_3_01ln__bwd__fused__kind_1_1ln__dropout__gra92c7b1e7d0db3d047617e99aa09b9df.html#a8c485a20c1571f1bc1864bc8acd7ead6">  288</a></span>    <span class="keywordtype">float</span> <a class="code hl_variable" href="structgpu_1_1xetla_1_1group_1_1ln__bwd__fused__op__t_3_01ln__bwd__fused__kind_1_1ln__dropout__gra92c7b1e7d0db3d047617e99aa09b9df.html#a8c485a20c1571f1bc1864bc8acd7ead6">dropout_prob</a>;</div>
<div class="line"><a id="l00289" name="l00289"></a><span class="lineno"><a class="line" href="structgpu_1_1xetla_1_1group_1_1ln__bwd__fused__op__t_3_01ln__bwd__fused__kind_1_1ln__dropout__gra92c7b1e7d0db3d047617e99aa09b9df.html#a47baa8bbc5b2cefdccecc0577b9848b7">  289</a></span>    <span class="keywordtype">float</span> <a class="code hl_variable" href="structgpu_1_1xetla_1_1group_1_1ln__bwd__fused__op__t_3_01ln__bwd__fused__kind_1_1ln__dropout__gra92c7b1e7d0db3d047617e99aa09b9df.html#a47baa8bbc5b2cefdccecc0577b9848b7">dropout_scale_inv</a>;</div>
<div class="line"><a id="l00290" name="l00290"></a><span class="lineno">  290</span> </div>
<div class="line"><a id="l00299" name="l00299"></a><span class="lineno"><a class="line" href="structgpu_1_1xetla_1_1group_1_1ln__bwd__fused__op__t_3_01ln__bwd__fused__kind_1_1ln__dropout__gra92c7b1e7d0db3d047617e99aa09b9df.html#a8d86702c150b66c9964aa9985c9dc8b8">  299</a></span>    <a class="code hl_define" href="common_2core_2common_8hpp.html#a9ed53999886ec13b86a4fe2e0fc16765">__XETLA_API</a> <span class="keywordtype">void</span> <a class="code hl_function" href="structgpu_1_1xetla_1_1group_1_1ln__bwd__fused__op__t_3_01ln__bwd__fused__kind_1_1ln__dropout__gra92c7b1e7d0db3d047617e99aa09b9df.html#a8d86702c150b66c9964aa9985c9dc8b8">init</a>(<a class="code hl_struct" href="structgpu_1_1xetla_1_1group_1_1ln__bwd__fused__op__arguments__t.html">arguments_t</a> *args, uint32_t wg_idx, uint32_t wg_idy,</div>
<div class="line"><a id="l00300" name="l00300"></a><span class="lineno">  300</span>            uint32_t sg_idx, uint32_t sg_idy) {</div>
<div class="line"><a id="l00301" name="l00301"></a><span class="lineno">  301</span>        <span class="keywordtype">int</span> start_n = wg_idx * wg_tile_n + sg_idx * sg_tile_n;</div>
<div class="line"><a id="l00302" name="l00302"></a><span class="lineno">  302</span>        <span class="keywordtype">int</span> start_m = wg_idy * wg_tile_m + sg_idy * sg_tile_m;</div>
<div class="line"><a id="l00303" name="l00303"></a><span class="lineno">  303</span>        mat_ld = args-&gt;<a class="code hl_variable" href="structgpu_1_1xetla_1_1group_1_1ln__bwd__fused__op__arguments__t.html#ac624f186f20fe9a5689e1328ab5693d0">mat_ld</a>;</div>
<div class="line"><a id="l00304" name="l00304"></a><span class="lineno">  304</span>        mask_ld = args-&gt;<a class="code hl_variable" href="structgpu_1_1xetla_1_1group_1_1ln__bwd__fused__op__arguments__t.html#a378369421fe42c7b51b5f9a9e833e916">mask_ld</a>;</div>
<div class="line"><a id="l00305" name="l00305"></a><span class="lineno">  305</span>        matrix_n = args-&gt;<a class="code hl_variable" href="structgpu_1_1xetla_1_1group_1_1ln__bwd__fused__op__arguments__t.html#a5ca6fd69a759b2b68a6f1e047a4486fa">matrix_n</a>;</div>
<div class="line"><a id="l00306" name="l00306"></a><span class="lineno">  306</span>        matrix_m = args-&gt;<a class="code hl_variable" href="structgpu_1_1xetla_1_1group_1_1ln__bwd__fused__op__arguments__t.html#a2bbf0067cd8d0c85039237d7c505c5d6">matrix_m</a>;</div>
<div class="line"><a id="l00307" name="l00307"></a><span class="lineno">  307</span>        grad_in_payload.init(args-&gt;<a class="code hl_variable" href="structgpu_1_1xetla_1_1group_1_1ln__bwd__fused__op__arguments__t.html#aca4e27dedde6f8ecd2aa0462c147344c">gradAdd_ptr</a>, matrix_n, matrix_m, mat_ld,</div>
<div class="line"><a id="l00308" name="l00308"></a><span class="lineno">  308</span>                start_n, start_m);</div>
<div class="line"><a id="l00309" name="l00309"></a><span class="lineno">  309</span>        mask_in_payload.init(</div>
<div class="line"><a id="l00310" name="l00310"></a><span class="lineno">  310</span>                args-&gt;<a class="code hl_variable" href="structgpu_1_1xetla_1_1group_1_1ln__bwd__fused__op__arguments__t.html#a96bc53f94fb970b26468b219769c0968">mask_ptr</a>, matrix_n, matrix_m, mask_ld, start_n, start_m);</div>
<div class="line"><a id="l00311" name="l00311"></a><span class="lineno">  311</span>        dropout_scale_inv = args-&gt;<a class="code hl_variable" href="structgpu_1_1xetla_1_1group_1_1ln__bwd__fused__op__arguments__t.html#a70a67b387d3dd8dfe8fa33ae09716dd0">dropout_scale_inv</a>;</div>
<div class="line"><a id="l00312" name="l00312"></a><span class="lineno">  312</span>        dropout_prob = args-&gt;<a class="code hl_variable" href="structgpu_1_1xetla_1_1group_1_1ln__bwd__fused__op__arguments__t.html#ada068c26ced84797f9772fe202d746f0">dropout_prob</a>;</div>
<div class="line"><a id="l00313" name="l00313"></a><span class="lineno">  313</span>    }</div>
<div class="line"><a id="l00314" name="l00314"></a><span class="lineno">  314</span> </div>
<div class="line"><a id="l00319" name="l00319"></a><span class="lineno"><a class="line" href="structgpu_1_1xetla_1_1group_1_1ln__bwd__fused__op__t_3_01ln__bwd__fused__kind_1_1ln__dropout__gra92c7b1e7d0db3d047617e99aa09b9df.html#a7e72d11bcd92c2b42492cc8ed7ed0927">  319</a></span>    <a class="code hl_define" href="common_2core_2common_8hpp.html#a9ed53999886ec13b86a4fe2e0fc16765">__XETLA_API</a> <a class="code hl_typedef" href="group__xetla__core__base__types.html#ga8cf5d016d24c8870706e20c376287e04">xetla_vector&lt;dtype_acc, sg_tile_n&gt;</a> <a class="code hl_function" href="structgpu_1_1xetla_1_1group_1_1ln__bwd__fused__op__t_3_01ln__bwd__fused__kind_1_1ln__dropout__gra92c7b1e7d0db3d047617e99aa09b9df.html#a7e72d11bcd92c2b42492cc8ed7ed0927">pre_op</a>(</div>
<div class="line"><a id="l00320" name="l00320"></a><span class="lineno">  320</span>            <a class="code hl_typedef" href="group__xetla__core__base__types.html#ga8cf5d016d24c8870706e20c376287e04">xetla_vector&lt;dtype_acc, sg_tile_n&gt;</a> input) {</div>
<div class="line"><a id="l00321" name="l00321"></a><span class="lineno">  321</span>        <a class="code hl_function" href="namespacegpu_1_1xetla_1_1subgroup.html#ae110043dd5332ce2a7ef91d2c8ae79ef">subgroup::tile_load</a>(grad_in, grad_in_payload);</div>
<div class="line"><a id="l00322" name="l00322"></a><span class="lineno">  322</span>        grad_in_payload.update_tdesc(wg_num_m * wg_tile_m * mat_ld);</div>
<div class="line"><a id="l00323" name="l00323"></a><span class="lineno">  323</span>        <a class="code hl_typedef" href="group__xetla__core__base__types.html#ga8cf5d016d24c8870706e20c376287e04">xetla_vector&lt;dtype_acc, sg_tile_n&gt;</a> grad_input</div>
<div class="line"><a id="l00324" name="l00324"></a><span class="lineno">  324</span>                = xetla_cvt&lt;dtype_acc, dtype_in&gt;(grad_in.<a class="code hl_variable" href="structgpu_1_1xetla_1_1subgroup_1_1tile__t.html#a7985ceac15e399ebf3000e5693d8801e">reg</a>);</div>
<div class="line"><a id="l00325" name="l00325"></a><span class="lineno">  325</span>        <span class="comment">// grad_add</span></div>
<div class="line"><a id="l00326" name="l00326"></a><span class="lineno">  326</span>        <a class="code hl_typedef" href="group__xetla__core__base__types.html#ga8cf5d016d24c8870706e20c376287e04">xetla_vector&lt;dtype_acc, sg_tile_n&gt;</a> output</div>
<div class="line"><a id="l00327" name="l00327"></a><span class="lineno">  327</span>                = reduce_helper&lt;reduce_op::sum, dtype_acc, sg_tile_n&gt;(</div>
<div class="line"><a id="l00328" name="l00328"></a><span class="lineno">  328</span>                        input, grad_input);</div>
<div class="line"><a id="l00329" name="l00329"></a><span class="lineno">  329</span>        <span class="keywordflow">if</span> (dropout_prob != 0) {</div>
<div class="line"><a id="l00330" name="l00330"></a><span class="lineno">  330</span>            <span class="comment">// dropout</span></div>
<div class="line"><a id="l00331" name="l00331"></a><span class="lineno">  331</span>            <a class="code hl_function" href="namespacegpu_1_1xetla_1_1subgroup.html#ae110043dd5332ce2a7ef91d2c8ae79ef">subgroup::tile_load</a>(mask_in, mask_in_payload);</div>
<div class="line"><a id="l00332" name="l00332"></a><span class="lineno">  332</span>            <a class="code hl_define" href="common_2core_2common_8hpp.html#a4894ef2f787a454434527ed8416177d9">SW_BARRIER</a>();</div>
<div class="line"><a id="l00333" name="l00333"></a><span class="lineno">  333</span>            mask_in_payload.update_tdesc(wg_num_m * wg_tile_m * mask_ld);</div>
<div class="line"><a id="l00334" name="l00334"></a><span class="lineno">  334</span>            output = drop_out&lt;dtype_acc, sg_tile_n&gt;(</div>
<div class="line"><a id="l00335" name="l00335"></a><span class="lineno">  335</span>                    output, mask_in.<a class="code hl_variable" href="structgpu_1_1xetla_1_1subgroup_1_1tile__t.html#a7985ceac15e399ebf3000e5693d8801e">reg</a>, dropout_scale_inv);</div>
<div class="line"><a id="l00336" name="l00336"></a><span class="lineno">  336</span>        }</div>
<div class="line"><a id="l00337" name="l00337"></a><span class="lineno">  337</span>        <span class="keywordflow">return</span> output;</div>
<div class="line"><a id="l00338" name="l00338"></a><span class="lineno">  338</span>    }</div>
<div class="line"><a id="l00339" name="l00339"></a><span class="lineno">  339</span> </div>
<div class="line"><a id="l00344" name="l00344"></a><span class="lineno"><a class="line" href="structgpu_1_1xetla_1_1group_1_1ln__bwd__fused__op__t_3_01ln__bwd__fused__kind_1_1ln__dropout__gra92c7b1e7d0db3d047617e99aa09b9df.html#ae043679a0bd25c90b2b28b43bd1235f0">  344</a></span>    <a class="code hl_define" href="common_2core_2common_8hpp.html#a9ed53999886ec13b86a4fe2e0fc16765">__XETLA_API</a> <a class="code hl_typedef" href="group__xetla__core__base__types.html#ga8cf5d016d24c8870706e20c376287e04">xetla_vector&lt;dtype_acc, sg_tile_n&gt;</a> <a class="code hl_function" href="structgpu_1_1xetla_1_1group_1_1ln__bwd__fused__op__t_3_01ln__bwd__fused__kind_1_1ln__dropout__gra92c7b1e7d0db3d047617e99aa09b9df.html#ae043679a0bd25c90b2b28b43bd1235f0">post_op</a>(</div>
<div class="line"><a id="l00345" name="l00345"></a><span class="lineno">  345</span>            <a class="code hl_typedef" href="group__xetla__core__base__types.html#ga8cf5d016d24c8870706e20c376287e04">xetla_vector&lt;dtype_acc, sg_tile_n&gt;</a> input) {</div>
<div class="line"><a id="l00346" name="l00346"></a><span class="lineno">  346</span>        <span class="keywordflow">return</span> input;</div>
<div class="line"><a id="l00347" name="l00347"></a><span class="lineno">  347</span>    }</div>
<div class="line"><a id="l00348" name="l00348"></a><span class="lineno">  348</span> </div>
<div class="line"><a id="l00354" name="l00354"></a><span class="lineno">  354</span>    <span class="keyword">template</span> &lt;<span class="keyword">typename</span> reduce_t&gt;</div>
<div class="line"><a id="l00355" name="l00355"></a><span class="lineno"><a class="line" href="structgpu_1_1xetla_1_1group_1_1ln__bwd__fused__op__t_3_01ln__bwd__fused__kind_1_1ln__dropout__gra92c7b1e7d0db3d047617e99aa09b9df.html#af151883a5375464a4a74bfd1ccc89253">  355</a></span>    <a class="code hl_define" href="common_2core_2common_8hpp.html#a9ed53999886ec13b86a4fe2e0fc16765">__XETLA_API</a> <span class="keywordtype">void</span> <a class="code hl_function" href="structgpu_1_1xetla_1_1group_1_1ln__bwd__fused__op__t_3_01ln__bwd__fused__kind_1_1ln__dropout__gra92c7b1e7d0db3d047617e99aa09b9df.html#af151883a5375464a4a74bfd1ccc89253">final_op</a>(reduce_t &amp;ln_group_row_reduce) {}</div>
<div class="line"><a id="l00356" name="l00356"></a><span class="lineno">  356</span>};</div>
<div class="line"><a id="l00357" name="l00357"></a><span class="lineno">  357</span> </div>
<div class="line"><a id="l00364" name="l00364"></a><span class="lineno">  364</span><span class="keyword">template</span> &lt;<span class="keyword">typename</span> dtype_in_, <span class="keyword">typename</span> dtype_out_, <span class="keyword">typename</span> dtype_acc_,</div>
<div class="line"><a id="l00365" name="l00365"></a><span class="lineno">  365</span>        <span class="keyword">typename</span> layer_norm_attr_&gt;</div>
<div class="line"><a id="l00366" name="l00366"></a><span class="lineno"><a class="line" href="structgpu_1_1xetla_1_1group_1_1ln__bwd__fused__op__t_3_01ln__bwd__fused__kind_1_1ln__dropout_00_85855d35f221cf3a31c3a01f77253cdf.html">  366</a></span><span class="keyword">struct </span><a class="code hl_struct" href="structgpu_1_1xetla_1_1group_1_1ln__bwd__fused__op__t.html">ln_bwd_fused_op_t</a>&lt;<a class="code hl_enumeration" href="namespacegpu_1_1xetla.html#aacf5f0d7a8241d58320b4a95e0f7592b">ln_bwd_fused_kind</a>::<a class="code hl_enumvalue" href="namespacegpu_1_1xetla.html#a71633e89354f0f1d0badcd0d90dea7ecad1094c3e2379e1803e554066186e1c19">ln_dropout</a>, dtype_in_, dtype_out_,</div>
<div class="line"><a id="l00367" name="l00367"></a><span class="lineno">  367</span>        dtype_acc_, layer_norm_attr_, <a class="code hl_enumvalue" href="namespacegpu_1_1xetla.html#aa5a2713edb27d6fed88a3c61673556f1a8fde9df1bf2567b76160d1beedca3130">gpu_arch::Xe</a>&gt; {</div>
<div class="line"><a id="l00368" name="l00368"></a><span class="lineno"><a class="line" href="structgpu_1_1xetla_1_1group_1_1ln__bwd__fused__op__t_3_01ln__bwd__fused__kind_1_1ln__dropout_00_85855d35f221cf3a31c3a01f77253cdf.html#a463ea0e31650888d348ef63cdf7c91e3">  368</a></span>    <span class="keyword">static</span> <span class="keyword">constexpr</span> <a class="code hl_enumeration" href="namespacegpu_1_1xetla.html#aacf5f0d7a8241d58320b4a95e0f7592b">ln_bwd_fused_kind</a> fused_op_kind</div>
<div class="line"><a id="l00369" name="l00369"></a><span class="lineno">  369</span>            = <a class="code hl_enumvalue" href="namespacegpu_1_1xetla.html#aacf5f0d7a8241d58320b4a95e0f7592bad1094c3e2379e1803e554066186e1c19">ln_bwd_fused_kind::ln_dropout</a>;</div>
<div class="line"><a id="l00370" name="l00370"></a><span class="lineno"><a class="line" href="structgpu_1_1xetla_1_1group_1_1ln__bwd__fused__op__t_3_01ln__bwd__fused__kind_1_1ln__dropout_00_85855d35f221cf3a31c3a01f77253cdf.html#a6b0f47b6a7a46afe9379a89782233d00">  370</a></span>    <span class="keyword">using </span><a class="code hl_typedef" href="structgpu_1_1xetla_1_1group_1_1ln__bwd__fused__op__t_3_01ln__bwd__fused__kind_1_1ln__dropout_00_85855d35f221cf3a31c3a01f77253cdf.html#a6b0f47b6a7a46afe9379a89782233d00">dtype_acc</a> = dtype_acc_;</div>
<div class="line"><a id="l00371" name="l00371"></a><span class="lineno"><a class="line" href="structgpu_1_1xetla_1_1group_1_1ln__bwd__fused__op__t_3_01ln__bwd__fused__kind_1_1ln__dropout_00_85855d35f221cf3a31c3a01f77253cdf.html#a176cd45202a9b5342d53455cf41407ee">  371</a></span>    <span class="keyword">using </span><a class="code hl_typedef" href="structgpu_1_1xetla_1_1group_1_1ln__bwd__fused__op__t_3_01ln__bwd__fused__kind_1_1ln__dropout_00_85855d35f221cf3a31c3a01f77253cdf.html#a176cd45202a9b5342d53455cf41407ee">dtype_in</a> = dtype_in_;</div>
<div class="line"><a id="l00372" name="l00372"></a><span class="lineno"><a class="line" href="structgpu_1_1xetla_1_1group_1_1ln__bwd__fused__op__t_3_01ln__bwd__fused__kind_1_1ln__dropout_00_85855d35f221cf3a31c3a01f77253cdf.html#a098ccb24a216b344cfad68624d7aea22">  372</a></span>    <span class="keyword">using </span><a class="code hl_typedef" href="structgpu_1_1xetla_1_1group_1_1ln__bwd__fused__op__t_3_01ln__bwd__fused__kind_1_1ln__dropout_00_85855d35f221cf3a31c3a01f77253cdf.html#a098ccb24a216b344cfad68624d7aea22">dtype_out</a> = dtype_out_;</div>
<div class="line"><a id="l00373" name="l00373"></a><span class="lineno"><a class="line" href="structgpu_1_1xetla_1_1group_1_1ln__bwd__fused__op__t_3_01ln__bwd__fused__kind_1_1ln__dropout_00_85855d35f221cf3a31c3a01f77253cdf.html#a695e3be9e1ce2f741386e4b9acf62080">  373</a></span>    <span class="keyword">using </span><a class="code hl_typedef" href="structgpu_1_1xetla_1_1group_1_1ln__bwd__fused__op__t_3_01ln__bwd__fused__kind_1_1ln__dropout_00_85855d35f221cf3a31c3a01f77253cdf.html#a695e3be9e1ce2f741386e4b9acf62080">dtype_mask</a> = uint8_t;</div>
<div class="line"><a id="l00374" name="l00374"></a><span class="lineno"><a class="line" href="structgpu_1_1xetla_1_1group_1_1ln__bwd__fused__op__t_3_01ln__bwd__fused__kind_1_1ln__dropout_00_85855d35f221cf3a31c3a01f77253cdf.html#ad683dae61981e9de697cf7a02dd263b5">  374</a></span>    <span class="keyword">using </span><a class="code hl_struct" href="structgpu_1_1xetla_1_1group_1_1ln__bwd__fused__op__arguments__t.html">arguments_t</a></div>
<div class="line"><a id="l00375" name="l00375"></a><span class="lineno">  375</span>            = <a class="code hl_struct" href="structgpu_1_1xetla_1_1group_1_1ln__bwd__fused__op__arguments__t.html">ln_bwd_fused_op_arguments_t&lt;dtype_in, dtype_out, dtype_acc&gt;</a>;</div>
<div class="line"><a id="l00376" name="l00376"></a><span class="lineno"><a class="line" href="structgpu_1_1xetla_1_1group_1_1ln__bwd__fused__op__t_3_01ln__bwd__fused__kind_1_1ln__dropout_00_85855d35f221cf3a31c3a01f77253cdf.html#ae98d5bb249141319ea5026f5fd64210d">  376</a></span>    <span class="keyword">static</span> <span class="keyword">constexpr</span> uint32_t wg_tile_m = layer_norm_attr_::wg_tile_m;</div>
<div class="line"><a id="l00377" name="l00377"></a><span class="lineno"><a class="line" href="structgpu_1_1xetla_1_1group_1_1ln__bwd__fused__op__t_3_01ln__bwd__fused__kind_1_1ln__dropout_00_85855d35f221cf3a31c3a01f77253cdf.html#ac5d692428f76cd33283895518f404643">  377</a></span>    <span class="keyword">static</span> <span class="keyword">constexpr</span> uint32_t wg_tile_n = layer_norm_attr_::wg_tile_n;</div>
<div class="line"><a id="l00378" name="l00378"></a><span class="lineno"><a class="line" href="structgpu_1_1xetla_1_1group_1_1ln__bwd__fused__op__t_3_01ln__bwd__fused__kind_1_1ln__dropout_00_85855d35f221cf3a31c3a01f77253cdf.html#a42561da1e04d6f25015a94b110055f8e">  378</a></span>    <span class="keyword">static</span> <span class="keyword">constexpr</span> uint32_t sg_tile_m = layer_norm_attr_::sg_tile_m;</div>
<div class="line"><a id="l00379" name="l00379"></a><span class="lineno"><a class="line" href="structgpu_1_1xetla_1_1group_1_1ln__bwd__fused__op__t_3_01ln__bwd__fused__kind_1_1ln__dropout_00_85855d35f221cf3a31c3a01f77253cdf.html#aca215c85a2b26c73c2818d55ed1e1da2">  379</a></span>    <span class="keyword">static</span> <span class="keyword">constexpr</span> uint32_t sg_tile_n = layer_norm_attr_::sg_tile_n;</div>
<div class="line"><a id="l00380" name="l00380"></a><span class="lineno"><a class="line" href="structgpu_1_1xetla_1_1group_1_1ln__bwd__fused__op__t_3_01ln__bwd__fused__kind_1_1ln__dropout_00_85855d35f221cf3a31c3a01f77253cdf.html#a7d26c19a1a7574d435dabce3a7b38b20">  380</a></span>    <span class="keyword">static</span> <span class="keyword">constexpr</span> uint32_t wg_num_m = layer_norm_attr_::wg_num_m;</div>
<div class="line"><a id="l00381" name="l00381"></a><span class="lineno"><a class="line" href="structgpu_1_1xetla_1_1group_1_1ln__bwd__fused__op__t_3_01ln__bwd__fused__kind_1_1ln__dropout_00_85855d35f221cf3a31c3a01f77253cdf.html#a34ad273c33ddc845ee94b889d72adfa5">  381</a></span>    <span class="keyword">static</span> <span class="keyword">constexpr</span> uint32_t wg_num_n = layer_norm_attr_::wg_num_n;</div>
<div class="line"><a id="l00382" name="l00382"></a><span class="lineno">  382</span> </div>
<div class="line"><a id="l00383" name="l00383"></a><span class="lineno"><a class="line" href="structgpu_1_1xetla_1_1group_1_1ln__bwd__fused__op__t_3_01ln__bwd__fused__kind_1_1ln__dropout_00_85855d35f221cf3a31c3a01f77253cdf.html#a10dca4ef801871fbf67d5288ab23f78f">  383</a></span>    <span class="keyword">static</span> <span class="keyword">constexpr</span> uint32_t wg_size_x</div>
<div class="line"><a id="l00384" name="l00384"></a><span class="lineno">  384</span>            = (wg_tile_n + sg_tile_n - 1) / sg_tile_n;</div>
<div class="line"><a id="l00385" name="l00385"></a><span class="lineno"><a class="line" href="structgpu_1_1xetla_1_1group_1_1ln__bwd__fused__op__t_3_01ln__bwd__fused__kind_1_1ln__dropout_00_85855d35f221cf3a31c3a01f77253cdf.html#a9a9cae9fbd888447beb7f3d505c31d9c">  385</a></span>    <span class="keyword">static</span> <span class="keyword">constexpr</span> uint32_t wg_size_y</div>
<div class="line"><a id="l00386" name="l00386"></a><span class="lineno">  386</span>            = (wg_tile_m + sg_tile_m - 1) / sg_tile_m;</div>
<div class="line"><a id="l00387" name="l00387"></a><span class="lineno"><a class="line" href="structgpu_1_1xetla_1_1group_1_1ln__bwd__fused__op__t_3_01ln__bwd__fused__kind_1_1ln__dropout_00_85855d35f221cf3a31c3a01f77253cdf.html#ac456eddb4356cc742b2160c0090e2c21">  387</a></span>    <span class="keyword">using </span><a class="code hl_struct" href="structgpu_1_1xetla_1_1subgroup_1_1tile__desc__t.html">ln_bwd_tile_desc_t</a> = <a class="code hl_struct" href="structgpu_1_1xetla_1_1subgroup_1_1tile__desc__t.html">subgroup::tile_desc_t</a>&lt;sg_tile_n, 1, sg_tile_n, 1,</div>
<div class="line"><a id="l00388" name="l00388"></a><span class="lineno">  388</span>            <a class="code hl_enumvalue" href="namespacegpu_1_1xetla.html#a51137fd81d0d9d2156525a1e279432aaa78506882d645395a052df8b01a927395">reg_layout::tiled</a>&gt;;</div>
<div class="line"><a id="l00389" name="l00389"></a><span class="lineno"><a class="line" href="structgpu_1_1xetla_1_1group_1_1ln__bwd__fused__op__t_3_01ln__bwd__fused__kind_1_1ln__dropout_00_85855d35f221cf3a31c3a01f77253cdf.html#a2c5417020aec6e7039b3cd9d01abe91e">  389</a></span>    <span class="keyword">using </span><a class="code hl_class" href="structgpu_1_1xetla_1_1subgroup_1_1tile__t.html">mask_in_t</a> = <a class="code hl_struct" href="structgpu_1_1xetla_1_1subgroup_1_1tile__t.html">subgroup::tile_t&lt;dtype_mask, ln_bwd_tile_desc_t&gt;</a>;</div>
<div class="line"><a id="l00390" name="l00390"></a><span class="lineno"><a class="line" href="structgpu_1_1xetla_1_1group_1_1ln__bwd__fused__op__t_3_01ln__bwd__fused__kind_1_1ln__dropout_00_85855d35f221cf3a31c3a01f77253cdf.html#aa7de3708210c9577730049eb30ddb583">  390</a></span>    <span class="keyword">using </span><a class="code hl_class" href="structgpu_1_1xetla_1_1subgroup_1_1mem__payload__t.html">mask_in_payload_t</a> = <a class="code hl_struct" href="structgpu_1_1xetla_1_1subgroup_1_1mem__payload__t.html">subgroup::mem_payload_t</a>&lt;</div>
<div class="line"><a id="l00391" name="l00391"></a><span class="lineno">  391</span>            <a class="code hl_struct" href="structgpu_1_1xetla_1_1mem__desc__t.html">mem_desc_t&lt;dtype_mask, mem_layout::row_major, mem_space::global&gt;</a>,</div>
<div class="line"><a id="l00392" name="l00392"></a><span class="lineno">  392</span>            <a class="code hl_struct" href="structgpu_1_1xetla_1_1subgroup_1_1tile__desc__t.html">ln_bwd_tile_desc_t</a>, <a class="code hl_enumvalue" href="namespacegpu_1_1xetla.html#aa8afe1d12e7777419fb6ea09534a0aa7a5baf9a1aba8e4b6fa44c20aafacc4233">msg_type::block_1d</a>, <a class="code hl_enumvalue" href="namespacegpu_1_1xetla.html#aa5a2713edb27d6fed88a3c61673556f1a8fde9df1bf2567b76160d1beedca3130">gpu_arch::Xe</a>&gt;;</div>
<div class="line"><a id="l00393" name="l00393"></a><span class="lineno">  393</span> </div>
<div class="line"><a id="l00394" name="l00394"></a><span class="lineno"><a class="line" href="structgpu_1_1xetla_1_1group_1_1ln__bwd__fused__op__t_3_01ln__bwd__fused__kind_1_1ln__dropout_00_85855d35f221cf3a31c3a01f77253cdf.html#a3ee3c9e2b20d0e2f74235ece070dd21b">  394</a></span>    <a class="code hl_class" href="structgpu_1_1xetla_1_1subgroup_1_1tile__t.html">mask_in_t</a> <a class="code hl_variable" href="structgpu_1_1xetla_1_1group_1_1ln__bwd__fused__op__t_3_01ln__bwd__fused__kind_1_1ln__dropout_00_85855d35f221cf3a31c3a01f77253cdf.html#a3ee3c9e2b20d0e2f74235ece070dd21b">mask_in</a>;</div>
<div class="line"><a id="l00395" name="l00395"></a><span class="lineno"><a class="line" href="structgpu_1_1xetla_1_1group_1_1ln__bwd__fused__op__t_3_01ln__bwd__fused__kind_1_1ln__dropout_00_85855d35f221cf3a31c3a01f77253cdf.html#a16bfb1ebfaeb1cc445d4f8121f0ac365">  395</a></span>    <a class="code hl_class" href="structgpu_1_1xetla_1_1subgroup_1_1mem__payload__t.html">mask_in_payload_t</a> <a class="code hl_variable" href="structgpu_1_1xetla_1_1group_1_1ln__bwd__fused__op__t_3_01ln__bwd__fused__kind_1_1ln__dropout_00_85855d35f221cf3a31c3a01f77253cdf.html#a16bfb1ebfaeb1cc445d4f8121f0ac365">mask_in_payload</a>;</div>
<div class="line"><a id="l00396" name="l00396"></a><span class="lineno"><a class="line" href="structgpu_1_1xetla_1_1group_1_1ln__bwd__fused__op__t_3_01ln__bwd__fused__kind_1_1ln__dropout_00_85855d35f221cf3a31c3a01f77253cdf.html#a8589d14180a7c8e2728118eb93428130">  396</a></span>    uint32_t <a class="code hl_variable" href="structgpu_1_1xetla_1_1group_1_1ln__bwd__fused__op__t_3_01ln__bwd__fused__kind_1_1ln__dropout_00_85855d35f221cf3a31c3a01f77253cdf.html#a8589d14180a7c8e2728118eb93428130">matrix_n</a>;</div>
<div class="line"><a id="l00397" name="l00397"></a><span class="lineno"><a class="line" href="structgpu_1_1xetla_1_1group_1_1ln__bwd__fused__op__t_3_01ln__bwd__fused__kind_1_1ln__dropout_00_85855d35f221cf3a31c3a01f77253cdf.html#a846eac9f54bd658266b5a9ba969ee0d7">  397</a></span>    uint32_t <a class="code hl_variable" href="structgpu_1_1xetla_1_1group_1_1ln__bwd__fused__op__t_3_01ln__bwd__fused__kind_1_1ln__dropout_00_85855d35f221cf3a31c3a01f77253cdf.html#a846eac9f54bd658266b5a9ba969ee0d7">matrix_m</a>;</div>
<div class="line"><a id="l00398" name="l00398"></a><span class="lineno"><a class="line" href="structgpu_1_1xetla_1_1group_1_1ln__bwd__fused__op__t_3_01ln__bwd__fused__kind_1_1ln__dropout_00_85855d35f221cf3a31c3a01f77253cdf.html#ad8da53f4632280965ac0851f2ef09769">  398</a></span>    uint32_t <a class="code hl_variable" href="structgpu_1_1xetla_1_1group_1_1ln__bwd__fused__op__t_3_01ln__bwd__fused__kind_1_1ln__dropout_00_85855d35f221cf3a31c3a01f77253cdf.html#ad8da53f4632280965ac0851f2ef09769">mask_ld</a>;</div>
<div class="line"><a id="l00399" name="l00399"></a><span class="lineno"><a class="line" href="structgpu_1_1xetla_1_1group_1_1ln__bwd__fused__op__t_3_01ln__bwd__fused__kind_1_1ln__dropout_00_85855d35f221cf3a31c3a01f77253cdf.html#abf87d6ca5f9c310c430039ab47e3e217">  399</a></span>    <span class="keywordtype">float</span> <a class="code hl_variable" href="structgpu_1_1xetla_1_1group_1_1ln__bwd__fused__op__t_3_01ln__bwd__fused__kind_1_1ln__dropout_00_85855d35f221cf3a31c3a01f77253cdf.html#abf87d6ca5f9c310c430039ab47e3e217">dropout_scale_inv</a>;</div>
<div class="line"><a id="l00400" name="l00400"></a><span class="lineno">  400</span> </div>
<div class="line"><a id="l00409" name="l00409"></a><span class="lineno"><a class="line" href="structgpu_1_1xetla_1_1group_1_1ln__bwd__fused__op__t_3_01ln__bwd__fused__kind_1_1ln__dropout_00_85855d35f221cf3a31c3a01f77253cdf.html#ac2769443a9bf87b85e79adbc584ded2c">  409</a></span>    <a class="code hl_define" href="common_2core_2common_8hpp.html#a9ed53999886ec13b86a4fe2e0fc16765">__XETLA_API</a> <span class="keywordtype">void</span> <a class="code hl_function" href="structgpu_1_1xetla_1_1group_1_1ln__bwd__fused__op__t_3_01ln__bwd__fused__kind_1_1ln__dropout_00_85855d35f221cf3a31c3a01f77253cdf.html#ac2769443a9bf87b85e79adbc584ded2c">init</a>(<a class="code hl_struct" href="structgpu_1_1xetla_1_1group_1_1ln__bwd__fused__op__arguments__t.html">arguments_t</a> *args, uint32_t wg_idx, uint32_t wg_idy,</div>
<div class="line"><a id="l00410" name="l00410"></a><span class="lineno">  410</span>            uint32_t sg_idx, uint32_t sg_idy) {</div>
<div class="line"><a id="l00411" name="l00411"></a><span class="lineno">  411</span>        <span class="keywordtype">int</span> start_m = wg_idy * wg_tile_m + sg_idy * sg_tile_m;</div>
<div class="line"><a id="l00412" name="l00412"></a><span class="lineno">  412</span>        <span class="keywordtype">int</span> start_n = wg_idx * wg_tile_n + sg_idx * sg_tile_n;</div>
<div class="line"><a id="l00413" name="l00413"></a><span class="lineno">  413</span>        mask_ld = args-&gt;<a class="code hl_variable" href="structgpu_1_1xetla_1_1group_1_1ln__bwd__fused__op__arguments__t.html#a378369421fe42c7b51b5f9a9e833e916">mask_ld</a>;</div>
<div class="line"><a id="l00414" name="l00414"></a><span class="lineno">  414</span>        matrix_m = args-&gt;<a class="code hl_variable" href="structgpu_1_1xetla_1_1group_1_1ln__bwd__fused__op__arguments__t.html#a2bbf0067cd8d0c85039237d7c505c5d6">matrix_m</a>;</div>
<div class="line"><a id="l00415" name="l00415"></a><span class="lineno">  415</span>        matrix_n = args-&gt;<a class="code hl_variable" href="structgpu_1_1xetla_1_1group_1_1ln__bwd__fused__op__arguments__t.html#a5ca6fd69a759b2b68a6f1e047a4486fa">matrix_n</a>;</div>
<div class="line"><a id="l00416" name="l00416"></a><span class="lineno">  416</span>        mask_in_payload.init(</div>
<div class="line"><a id="l00417" name="l00417"></a><span class="lineno">  417</span>                args-&gt;<a class="code hl_variable" href="structgpu_1_1xetla_1_1group_1_1ln__bwd__fused__op__arguments__t.html#a96bc53f94fb970b26468b219769c0968">mask_ptr</a>, matrix_n, matrix_m, mask_ld, start_n, start_m);</div>
<div class="line"><a id="l00418" name="l00418"></a><span class="lineno">  418</span>        dropout_scale_inv = args-&gt;<a class="code hl_variable" href="structgpu_1_1xetla_1_1group_1_1ln__bwd__fused__op__arguments__t.html#a70a67b387d3dd8dfe8fa33ae09716dd0">dropout_scale_inv</a>;</div>
<div class="line"><a id="l00419" name="l00419"></a><span class="lineno">  419</span>    }</div>
<div class="line"><a id="l00420" name="l00420"></a><span class="lineno">  420</span> </div>
<div class="line"><a id="l00425" name="l00425"></a><span class="lineno"><a class="line" href="structgpu_1_1xetla_1_1group_1_1ln__bwd__fused__op__t_3_01ln__bwd__fused__kind_1_1ln__dropout_00_85855d35f221cf3a31c3a01f77253cdf.html#ab6daddc16a3d1ce2354a88ae73f034f5">  425</a></span>    <a class="code hl_define" href="common_2core_2common_8hpp.html#a9ed53999886ec13b86a4fe2e0fc16765">__XETLA_API</a> <a class="code hl_typedef" href="group__xetla__core__base__types.html#ga8cf5d016d24c8870706e20c376287e04">xetla_vector&lt;dtype_acc, sg_tile_n&gt;</a> <a class="code hl_function" href="structgpu_1_1xetla_1_1group_1_1ln__bwd__fused__op__t_3_01ln__bwd__fused__kind_1_1ln__dropout_00_85855d35f221cf3a31c3a01f77253cdf.html#ab6daddc16a3d1ce2354a88ae73f034f5">pre_op</a>(</div>
<div class="line"><a id="l00426" name="l00426"></a><span class="lineno">  426</span>            <a class="code hl_typedef" href="group__xetla__core__base__types.html#ga8cf5d016d24c8870706e20c376287e04">xetla_vector&lt;dtype_acc, sg_tile_n&gt;</a> input) {</div>
<div class="line"><a id="l00427" name="l00427"></a><span class="lineno">  427</span>        <a class="code hl_typedef" href="group__xetla__core__base__types.html#ga8cf5d016d24c8870706e20c376287e04">xetla_vector&lt;dtype_acc, sg_tile_n&gt;</a> output;</div>
<div class="line"><a id="l00428" name="l00428"></a><span class="lineno">  428</span>        <span class="comment">// dropout</span></div>
<div class="line"><a id="l00429" name="l00429"></a><span class="lineno">  429</span>        <a class="code hl_function" href="namespacegpu_1_1xetla_1_1subgroup.html#ae110043dd5332ce2a7ef91d2c8ae79ef">subgroup::tile_load</a>(mask_in, mask_in_payload);</div>
<div class="line"><a id="l00430" name="l00430"></a><span class="lineno">  430</span>        <a class="code hl_define" href="common_2core_2common_8hpp.html#a4894ef2f787a454434527ed8416177d9">SW_BARRIER</a>();</div>
<div class="line"><a id="l00431" name="l00431"></a><span class="lineno">  431</span>        mask_in_payload.update_tdesc(wg_num_m * wg_tile_m * mask_ld);</div>
<div class="line"><a id="l00432" name="l00432"></a><span class="lineno">  432</span>        output = drop_out&lt;dtype_acc, sg_tile_n&gt;(</div>
<div class="line"><a id="l00433" name="l00433"></a><span class="lineno">  433</span>                input, mask_in.<a class="code hl_variable" href="structgpu_1_1xetla_1_1subgroup_1_1tile__t.html#a7985ceac15e399ebf3000e5693d8801e">reg</a>, dropout_scale_inv);</div>
<div class="line"><a id="l00434" name="l00434"></a><span class="lineno">  434</span>        <span class="keywordflow">return</span> output;</div>
<div class="line"><a id="l00435" name="l00435"></a><span class="lineno">  435</span>    }</div>
<div class="line"><a id="l00436" name="l00436"></a><span class="lineno">  436</span> </div>
<div class="line"><a id="l00441" name="l00441"></a><span class="lineno"><a class="line" href="structgpu_1_1xetla_1_1group_1_1ln__bwd__fused__op__t_3_01ln__bwd__fused__kind_1_1ln__dropout_00_85855d35f221cf3a31c3a01f77253cdf.html#aedae55dcbefb0e1310397e1c84bb15b1">  441</a></span>    <a class="code hl_define" href="common_2core_2common_8hpp.html#a9ed53999886ec13b86a4fe2e0fc16765">__XETLA_API</a> <a class="code hl_typedef" href="group__xetla__core__base__types.html#ga8cf5d016d24c8870706e20c376287e04">xetla_vector&lt;dtype_acc, sg_tile_n&gt;</a> <a class="code hl_function" href="structgpu_1_1xetla_1_1group_1_1ln__bwd__fused__op__t_3_01ln__bwd__fused__kind_1_1ln__dropout_00_85855d35f221cf3a31c3a01f77253cdf.html#aedae55dcbefb0e1310397e1c84bb15b1">post_op</a>(</div>
<div class="line"><a id="l00442" name="l00442"></a><span class="lineno">  442</span>            <a class="code hl_typedef" href="group__xetla__core__base__types.html#ga8cf5d016d24c8870706e20c376287e04">xetla_vector&lt;dtype_acc, sg_tile_n&gt;</a> input) {</div>
<div class="line"><a id="l00443" name="l00443"></a><span class="lineno">  443</span>        <span class="keywordflow">return</span> input;</div>
<div class="line"><a id="l00444" name="l00444"></a><span class="lineno">  444</span>    }</div>
<div class="line"><a id="l00445" name="l00445"></a><span class="lineno">  445</span> </div>
<div class="line"><a id="l00451" name="l00451"></a><span class="lineno">  451</span>    <span class="keyword">template</span> &lt;<span class="keyword">typename</span> reduce_t&gt;</div>
<div class="line"><a id="l00452" name="l00452"></a><span class="lineno"><a class="line" href="structgpu_1_1xetla_1_1group_1_1ln__bwd__fused__op__t_3_01ln__bwd__fused__kind_1_1ln__dropout_00_85855d35f221cf3a31c3a01f77253cdf.html#ac9feb1b4130f3783870e38fd732865d8">  452</a></span>    <a class="code hl_define" href="common_2core_2common_8hpp.html#a9ed53999886ec13b86a4fe2e0fc16765">__XETLA_API</a> <span class="keywordtype">void</span> <a class="code hl_function" href="structgpu_1_1xetla_1_1group_1_1ln__bwd__fused__op__t_3_01ln__bwd__fused__kind_1_1ln__dropout_00_85855d35f221cf3a31c3a01f77253cdf.html#ac9feb1b4130f3783870e38fd732865d8">final_op</a>(reduce_t &amp;ln_group_row_reduce) {}</div>
<div class="line"><a id="l00453" name="l00453"></a><span class="lineno">  453</span>};</div>
<div class="line"><a id="l00454" name="l00454"></a><span class="lineno">  454</span> </div>
<div class="line"><a id="l00455" name="l00455"></a><span class="lineno">  455</span>} <span class="comment">// namespace gpu::xetla::group</span></div>
<div class="ttc" id="acommon_2core_2common_8hpp_html_a4894ef2f787a454434527ed8416177d9"><div class="ttname"><a href="common_2core_2common_8hpp.html#a4894ef2f787a454434527ed8416177d9">SW_BARRIER</a></div><div class="ttdeci">#define SW_BARRIER()</div><div class="ttdoc">SW_BARRIER, insert software scheduling barrier, for better code control.</div><div class="ttdef"><b>Definition</b> common.hpp:227</div></div>
<div class="ttc" id="acommon_2core_2common_8hpp_html_a9ed53999886ec13b86a4fe2e0fc16765"><div class="ttname"><a href="common_2core_2common_8hpp.html#a9ed53999886ec13b86a4fe2e0fc16765">__XETLA_API</a></div><div class="ttdeci">#define __XETLA_API</div><div class="ttdef"><b>Definition</b> common.hpp:43</div></div>
<div class="ttc" id="agroup__xetla__core__base__types_html_ga8cf5d016d24c8870706e20c376287e04"><div class="ttname"><a href="group__xetla__core__base__types.html#ga8cf5d016d24c8870706e20c376287e04">gpu::xetla::xetla_vector</a></div><div class="ttdeci">__ESIMD_NS::simd&lt; native_type_t&lt; Ty &gt;, N &gt; xetla_vector</div><div class="ttdoc">wrapper for xetla_vector.</div><div class="ttdef"><b>Definition</b> base_types.hpp:149</div></div>
<div class="ttc" id="alayer__norm__fused__op__api_8hpp_html"><div class="ttname"><a href="layer__norm__fused__op__api_8hpp.html">layer_norm_fused_op_api.hpp</a></div><div class="ttdoc">C++ API.</div></div>
<div class="ttc" id="anamespacegpu_1_1xetla_1_1group_html"><div class="ttname"><a href="namespacegpu_1_1xetla_1_1group.html">gpu::xetla::group</a></div><div class="ttdef"><b>Definition</b> limitation.hpp:607</div></div>
<div class="ttc" id="anamespacegpu_1_1xetla_1_1subgroup_html_ae110043dd5332ce2a7ef91d2c8ae79ef"><div class="ttname"><a href="namespacegpu_1_1xetla_1_1subgroup.html#ae110043dd5332ce2a7ef91d2c8ae79ef">gpu::xetla::subgroup::tile_load</a></div><div class="ttdeci">__XETLA_API std::enable_if_t&lt; detail::check_load_type&lt; tile_t, payload_t &gt;::is_global_2d_xe &gt; tile_load(tile_t &amp;tile, payload_t &amp;payload)</div><div class="ttdoc">This function loads data from 2D memory surface.</div><div class="ttdef"><b>Definition</b> load_xe.hpp:76</div></div>
<div class="ttc" id="anamespacegpu_1_1xetla_html_a51137fd81d0d9d2156525a1e279432aaa78506882d645395a052df8b01a927395"><div class="ttname"><a href="namespacegpu_1_1xetla.html#a51137fd81d0d9d2156525a1e279432aaa78506882d645395a052df8b01a927395">gpu::xetla::reg_layout::tiled</a></div><div class="ttdeci">@ tiled</div></div>
<div class="ttc" id="anamespacegpu_1_1xetla_html_a71633e89354f0f1d0badcd0d90dea7eca50054c633c718e5b1c128c96ba1853ee"><div class="ttname"><a href="namespacegpu_1_1xetla.html#a71633e89354f0f1d0badcd0d90dea7eca50054c633c718e5b1c128c96ba1853ee">gpu::xetla::ln_fwd_fused_kind::bias_dropout_resAdd_ln</a></div><div class="ttdeci">@ bias_dropout_resAdd_ln</div></div>
<div class="ttc" id="anamespacegpu_1_1xetla_html_a71633e89354f0f1d0badcd0d90dea7ecad1094c3e2379e1803e554066186e1c19"><div class="ttname"><a href="namespacegpu_1_1xetla.html#a71633e89354f0f1d0badcd0d90dea7ecad1094c3e2379e1803e554066186e1c19">gpu::xetla::ln_fwd_fused_kind::ln_dropout</a></div><div class="ttdeci">@ ln_dropout</div></div>
<div class="ttc" id="anamespacegpu_1_1xetla_html_aa5a2713edb27d6fed88a3c61673556f1"><div class="ttname"><a href="namespacegpu_1_1xetla.html#aa5a2713edb27d6fed88a3c61673556f1">gpu::xetla::gpu_arch</a></div><div class="ttdeci">gpu_arch</div><div class="ttdef"><b>Definition</b> common.hpp:73</div></div>
<div class="ttc" id="anamespacegpu_1_1xetla_html_aa5a2713edb27d6fed88a3c61673556f1a8fde9df1bf2567b76160d1beedca3130"><div class="ttname"><a href="namespacegpu_1_1xetla.html#aa5a2713edb27d6fed88a3c61673556f1a8fde9df1bf2567b76160d1beedca3130">gpu::xetla::gpu_arch::Xe</a></div><div class="ttdeci">@ Xe</div></div>
<div class="ttc" id="anamespacegpu_1_1xetla_html_aa8afe1d12e7777419fb6ea09534a0aa7a5baf9a1aba8e4b6fa44c20aafacc4233"><div class="ttname"><a href="namespacegpu_1_1xetla.html#aa8afe1d12e7777419fb6ea09534a0aa7a5baf9a1aba8e4b6fa44c20aafacc4233">gpu::xetla::msg_type::block_1d</a></div><div class="ttdeci">@ block_1d</div></div>
<div class="ttc" id="anamespacegpu_1_1xetla_html_aacf5f0d7a8241d58320b4a95e0f7592b"><div class="ttname"><a href="namespacegpu_1_1xetla.html#aacf5f0d7a8241d58320b4a95e0f7592b">gpu::xetla::ln_bwd_fused_kind</a></div><div class="ttdeci">ln_bwd_fused_kind</div><div class="ttdef"><b>Definition</b> layer_norm_fused_op_api.hpp:40</div></div>
<div class="ttc" id="anamespacegpu_1_1xetla_html_aacf5f0d7a8241d58320b4a95e0f7592ba50054c633c718e5b1c128c96ba1853ee"><div class="ttname"><a href="namespacegpu_1_1xetla.html#aacf5f0d7a8241d58320b4a95e0f7592ba50054c633c718e5b1c128c96ba1853ee">gpu::xetla::ln_bwd_fused_kind::bias_dropout_resAdd_ln</a></div><div class="ttdeci">@ bias_dropout_resAdd_ln</div></div>
<div class="ttc" id="anamespacegpu_1_1xetla_html_aacf5f0d7a8241d58320b4a95e0f7592ba8f9524126712534cd132e17944140f04"><div class="ttname"><a href="namespacegpu_1_1xetla.html#aacf5f0d7a8241d58320b4a95e0f7592ba8f9524126712534cd132e17944140f04">gpu::xetla::ln_bwd_fused_kind::ln_dropout_gradAdd</a></div><div class="ttdeci">@ ln_dropout_gradAdd</div></div>
<div class="ttc" id="anamespacegpu_1_1xetla_html_aacf5f0d7a8241d58320b4a95e0f7592bad1094c3e2379e1803e554066186e1c19"><div class="ttname"><a href="namespacegpu_1_1xetla.html#aacf5f0d7a8241d58320b4a95e0f7592bad1094c3e2379e1803e554066186e1c19">gpu::xetla::ln_bwd_fused_kind::ln_dropout</a></div><div class="ttdeci">@ ln_dropout</div></div>
<div class="ttc" id="astructgpu_1_1xetla_1_1group_1_1ln__bwd__fused__op__arguments__t_html"><div class="ttname"><a href="structgpu_1_1xetla_1_1group_1_1ln__bwd__fused__op__arguments__t.html">gpu::xetla::group::ln_bwd_fused_op_arguments_t</a></div><div class="ttdef"><b>Definition</b> layer_norm_fused_op_bwd_xe.hpp:32</div></div>
<div class="ttc" id="astructgpu_1_1xetla_1_1group_1_1ln__bwd__fused__op__arguments__t_html_a07f0aac4809adc196e41750ded851a6f"><div class="ttname"><a href="structgpu_1_1xetla_1_1group_1_1ln__bwd__fused__op__arguments__t.html#a07f0aac4809adc196e41750ded851a6f">gpu::xetla::group::ln_bwd_fused_op_arguments_t::dbias_acc_ptr</a></div><div class="ttdeci">dtype_acc * dbias_acc_ptr</div><div class="ttdef"><b>Definition</b> layer_norm_fused_op_bwd_xe.hpp:33</div></div>
<div class="ttc" id="astructgpu_1_1xetla_1_1group_1_1ln__bwd__fused__op__arguments__t_html_a2083f0ac3d8eee8ebcfe0d4df2c9b550"><div class="ttname"><a href="structgpu_1_1xetla_1_1group_1_1ln__bwd__fused__op__arguments__t.html#a2083f0ac3d8eee8ebcfe0d4df2c9b550">gpu::xetla::group::ln_bwd_fused_op_arguments_t::dx_resAdd_ptr</a></div><div class="ttdeci">dtype_out * dx_resAdd_ptr</div><div class="ttdef"><b>Definition</b> layer_norm_fused_op_bwd_xe.hpp:34</div></div>
<div class="ttc" id="astructgpu_1_1xetla_1_1group_1_1ln__bwd__fused__op__arguments__t_html_a2bbf0067cd8d0c85039237d7c505c5d6"><div class="ttname"><a href="structgpu_1_1xetla_1_1group_1_1ln__bwd__fused__op__arguments__t.html#a2bbf0067cd8d0c85039237d7c505c5d6">gpu::xetla::group::ln_bwd_fused_op_arguments_t::matrix_m</a></div><div class="ttdeci">uint32_t matrix_m</div><div class="ttdef"><b>Definition</b> layer_norm_fused_op_bwd_xe.hpp:37</div></div>
<div class="ttc" id="astructgpu_1_1xetla_1_1group_1_1ln__bwd__fused__op__arguments__t_html_a378369421fe42c7b51b5f9a9e833e916"><div class="ttname"><a href="structgpu_1_1xetla_1_1group_1_1ln__bwd__fused__op__arguments__t.html#a378369421fe42c7b51b5f9a9e833e916">gpu::xetla::group::ln_bwd_fused_op_arguments_t::mask_ld</a></div><div class="ttdeci">uint32_t mask_ld</div><div class="ttdef"><b>Definition</b> layer_norm_fused_op_bwd_xe.hpp:40</div></div>
<div class="ttc" id="astructgpu_1_1xetla_1_1group_1_1ln__bwd__fused__op__arguments__t_html_a5ca6fd69a759b2b68a6f1e047a4486fa"><div class="ttname"><a href="structgpu_1_1xetla_1_1group_1_1ln__bwd__fused__op__arguments__t.html#a5ca6fd69a759b2b68a6f1e047a4486fa">gpu::xetla::group::ln_bwd_fused_op_arguments_t::matrix_n</a></div><div class="ttdeci">uint32_t matrix_n</div><div class="ttdef"><b>Definition</b> layer_norm_fused_op_bwd_xe.hpp:38</div></div>
<div class="ttc" id="astructgpu_1_1xetla_1_1group_1_1ln__bwd__fused__op__arguments__t_html_a70a67b387d3dd8dfe8fa33ae09716dd0"><div class="ttname"><a href="structgpu_1_1xetla_1_1group_1_1ln__bwd__fused__op__arguments__t.html#a70a67b387d3dd8dfe8fa33ae09716dd0">gpu::xetla::group::ln_bwd_fused_op_arguments_t::dropout_scale_inv</a></div><div class="ttdeci">float dropout_scale_inv</div><div class="ttdef"><b>Definition</b> layer_norm_fused_op_bwd_xe.hpp:43</div></div>
<div class="ttc" id="astructgpu_1_1xetla_1_1group_1_1ln__bwd__fused__op__arguments__t_html_a96bc53f94fb970b26468b219769c0968"><div class="ttname"><a href="structgpu_1_1xetla_1_1group_1_1ln__bwd__fused__op__arguments__t.html#a96bc53f94fb970b26468b219769c0968">gpu::xetla::group::ln_bwd_fused_op_arguments_t::mask_ptr</a></div><div class="ttdeci">uint8_t * mask_ptr</div><div class="ttdef"><b>Definition</b> layer_norm_fused_op_bwd_xe.hpp:36</div></div>
<div class="ttc" id="astructgpu_1_1xetla_1_1group_1_1ln__bwd__fused__op__arguments__t_html_ac624f186f20fe9a5689e1328ab5693d0"><div class="ttname"><a href="structgpu_1_1xetla_1_1group_1_1ln__bwd__fused__op__arguments__t.html#ac624f186f20fe9a5689e1328ab5693d0">gpu::xetla::group::ln_bwd_fused_op_arguments_t::mat_ld</a></div><div class="ttdeci">uint32_t mat_ld</div><div class="ttdef"><b>Definition</b> layer_norm_fused_op_bwd_xe.hpp:39</div></div>
<div class="ttc" id="astructgpu_1_1xetla_1_1group_1_1ln__bwd__fused__op__arguments__t_html_aca4e27dedde6f8ecd2aa0462c147344c"><div class="ttname"><a href="structgpu_1_1xetla_1_1group_1_1ln__bwd__fused__op__arguments__t.html#aca4e27dedde6f8ecd2aa0462c147344c">gpu::xetla::group::ln_bwd_fused_op_arguments_t::gradAdd_ptr</a></div><div class="ttdeci">dtype_in * gradAdd_ptr</div><div class="ttdef"><b>Definition</b> layer_norm_fused_op_bwd_xe.hpp:35</div></div>
<div class="ttc" id="astructgpu_1_1xetla_1_1group_1_1ln__bwd__fused__op__arguments__t_html_ada068c26ced84797f9772fe202d746f0"><div class="ttname"><a href="structgpu_1_1xetla_1_1group_1_1ln__bwd__fused__op__arguments__t.html#ada068c26ced84797f9772fe202d746f0">gpu::xetla::group::ln_bwd_fused_op_arguments_t::dropout_prob</a></div><div class="ttdeci">float dropout_prob</div><div class="ttdef"><b>Definition</b> layer_norm_fused_op_bwd_xe.hpp:42</div></div>
<div class="ttc" id="astructgpu_1_1xetla_1_1group_1_1ln__bwd__fused__op__t_3_01ln__bwd__fused__kind_1_1bias__dropout__cb4d0474e0a28c140fa444d1da09a494_html_a0f467fb7bf34ac7236adee6e29a31396"><div class="ttname"><a href="structgpu_1_1xetla_1_1group_1_1ln__bwd__fused__op__t_3_01ln__bwd__fused__kind_1_1bias__dropout__cb4d0474e0a28c140fa444d1da09a494.html#a0f467fb7bf34ac7236adee6e29a31396">gpu::xetla::group::ln_bwd_fused_op_t&lt; ln_bwd_fused_kind::bias_dropout_resAdd_ln, dtype_in_, dtype_out_, dtype_acc_, layer_norm_attr_, gpu_arch::Xe &gt;::pre_op</a></div><div class="ttdeci">__XETLA_API xetla_vector&lt; dtype_acc, sg_tile_n &gt; pre_op(xetla_vector&lt; dtype_acc, sg_tile_n &gt; input)</div><div class="ttdef"><b>Definition</b> layer_norm_fused_op_bwd_xe.hpp:197</div></div>
<div class="ttc" id="astructgpu_1_1xetla_1_1group_1_1ln__bwd__fused__op__t_3_01ln__bwd__fused__kind_1_1bias__dropout__cb4d0474e0a28c140fa444d1da09a494_html_a2467782c8f21f74bca275f84c211ca27"><div class="ttname"><a href="structgpu_1_1xetla_1_1group_1_1ln__bwd__fused__op__t_3_01ln__bwd__fused__kind_1_1bias__dropout__cb4d0474e0a28c140fa444d1da09a494.html#a2467782c8f21f74bca275f84c211ca27">gpu::xetla::group::ln_bwd_fused_op_t&lt; ln_bwd_fused_kind::bias_dropout_resAdd_ln, dtype_in_, dtype_out_, dtype_acc_, layer_norm_attr_, gpu_arch::Xe &gt;::post_op</a></div><div class="ttdeci">__XETLA_API xetla_vector&lt; dtype_acc, sg_tile_n &gt; post_op(xetla_vector&lt; dtype_acc, sg_tile_n &gt; input)</div><div class="ttdef"><b>Definition</b> layer_norm_fused_op_bwd_xe.hpp:206</div></div>
<div class="ttc" id="astructgpu_1_1xetla_1_1group_1_1ln__bwd__fused__op__t_3_01ln__bwd__fused__kind_1_1bias__dropout__cb4d0474e0a28c140fa444d1da09a494_html_a283bf429132072c6b0bae5ba92f4ebdf"><div class="ttname"><a href="structgpu_1_1xetla_1_1group_1_1ln__bwd__fused__op__t_3_01ln__bwd__fused__kind_1_1bias__dropout__cb4d0474e0a28c140fa444d1da09a494.html#a283bf429132072c6b0bae5ba92f4ebdf">gpu::xetla::group::ln_bwd_fused_op_t&lt; ln_bwd_fused_kind::bias_dropout_resAdd_ln, dtype_in_, dtype_out_, dtype_acc_, layer_norm_attr_, gpu_arch::Xe &gt;::dtype_mask</a></div><div class="ttdeci">uint8_t dtype_mask</div><div class="ttdef"><b>Definition</b> layer_norm_fused_op_bwd_xe.hpp:123</div></div>
<div class="ttc" id="astructgpu_1_1xetla_1_1group_1_1ln__bwd__fused__op__t_3_01ln__bwd__fused__kind_1_1bias__dropout__cb4d0474e0a28c140fa444d1da09a494_html_a32cfc1c564ac6f08944e6febd9723144"><div class="ttname"><a href="structgpu_1_1xetla_1_1group_1_1ln__bwd__fused__op__t_3_01ln__bwd__fused__kind_1_1bias__dropout__cb4d0474e0a28c140fa444d1da09a494.html#a32cfc1c564ac6f08944e6febd9723144">gpu::xetla::group::ln_bwd_fused_op_t&lt; ln_bwd_fused_kind::bias_dropout_resAdd_ln, dtype_in_, dtype_out_, dtype_acc_, layer_norm_attr_, gpu_arch::Xe &gt;::mask_in</a></div><div class="ttdeci">mask_in_t mask_in</div><div class="ttdef"><b>Definition</b> layer_norm_fused_op_bwd_xe.hpp:152</div></div>
<div class="ttc" id="astructgpu_1_1xetla_1_1group_1_1ln__bwd__fused__op__t_3_01ln__bwd__fused__kind_1_1bias__dropout__cb4d0474e0a28c140fa444d1da09a494_html_a3ac5572563f98d4f4e2e399a9d350521"><div class="ttname"><a href="structgpu_1_1xetla_1_1group_1_1ln__bwd__fused__op__t_3_01ln__bwd__fused__kind_1_1bias__dropout__cb4d0474e0a28c140fa444d1da09a494.html#a3ac5572563f98d4f4e2e399a9d350521">gpu::xetla::group::ln_bwd_fused_op_t&lt; ln_bwd_fused_kind::bias_dropout_resAdd_ln, dtype_in_, dtype_out_, dtype_acc_, layer_norm_attr_, gpu_arch::Xe &gt;::mask_ld</a></div><div class="ttdeci">uint32_t mask_ld</div><div class="ttdef"><b>Definition</b> layer_norm_fused_op_bwd_xe.hpp:155</div></div>
<div class="ttc" id="astructgpu_1_1xetla_1_1group_1_1ln__bwd__fused__op__t_3_01ln__bwd__fused__kind_1_1bias__dropout__cb4d0474e0a28c140fa444d1da09a494_html_a3d1cabec35d2bcf87eb2e650e7e97ea4"><div class="ttname"><a href="structgpu_1_1xetla_1_1group_1_1ln__bwd__fused__op__t_3_01ln__bwd__fused__kind_1_1bias__dropout__cb4d0474e0a28c140fa444d1da09a494.html#a3d1cabec35d2bcf87eb2e650e7e97ea4">gpu::xetla::group::ln_bwd_fused_op_t&lt; ln_bwd_fused_kind::bias_dropout_resAdd_ln, dtype_in_, dtype_out_, dtype_acc_, layer_norm_attr_, gpu_arch::Xe &gt;::dropout_scale_inv</a></div><div class="ttdeci">float dropout_scale_inv</div><div class="ttdef"><b>Definition</b> layer_norm_fused_op_bwd_xe.hpp:163</div></div>
<div class="ttc" id="astructgpu_1_1xetla_1_1group_1_1ln__bwd__fused__op__t_3_01ln__bwd__fused__kind_1_1bias__dropout__cb4d0474e0a28c140fa444d1da09a494_html_a3eb9cf04e6df4438fc3c2806da3e7d17"><div class="ttname"><a href="structgpu_1_1xetla_1_1group_1_1ln__bwd__fused__op__t_3_01ln__bwd__fused__kind_1_1bias__dropout__cb4d0474e0a28c140fa444d1da09a494.html#a3eb9cf04e6df4438fc3c2806da3e7d17">gpu::xetla::group::ln_bwd_fused_op_t&lt; ln_bwd_fused_kind::bias_dropout_resAdd_ln, dtype_in_, dtype_out_, dtype_acc_, layer_norm_attr_, gpu_arch::Xe &gt;::dropout_prob</a></div><div class="ttdeci">float dropout_prob</div><div class="ttdef"><b>Definition</b> layer_norm_fused_op_bwd_xe.hpp:162</div></div>
<div class="ttc" id="astructgpu_1_1xetla_1_1group_1_1ln__bwd__fused__op__t_3_01ln__bwd__fused__kind_1_1bias__dropout__cb4d0474e0a28c140fa444d1da09a494_html_a4425e8c8f622411a463520c79a916165"><div class="ttname"><a href="structgpu_1_1xetla_1_1group_1_1ln__bwd__fused__op__t_3_01ln__bwd__fused__kind_1_1bias__dropout__cb4d0474e0a28c140fa444d1da09a494.html#a4425e8c8f622411a463520c79a916165">gpu::xetla::group::ln_bwd_fused_op_t&lt; ln_bwd_fused_kind::bias_dropout_resAdd_ln, dtype_in_, dtype_out_, dtype_acc_, layer_norm_attr_, gpu_arch::Xe &gt;::init</a></div><div class="ttdeci">__XETLA_API void init(arguments_t *args, uint32_t wg_idx, uint32_t wg_idy, uint32_t sg_idx, uint32_t sg_idy)</div><div class="ttdef"><b>Definition</b> layer_norm_fused_op_bwd_xe.hpp:173</div></div>
<div class="ttc" id="astructgpu_1_1xetla_1_1group_1_1ln__bwd__fused__op__t_3_01ln__bwd__fused__kind_1_1bias__dropout__cb4d0474e0a28c140fa444d1da09a494_html_a481ebaacacf9221118c83867a28f06d5"><div class="ttname"><a href="structgpu_1_1xetla_1_1group_1_1ln__bwd__fused__op__t_3_01ln__bwd__fused__kind_1_1bias__dropout__cb4d0474e0a28c140fa444d1da09a494.html#a481ebaacacf9221118c83867a28f06d5">gpu::xetla::group::ln_bwd_fused_op_t&lt; ln_bwd_fused_kind::bias_dropout_resAdd_ln, dtype_in_, dtype_out_, dtype_acc_, layer_norm_attr_, gpu_arch::Xe &gt;::dbias_n</a></div><div class="ttdeci">int32_t dbias_n</div><div class="ttdef"><b>Definition</b> layer_norm_fused_op_bwd_xe.hpp:158</div></div>
<div class="ttc" id="astructgpu_1_1xetla_1_1group_1_1ln__bwd__fused__op__t_3_01ln__bwd__fused__kind_1_1bias__dropout__cb4d0474e0a28c140fa444d1da09a494_html_a4c06961e53485b61c198c291948f7739"><div class="ttname"><a href="structgpu_1_1xetla_1_1group_1_1ln__bwd__fused__op__t_3_01ln__bwd__fused__kind_1_1bias__dropout__cb4d0474e0a28c140fa444d1da09a494.html#a4c06961e53485b61c198c291948f7739">gpu::xetla::group::ln_bwd_fused_op_t&lt; ln_bwd_fused_kind::bias_dropout_resAdd_ln, dtype_in_, dtype_out_, dtype_acc_, layer_norm_attr_, gpu_arch::Xe &gt;::matrix_m</a></div><div class="ttdeci">uint32_t matrix_m</div><div class="ttdef"><b>Definition</b> layer_norm_fused_op_bwd_xe.hpp:157</div></div>
<div class="ttc" id="astructgpu_1_1xetla_1_1group_1_1ln__bwd__fused__op__t_3_01ln__bwd__fused__kind_1_1bias__dropout__cb4d0474e0a28c140fa444d1da09a494_html_a4e7174742a86817a326117cce9ce7d3e"><div class="ttname"><a href="structgpu_1_1xetla_1_1group_1_1ln__bwd__fused__op__t_3_01ln__bwd__fused__kind_1_1bias__dropout__cb4d0474e0a28c140fa444d1da09a494.html#a4e7174742a86817a326117cce9ce7d3e">gpu::xetla::group::ln_bwd_fused_op_t&lt; ln_bwd_fused_kind::bias_dropout_resAdd_ln, dtype_in_, dtype_out_, dtype_acc_, layer_norm_attr_, gpu_arch::Xe &gt;::dbias_acc_ptr</a></div><div class="ttdeci">dtype_acc * dbias_acc_ptr</div><div class="ttdef"><b>Definition</b> layer_norm_fused_op_bwd_xe.hpp:160</div></div>
<div class="ttc" id="astructgpu_1_1xetla_1_1group_1_1ln__bwd__fused__op__t_3_01ln__bwd__fused__kind_1_1bias__dropout__cb4d0474e0a28c140fa444d1da09a494_html_a5b396e89e1a4518120cc347db1150850"><div class="ttname"><a href="structgpu_1_1xetla_1_1group_1_1ln__bwd__fused__op__t_3_01ln__bwd__fused__kind_1_1bias__dropout__cb4d0474e0a28c140fa444d1da09a494.html#a5b396e89e1a4518120cc347db1150850">gpu::xetla::group::ln_bwd_fused_op_t&lt; ln_bwd_fused_kind::bias_dropout_resAdd_ln, dtype_in_, dtype_out_, dtype_acc_, layer_norm_attr_, gpu_arch::Xe &gt;::dtype_in</a></div><div class="ttdeci">dtype_in_ dtype_in</div><div class="ttdef"><b>Definition</b> layer_norm_fused_op_bwd_xe.hpp:121</div></div>
<div class="ttc" id="astructgpu_1_1xetla_1_1group_1_1ln__bwd__fused__op__t_3_01ln__bwd__fused__kind_1_1bias__dropout__cb4d0474e0a28c140fa444d1da09a494_html_a5e2f9acbb985391eb3de920e1b25446d"><div class="ttname"><a href="structgpu_1_1xetla_1_1group_1_1ln__bwd__fused__op__t_3_01ln__bwd__fused__kind_1_1bias__dropout__cb4d0474e0a28c140fa444d1da09a494.html#a5e2f9acbb985391eb3de920e1b25446d">gpu::xetla::group::ln_bwd_fused_op_t&lt; ln_bwd_fused_kind::bias_dropout_resAdd_ln, dtype_in_, dtype_out_, dtype_acc_, layer_norm_attr_, gpu_arch::Xe &gt;::dx_resAdd_out_payload</a></div><div class="ttdeci">dx_resAdd_out_payload_t dx_resAdd_out_payload</div><div class="ttdef"><b>Definition</b> layer_norm_fused_op_bwd_xe.hpp:151</div></div>
<div class="ttc" id="astructgpu_1_1xetla_1_1group_1_1ln__bwd__fused__op__t_3_01ln__bwd__fused__kind_1_1bias__dropout__cb4d0474e0a28c140fa444d1da09a494_html_a85c84e2078286888a96539a2fd766828"><div class="ttname"><a href="structgpu_1_1xetla_1_1group_1_1ln__bwd__fused__op__t_3_01ln__bwd__fused__kind_1_1bias__dropout__cb4d0474e0a28c140fa444d1da09a494.html#a85c84e2078286888a96539a2fd766828">gpu::xetla::group::ln_bwd_fused_op_t&lt; ln_bwd_fused_kind::bias_dropout_resAdd_ln, dtype_in_, dtype_out_, dtype_acc_, layer_norm_attr_, gpu_arch::Xe &gt;::dx_resAdd_out</a></div><div class="ttdeci">dx_resAdd_out_t dx_resAdd_out</div><div class="ttdef"><b>Definition</b> layer_norm_fused_op_bwd_xe.hpp:150</div></div>
<div class="ttc" id="astructgpu_1_1xetla_1_1group_1_1ln__bwd__fused__op__t_3_01ln__bwd__fused__kind_1_1bias__dropout__cb4d0474e0a28c140fa444d1da09a494_html_a89258990a57f99c0607ae5b193c7dce8"><div class="ttname"><a href="structgpu_1_1xetla_1_1group_1_1ln__bwd__fused__op__t_3_01ln__bwd__fused__kind_1_1bias__dropout__cb4d0474e0a28c140fa444d1da09a494.html#a89258990a57f99c0607ae5b193c7dce8">gpu::xetla::group::ln_bwd_fused_op_t&lt; ln_bwd_fused_kind::bias_dropout_resAdd_ln, dtype_in_, dtype_out_, dtype_acc_, layer_norm_attr_, gpu_arch::Xe &gt;::dbias</a></div><div class="ttdeci">xetla_vector&lt; dtype_acc, sg_tile_n &gt; dbias</div><div class="ttdef"><b>Definition</b> layer_norm_fused_op_bwd_xe.hpp:161</div></div>
<div class="ttc" id="astructgpu_1_1xetla_1_1group_1_1ln__bwd__fused__op__t_3_01ln__bwd__fused__kind_1_1bias__dropout__cb4d0474e0a28c140fa444d1da09a494_html_a9eaaef007309e360560adb033951828a"><div class="ttname"><a href="structgpu_1_1xetla_1_1group_1_1ln__bwd__fused__op__t_3_01ln__bwd__fused__kind_1_1bias__dropout__cb4d0474e0a28c140fa444d1da09a494.html#a9eaaef007309e360560adb033951828a">gpu::xetla::group::ln_bwd_fused_op_t&lt; ln_bwd_fused_kind::bias_dropout_resAdd_ln, dtype_in_, dtype_out_, dtype_acc_, layer_norm_attr_, gpu_arch::Xe &gt;::mat_ld</a></div><div class="ttdeci">uint32_t mat_ld</div><div class="ttdef"><b>Definition</b> layer_norm_fused_op_bwd_xe.hpp:154</div></div>
<div class="ttc" id="astructgpu_1_1xetla_1_1group_1_1ln__bwd__fused__op__t_3_01ln__bwd__fused__kind_1_1bias__dropout__cb4d0474e0a28c140fa444d1da09a494_html_aa415f946f85a23532905c9e04899d27e"><div class="ttname"><a href="structgpu_1_1xetla_1_1group_1_1ln__bwd__fused__op__t_3_01ln__bwd__fused__kind_1_1bias__dropout__cb4d0474e0a28c140fa444d1da09a494.html#aa415f946f85a23532905c9e04899d27e">gpu::xetla::group::ln_bwd_fused_op_t&lt; ln_bwd_fused_kind::bias_dropout_resAdd_ln, dtype_in_, dtype_out_, dtype_acc_, layer_norm_attr_, gpu_arch::Xe &gt;::dtype_acc</a></div><div class="ttdeci">dtype_acc_ dtype_acc</div><div class="ttdef"><b>Definition</b> layer_norm_fused_op_bwd_xe.hpp:120</div></div>
<div class="ttc" id="astructgpu_1_1xetla_1_1group_1_1ln__bwd__fused__op__t_3_01ln__bwd__fused__kind_1_1bias__dropout__cb4d0474e0a28c140fa444d1da09a494_html_ae7950f281f39706d668deb99e2d946a5"><div class="ttname"><a href="structgpu_1_1xetla_1_1group_1_1ln__bwd__fused__op__t_3_01ln__bwd__fused__kind_1_1bias__dropout__cb4d0474e0a28c140fa444d1da09a494.html#ae7950f281f39706d668deb99e2d946a5">gpu::xetla::group::ln_bwd_fused_op_t&lt; ln_bwd_fused_kind::bias_dropout_resAdd_ln, dtype_in_, dtype_out_, dtype_acc_, layer_norm_attr_, gpu_arch::Xe &gt;::final_op</a></div><div class="ttdeci">__XETLA_API void final_op(reduce_t &amp;ln_group_row_reduce)</div><div class="ttdef"><b>Definition</b> layer_norm_fused_op_bwd_xe.hpp:230</div></div>
<div class="ttc" id="astructgpu_1_1xetla_1_1group_1_1ln__bwd__fused__op__t_3_01ln__bwd__fused__kind_1_1bias__dropout__cb4d0474e0a28c140fa444d1da09a494_html_ae8a281a43fc61eeb1f5417c35b07b56c"><div class="ttname"><a href="structgpu_1_1xetla_1_1group_1_1ln__bwd__fused__op__t_3_01ln__bwd__fused__kind_1_1bias__dropout__cb4d0474e0a28c140fa444d1da09a494.html#ae8a281a43fc61eeb1f5417c35b07b56c">gpu::xetla::group::ln_bwd_fused_op_t&lt; ln_bwd_fused_kind::bias_dropout_resAdd_ln, dtype_in_, dtype_out_, dtype_acc_, layer_norm_attr_, gpu_arch::Xe &gt;::dbias_m</a></div><div class="ttdeci">int32_t dbias_m</div><div class="ttdef"><b>Definition</b> layer_norm_fused_op_bwd_xe.hpp:159</div></div>
<div class="ttc" id="astructgpu_1_1xetla_1_1group_1_1ln__bwd__fused__op__t_3_01ln__bwd__fused__kind_1_1bias__dropout__cb4d0474e0a28c140fa444d1da09a494_html_ae8a78de73ef74bb0085bb83b7f280672"><div class="ttname"><a href="structgpu_1_1xetla_1_1group_1_1ln__bwd__fused__op__t_3_01ln__bwd__fused__kind_1_1bias__dropout__cb4d0474e0a28c140fa444d1da09a494.html#ae8a78de73ef74bb0085bb83b7f280672">gpu::xetla::group::ln_bwd_fused_op_t&lt; ln_bwd_fused_kind::bias_dropout_resAdd_ln, dtype_in_, dtype_out_, dtype_acc_, layer_norm_attr_, gpu_arch::Xe &gt;::matrix_n</a></div><div class="ttdeci">uint32_t matrix_n</div><div class="ttdef"><b>Definition</b> layer_norm_fused_op_bwd_xe.hpp:156</div></div>
<div class="ttc" id="astructgpu_1_1xetla_1_1group_1_1ln__bwd__fused__op__t_3_01ln__bwd__fused__kind_1_1bias__dropout__cb4d0474e0a28c140fa444d1da09a494_html_afa3aa816243af994b255f7db3dfe5ebf"><div class="ttname"><a href="structgpu_1_1xetla_1_1group_1_1ln__bwd__fused__op__t_3_01ln__bwd__fused__kind_1_1bias__dropout__cb4d0474e0a28c140fa444d1da09a494.html#afa3aa816243af994b255f7db3dfe5ebf">gpu::xetla::group::ln_bwd_fused_op_t&lt; ln_bwd_fused_kind::bias_dropout_resAdd_ln, dtype_in_, dtype_out_, dtype_acc_, layer_norm_attr_, gpu_arch::Xe &gt;::mask_in_payload</a></div><div class="ttdeci">mask_in_payload_t mask_in_payload</div><div class="ttdef"><b>Definition</b> layer_norm_fused_op_bwd_xe.hpp:153</div></div>
<div class="ttc" id="astructgpu_1_1xetla_1_1group_1_1ln__bwd__fused__op__t_3_01ln__bwd__fused__kind_1_1bias__dropout__cb4d0474e0a28c140fa444d1da09a494_html_afc4fceff36cc8b08fa046678f7849cd3"><div class="ttname"><a href="structgpu_1_1xetla_1_1group_1_1ln__bwd__fused__op__t_3_01ln__bwd__fused__kind_1_1bias__dropout__cb4d0474e0a28c140fa444d1da09a494.html#afc4fceff36cc8b08fa046678f7849cd3">gpu::xetla::group::ln_bwd_fused_op_t&lt; ln_bwd_fused_kind::bias_dropout_resAdd_ln, dtype_in_, dtype_out_, dtype_acc_, layer_norm_attr_, gpu_arch::Xe &gt;::dtype_out</a></div><div class="ttdeci">dtype_out_ dtype_out</div><div class="ttdef"><b>Definition</b> layer_norm_fused_op_bwd_xe.hpp:122</div></div>
<div class="ttc" id="astructgpu_1_1xetla_1_1group_1_1ln__bwd__fused__op__t_3_01ln__bwd__fused__kind_1_1ln__dropout_00_85855d35f221cf3a31c3a01f77253cdf_html_a098ccb24a216b344cfad68624d7aea22"><div class="ttname"><a href="structgpu_1_1xetla_1_1group_1_1ln__bwd__fused__op__t_3_01ln__bwd__fused__kind_1_1ln__dropout_00_85855d35f221cf3a31c3a01f77253cdf.html#a098ccb24a216b344cfad68624d7aea22">gpu::xetla::group::ln_bwd_fused_op_t&lt; ln_bwd_fused_kind::ln_dropout, dtype_in_, dtype_out_, dtype_acc_, layer_norm_attr_, gpu_arch::Xe &gt;::dtype_out</a></div><div class="ttdeci">dtype_out_ dtype_out</div><div class="ttdef"><b>Definition</b> layer_norm_fused_op_bwd_xe.hpp:372</div></div>
<div class="ttc" id="astructgpu_1_1xetla_1_1group_1_1ln__bwd__fused__op__t_3_01ln__bwd__fused__kind_1_1ln__dropout_00_85855d35f221cf3a31c3a01f77253cdf_html_a16bfb1ebfaeb1cc445d4f8121f0ac365"><div class="ttname"><a href="structgpu_1_1xetla_1_1group_1_1ln__bwd__fused__op__t_3_01ln__bwd__fused__kind_1_1ln__dropout_00_85855d35f221cf3a31c3a01f77253cdf.html#a16bfb1ebfaeb1cc445d4f8121f0ac365">gpu::xetla::group::ln_bwd_fused_op_t&lt; ln_bwd_fused_kind::ln_dropout, dtype_in_, dtype_out_, dtype_acc_, layer_norm_attr_, gpu_arch::Xe &gt;::mask_in_payload</a></div><div class="ttdeci">mask_in_payload_t mask_in_payload</div><div class="ttdef"><b>Definition</b> layer_norm_fused_op_bwd_xe.hpp:395</div></div>
<div class="ttc" id="astructgpu_1_1xetla_1_1group_1_1ln__bwd__fused__op__t_3_01ln__bwd__fused__kind_1_1ln__dropout_00_85855d35f221cf3a31c3a01f77253cdf_html_a176cd45202a9b5342d53455cf41407ee"><div class="ttname"><a href="structgpu_1_1xetla_1_1group_1_1ln__bwd__fused__op__t_3_01ln__bwd__fused__kind_1_1ln__dropout_00_85855d35f221cf3a31c3a01f77253cdf.html#a176cd45202a9b5342d53455cf41407ee">gpu::xetla::group::ln_bwd_fused_op_t&lt; ln_bwd_fused_kind::ln_dropout, dtype_in_, dtype_out_, dtype_acc_, layer_norm_attr_, gpu_arch::Xe &gt;::dtype_in</a></div><div class="ttdeci">dtype_in_ dtype_in</div><div class="ttdef"><b>Definition</b> layer_norm_fused_op_bwd_xe.hpp:371</div></div>
<div class="ttc" id="astructgpu_1_1xetla_1_1group_1_1ln__bwd__fused__op__t_3_01ln__bwd__fused__kind_1_1ln__dropout_00_85855d35f221cf3a31c3a01f77253cdf_html_a3ee3c9e2b20d0e2f74235ece070dd21b"><div class="ttname"><a href="structgpu_1_1xetla_1_1group_1_1ln__bwd__fused__op__t_3_01ln__bwd__fused__kind_1_1ln__dropout_00_85855d35f221cf3a31c3a01f77253cdf.html#a3ee3c9e2b20d0e2f74235ece070dd21b">gpu::xetla::group::ln_bwd_fused_op_t&lt; ln_bwd_fused_kind::ln_dropout, dtype_in_, dtype_out_, dtype_acc_, layer_norm_attr_, gpu_arch::Xe &gt;::mask_in</a></div><div class="ttdeci">mask_in_t mask_in</div><div class="ttdef"><b>Definition</b> layer_norm_fused_op_bwd_xe.hpp:394</div></div>
<div class="ttc" id="astructgpu_1_1xetla_1_1group_1_1ln__bwd__fused__op__t_3_01ln__bwd__fused__kind_1_1ln__dropout_00_85855d35f221cf3a31c3a01f77253cdf_html_a695e3be9e1ce2f741386e4b9acf62080"><div class="ttname"><a href="structgpu_1_1xetla_1_1group_1_1ln__bwd__fused__op__t_3_01ln__bwd__fused__kind_1_1ln__dropout_00_85855d35f221cf3a31c3a01f77253cdf.html#a695e3be9e1ce2f741386e4b9acf62080">gpu::xetla::group::ln_bwd_fused_op_t&lt; ln_bwd_fused_kind::ln_dropout, dtype_in_, dtype_out_, dtype_acc_, layer_norm_attr_, gpu_arch::Xe &gt;::dtype_mask</a></div><div class="ttdeci">uint8_t dtype_mask</div><div class="ttdef"><b>Definition</b> layer_norm_fused_op_bwd_xe.hpp:373</div></div>
<div class="ttc" id="astructgpu_1_1xetla_1_1group_1_1ln__bwd__fused__op__t_3_01ln__bwd__fused__kind_1_1ln__dropout_00_85855d35f221cf3a31c3a01f77253cdf_html_a6b0f47b6a7a46afe9379a89782233d00"><div class="ttname"><a href="structgpu_1_1xetla_1_1group_1_1ln__bwd__fused__op__t_3_01ln__bwd__fused__kind_1_1ln__dropout_00_85855d35f221cf3a31c3a01f77253cdf.html#a6b0f47b6a7a46afe9379a89782233d00">gpu::xetla::group::ln_bwd_fused_op_t&lt; ln_bwd_fused_kind::ln_dropout, dtype_in_, dtype_out_, dtype_acc_, layer_norm_attr_, gpu_arch::Xe &gt;::dtype_acc</a></div><div class="ttdeci">dtype_acc_ dtype_acc</div><div class="ttdef"><b>Definition</b> layer_norm_fused_op_bwd_xe.hpp:370</div></div>
<div class="ttc" id="astructgpu_1_1xetla_1_1group_1_1ln__bwd__fused__op__t_3_01ln__bwd__fused__kind_1_1ln__dropout_00_85855d35f221cf3a31c3a01f77253cdf_html_a846eac9f54bd658266b5a9ba969ee0d7"><div class="ttname"><a href="structgpu_1_1xetla_1_1group_1_1ln__bwd__fused__op__t_3_01ln__bwd__fused__kind_1_1ln__dropout_00_85855d35f221cf3a31c3a01f77253cdf.html#a846eac9f54bd658266b5a9ba969ee0d7">gpu::xetla::group::ln_bwd_fused_op_t&lt; ln_bwd_fused_kind::ln_dropout, dtype_in_, dtype_out_, dtype_acc_, layer_norm_attr_, gpu_arch::Xe &gt;::matrix_m</a></div><div class="ttdeci">uint32_t matrix_m</div><div class="ttdef"><b>Definition</b> layer_norm_fused_op_bwd_xe.hpp:397</div></div>
<div class="ttc" id="astructgpu_1_1xetla_1_1group_1_1ln__bwd__fused__op__t_3_01ln__bwd__fused__kind_1_1ln__dropout_00_85855d35f221cf3a31c3a01f77253cdf_html_a8589d14180a7c8e2728118eb93428130"><div class="ttname"><a href="structgpu_1_1xetla_1_1group_1_1ln__bwd__fused__op__t_3_01ln__bwd__fused__kind_1_1ln__dropout_00_85855d35f221cf3a31c3a01f77253cdf.html#a8589d14180a7c8e2728118eb93428130">gpu::xetla::group::ln_bwd_fused_op_t&lt; ln_bwd_fused_kind::ln_dropout, dtype_in_, dtype_out_, dtype_acc_, layer_norm_attr_, gpu_arch::Xe &gt;::matrix_n</a></div><div class="ttdeci">uint32_t matrix_n</div><div class="ttdef"><b>Definition</b> layer_norm_fused_op_bwd_xe.hpp:396</div></div>
<div class="ttc" id="astructgpu_1_1xetla_1_1group_1_1ln__bwd__fused__op__t_3_01ln__bwd__fused__kind_1_1ln__dropout_00_85855d35f221cf3a31c3a01f77253cdf_html_ab6daddc16a3d1ce2354a88ae73f034f5"><div class="ttname"><a href="structgpu_1_1xetla_1_1group_1_1ln__bwd__fused__op__t_3_01ln__bwd__fused__kind_1_1ln__dropout_00_85855d35f221cf3a31c3a01f77253cdf.html#ab6daddc16a3d1ce2354a88ae73f034f5">gpu::xetla::group::ln_bwd_fused_op_t&lt; ln_bwd_fused_kind::ln_dropout, dtype_in_, dtype_out_, dtype_acc_, layer_norm_attr_, gpu_arch::Xe &gt;::pre_op</a></div><div class="ttdeci">__XETLA_API xetla_vector&lt; dtype_acc, sg_tile_n &gt; pre_op(xetla_vector&lt; dtype_acc, sg_tile_n &gt; input)</div><div class="ttdef"><b>Definition</b> layer_norm_fused_op_bwd_xe.hpp:425</div></div>
<div class="ttc" id="astructgpu_1_1xetla_1_1group_1_1ln__bwd__fused__op__t_3_01ln__bwd__fused__kind_1_1ln__dropout_00_85855d35f221cf3a31c3a01f77253cdf_html_abf87d6ca5f9c310c430039ab47e3e217"><div class="ttname"><a href="structgpu_1_1xetla_1_1group_1_1ln__bwd__fused__op__t_3_01ln__bwd__fused__kind_1_1ln__dropout_00_85855d35f221cf3a31c3a01f77253cdf.html#abf87d6ca5f9c310c430039ab47e3e217">gpu::xetla::group::ln_bwd_fused_op_t&lt; ln_bwd_fused_kind::ln_dropout, dtype_in_, dtype_out_, dtype_acc_, layer_norm_attr_, gpu_arch::Xe &gt;::dropout_scale_inv</a></div><div class="ttdeci">float dropout_scale_inv</div><div class="ttdef"><b>Definition</b> layer_norm_fused_op_bwd_xe.hpp:399</div></div>
<div class="ttc" id="astructgpu_1_1xetla_1_1group_1_1ln__bwd__fused__op__t_3_01ln__bwd__fused__kind_1_1ln__dropout_00_85855d35f221cf3a31c3a01f77253cdf_html_ac2769443a9bf87b85e79adbc584ded2c"><div class="ttname"><a href="structgpu_1_1xetla_1_1group_1_1ln__bwd__fused__op__t_3_01ln__bwd__fused__kind_1_1ln__dropout_00_85855d35f221cf3a31c3a01f77253cdf.html#ac2769443a9bf87b85e79adbc584ded2c">gpu::xetla::group::ln_bwd_fused_op_t&lt; ln_bwd_fused_kind::ln_dropout, dtype_in_, dtype_out_, dtype_acc_, layer_norm_attr_, gpu_arch::Xe &gt;::init</a></div><div class="ttdeci">__XETLA_API void init(arguments_t *args, uint32_t wg_idx, uint32_t wg_idy, uint32_t sg_idx, uint32_t sg_idy)</div><div class="ttdef"><b>Definition</b> layer_norm_fused_op_bwd_xe.hpp:409</div></div>
<div class="ttc" id="astructgpu_1_1xetla_1_1group_1_1ln__bwd__fused__op__t_3_01ln__bwd__fused__kind_1_1ln__dropout_00_85855d35f221cf3a31c3a01f77253cdf_html_ac9feb1b4130f3783870e38fd732865d8"><div class="ttname"><a href="structgpu_1_1xetla_1_1group_1_1ln__bwd__fused__op__t_3_01ln__bwd__fused__kind_1_1ln__dropout_00_85855d35f221cf3a31c3a01f77253cdf.html#ac9feb1b4130f3783870e38fd732865d8">gpu::xetla::group::ln_bwd_fused_op_t&lt; ln_bwd_fused_kind::ln_dropout, dtype_in_, dtype_out_, dtype_acc_, layer_norm_attr_, gpu_arch::Xe &gt;::final_op</a></div><div class="ttdeci">__XETLA_API void final_op(reduce_t &amp;ln_group_row_reduce)</div><div class="ttdef"><b>Definition</b> layer_norm_fused_op_bwd_xe.hpp:452</div></div>
<div class="ttc" id="astructgpu_1_1xetla_1_1group_1_1ln__bwd__fused__op__t_3_01ln__bwd__fused__kind_1_1ln__dropout_00_85855d35f221cf3a31c3a01f77253cdf_html_ad8da53f4632280965ac0851f2ef09769"><div class="ttname"><a href="structgpu_1_1xetla_1_1group_1_1ln__bwd__fused__op__t_3_01ln__bwd__fused__kind_1_1ln__dropout_00_85855d35f221cf3a31c3a01f77253cdf.html#ad8da53f4632280965ac0851f2ef09769">gpu::xetla::group::ln_bwd_fused_op_t&lt; ln_bwd_fused_kind::ln_dropout, dtype_in_, dtype_out_, dtype_acc_, layer_norm_attr_, gpu_arch::Xe &gt;::mask_ld</a></div><div class="ttdeci">uint32_t mask_ld</div><div class="ttdef"><b>Definition</b> layer_norm_fused_op_bwd_xe.hpp:398</div></div>
<div class="ttc" id="astructgpu_1_1xetla_1_1group_1_1ln__bwd__fused__op__t_3_01ln__bwd__fused__kind_1_1ln__dropout_00_85855d35f221cf3a31c3a01f77253cdf_html_aedae55dcbefb0e1310397e1c84bb15b1"><div class="ttname"><a href="structgpu_1_1xetla_1_1group_1_1ln__bwd__fused__op__t_3_01ln__bwd__fused__kind_1_1ln__dropout_00_85855d35f221cf3a31c3a01f77253cdf.html#aedae55dcbefb0e1310397e1c84bb15b1">gpu::xetla::group::ln_bwd_fused_op_t&lt; ln_bwd_fused_kind::ln_dropout, dtype_in_, dtype_out_, dtype_acc_, layer_norm_attr_, gpu_arch::Xe &gt;::post_op</a></div><div class="ttdeci">__XETLA_API xetla_vector&lt; dtype_acc, sg_tile_n &gt; post_op(xetla_vector&lt; dtype_acc, sg_tile_n &gt; input)</div><div class="ttdef"><b>Definition</b> layer_norm_fused_op_bwd_xe.hpp:441</div></div>
<div class="ttc" id="astructgpu_1_1xetla_1_1group_1_1ln__bwd__fused__op__t_3_01ln__bwd__fused__kind_1_1ln__dropout__gra92c7b1e7d0db3d047617e99aa09b9df_html_a39cef2885bb55a37e7c765f8c9c74bd8"><div class="ttname"><a href="structgpu_1_1xetla_1_1group_1_1ln__bwd__fused__op__t_3_01ln__bwd__fused__kind_1_1ln__dropout__gra92c7b1e7d0db3d047617e99aa09b9df.html#a39cef2885bb55a37e7c765f8c9c74bd8">gpu::xetla::group::ln_bwd_fused_op_t&lt; ln_bwd_fused_kind::ln_dropout_gradAdd, dtype_in_, dtype_out_, dtype_acc_, layer_norm_attr_, gpu_arch::Xe &gt;::matrix_m</a></div><div class="ttdeci">uint32_t matrix_m</div><div class="ttdef"><b>Definition</b> layer_norm_fused_op_bwd_xe.hpp:287</div></div>
<div class="ttc" id="astructgpu_1_1xetla_1_1group_1_1ln__bwd__fused__op__t_3_01ln__bwd__fused__kind_1_1ln__dropout__gra92c7b1e7d0db3d047617e99aa09b9df_html_a45bb083ed20f8f40d9e9eb0f1dd88332"><div class="ttname"><a href="structgpu_1_1xetla_1_1group_1_1ln__bwd__fused__op__t_3_01ln__bwd__fused__kind_1_1ln__dropout__gra92c7b1e7d0db3d047617e99aa09b9df.html#a45bb083ed20f8f40d9e9eb0f1dd88332">gpu::xetla::group::ln_bwd_fused_op_t&lt; ln_bwd_fused_kind::ln_dropout_gradAdd, dtype_in_, dtype_out_, dtype_acc_, layer_norm_attr_, gpu_arch::Xe &gt;::mask_ld</a></div><div class="ttdeci">uint32_t mask_ld</div><div class="ttdef"><b>Definition</b> layer_norm_fused_op_bwd_xe.hpp:285</div></div>
<div class="ttc" id="astructgpu_1_1xetla_1_1group_1_1ln__bwd__fused__op__t_3_01ln__bwd__fused__kind_1_1ln__dropout__gra92c7b1e7d0db3d047617e99aa09b9df_html_a47baa8bbc5b2cefdccecc0577b9848b7"><div class="ttname"><a href="structgpu_1_1xetla_1_1group_1_1ln__bwd__fused__op__t_3_01ln__bwd__fused__kind_1_1ln__dropout__gra92c7b1e7d0db3d047617e99aa09b9df.html#a47baa8bbc5b2cefdccecc0577b9848b7">gpu::xetla::group::ln_bwd_fused_op_t&lt; ln_bwd_fused_kind::ln_dropout_gradAdd, dtype_in_, dtype_out_, dtype_acc_, layer_norm_attr_, gpu_arch::Xe &gt;::dropout_scale_inv</a></div><div class="ttdeci">float dropout_scale_inv</div><div class="ttdef"><b>Definition</b> layer_norm_fused_op_bwd_xe.hpp:289</div></div>
<div class="ttc" id="astructgpu_1_1xetla_1_1group_1_1ln__bwd__fused__op__t_3_01ln__bwd__fused__kind_1_1ln__dropout__gra92c7b1e7d0db3d047617e99aa09b9df_html_a5a9649b65ac3248ff435a6e5ab140eeb"><div class="ttname"><a href="structgpu_1_1xetla_1_1group_1_1ln__bwd__fused__op__t_3_01ln__bwd__fused__kind_1_1ln__dropout__gra92c7b1e7d0db3d047617e99aa09b9df.html#a5a9649b65ac3248ff435a6e5ab140eeb">gpu::xetla::group::ln_bwd_fused_op_t&lt; ln_bwd_fused_kind::ln_dropout_gradAdd, dtype_in_, dtype_out_, dtype_acc_, layer_norm_attr_, gpu_arch::Xe &gt;::dtype_mask</a></div><div class="ttdeci">uint8_t dtype_mask</div><div class="ttdef"><b>Definition</b> layer_norm_fused_op_bwd_xe.hpp:251</div></div>
<div class="ttc" id="astructgpu_1_1xetla_1_1group_1_1ln__bwd__fused__op__t_3_01ln__bwd__fused__kind_1_1ln__dropout__gra92c7b1e7d0db3d047617e99aa09b9df_html_a6c76a53d67534dcfd520bf632407e769"><div class="ttname"><a href="structgpu_1_1xetla_1_1group_1_1ln__bwd__fused__op__t_3_01ln__bwd__fused__kind_1_1ln__dropout__gra92c7b1e7d0db3d047617e99aa09b9df.html#a6c76a53d67534dcfd520bf632407e769">gpu::xetla::group::ln_bwd_fused_op_t&lt; ln_bwd_fused_kind::ln_dropout_gradAdd, dtype_in_, dtype_out_, dtype_acc_, layer_norm_attr_, gpu_arch::Xe &gt;::mask_in_payload</a></div><div class="ttdeci">mask_in_payload_t mask_in_payload</div><div class="ttdef"><b>Definition</b> layer_norm_fused_op_bwd_xe.hpp:282</div></div>
<div class="ttc" id="astructgpu_1_1xetla_1_1group_1_1ln__bwd__fused__op__t_3_01ln__bwd__fused__kind_1_1ln__dropout__gra92c7b1e7d0db3d047617e99aa09b9df_html_a75ff13c7a726900f0eafbb6bffeb99d8"><div class="ttname"><a href="structgpu_1_1xetla_1_1group_1_1ln__bwd__fused__op__t_3_01ln__bwd__fused__kind_1_1ln__dropout__gra92c7b1e7d0db3d047617e99aa09b9df.html#a75ff13c7a726900f0eafbb6bffeb99d8">gpu::xetla::group::ln_bwd_fused_op_t&lt; ln_bwd_fused_kind::ln_dropout_gradAdd, dtype_in_, dtype_out_, dtype_acc_, layer_norm_attr_, gpu_arch::Xe &gt;::dtype_out</a></div><div class="ttdeci">dtype_out_ dtype_out</div><div class="ttdef"><b>Definition</b> layer_norm_fused_op_bwd_xe.hpp:250</div></div>
<div class="ttc" id="astructgpu_1_1xetla_1_1group_1_1ln__bwd__fused__op__t_3_01ln__bwd__fused__kind_1_1ln__dropout__gra92c7b1e7d0db3d047617e99aa09b9df_html_a7649a2529901a761152df1edf82afa84"><div class="ttname"><a href="structgpu_1_1xetla_1_1group_1_1ln__bwd__fused__op__t_3_01ln__bwd__fused__kind_1_1ln__dropout__gra92c7b1e7d0db3d047617e99aa09b9df.html#a7649a2529901a761152df1edf82afa84">gpu::xetla::group::ln_bwd_fused_op_t&lt; ln_bwd_fused_kind::ln_dropout_gradAdd, dtype_in_, dtype_out_, dtype_acc_, layer_norm_attr_, gpu_arch::Xe &gt;::matrix_n</a></div><div class="ttdeci">uint32_t matrix_n</div><div class="ttdef"><b>Definition</b> layer_norm_fused_op_bwd_xe.hpp:286</div></div>
<div class="ttc" id="astructgpu_1_1xetla_1_1group_1_1ln__bwd__fused__op__t_3_01ln__bwd__fused__kind_1_1ln__dropout__gra92c7b1e7d0db3d047617e99aa09b9df_html_a792ec301a9e080568bd3602461fe84c1"><div class="ttname"><a href="structgpu_1_1xetla_1_1group_1_1ln__bwd__fused__op__t_3_01ln__bwd__fused__kind_1_1ln__dropout__gra92c7b1e7d0db3d047617e99aa09b9df.html#a792ec301a9e080568bd3602461fe84c1">gpu::xetla::group::ln_bwd_fused_op_t&lt; ln_bwd_fused_kind::ln_dropout_gradAdd, dtype_in_, dtype_out_, dtype_acc_, layer_norm_attr_, gpu_arch::Xe &gt;::grad_in</a></div><div class="ttdeci">grad_in_t grad_in</div><div class="ttdef"><b>Definition</b> layer_norm_fused_op_bwd_xe.hpp:279</div></div>
<div class="ttc" id="astructgpu_1_1xetla_1_1group_1_1ln__bwd__fused__op__t_3_01ln__bwd__fused__kind_1_1ln__dropout__gra92c7b1e7d0db3d047617e99aa09b9df_html_a7e72d11bcd92c2b42492cc8ed7ed0927"><div class="ttname"><a href="structgpu_1_1xetla_1_1group_1_1ln__bwd__fused__op__t_3_01ln__bwd__fused__kind_1_1ln__dropout__gra92c7b1e7d0db3d047617e99aa09b9df.html#a7e72d11bcd92c2b42492cc8ed7ed0927">gpu::xetla::group::ln_bwd_fused_op_t&lt; ln_bwd_fused_kind::ln_dropout_gradAdd, dtype_in_, dtype_out_, dtype_acc_, layer_norm_attr_, gpu_arch::Xe &gt;::pre_op</a></div><div class="ttdeci">__XETLA_API xetla_vector&lt; dtype_acc, sg_tile_n &gt; pre_op(xetla_vector&lt; dtype_acc, sg_tile_n &gt; input)</div><div class="ttdef"><b>Definition</b> layer_norm_fused_op_bwd_xe.hpp:319</div></div>
<div class="ttc" id="astructgpu_1_1xetla_1_1group_1_1ln__bwd__fused__op__t_3_01ln__bwd__fused__kind_1_1ln__dropout__gra92c7b1e7d0db3d047617e99aa09b9df_html_a8c485a20c1571f1bc1864bc8acd7ead6"><div class="ttname"><a href="structgpu_1_1xetla_1_1group_1_1ln__bwd__fused__op__t_3_01ln__bwd__fused__kind_1_1ln__dropout__gra92c7b1e7d0db3d047617e99aa09b9df.html#a8c485a20c1571f1bc1864bc8acd7ead6">gpu::xetla::group::ln_bwd_fused_op_t&lt; ln_bwd_fused_kind::ln_dropout_gradAdd, dtype_in_, dtype_out_, dtype_acc_, layer_norm_attr_, gpu_arch::Xe &gt;::dropout_prob</a></div><div class="ttdeci">float dropout_prob</div><div class="ttdef"><b>Definition</b> layer_norm_fused_op_bwd_xe.hpp:288</div></div>
<div class="ttc" id="astructgpu_1_1xetla_1_1group_1_1ln__bwd__fused__op__t_3_01ln__bwd__fused__kind_1_1ln__dropout__gra92c7b1e7d0db3d047617e99aa09b9df_html_a8d86702c150b66c9964aa9985c9dc8b8"><div class="ttname"><a href="structgpu_1_1xetla_1_1group_1_1ln__bwd__fused__op__t_3_01ln__bwd__fused__kind_1_1ln__dropout__gra92c7b1e7d0db3d047617e99aa09b9df.html#a8d86702c150b66c9964aa9985c9dc8b8">gpu::xetla::group::ln_bwd_fused_op_t&lt; ln_bwd_fused_kind::ln_dropout_gradAdd, dtype_in_, dtype_out_, dtype_acc_, layer_norm_attr_, gpu_arch::Xe &gt;::init</a></div><div class="ttdeci">__XETLA_API void init(arguments_t *args, uint32_t wg_idx, uint32_t wg_idy, uint32_t sg_idx, uint32_t sg_idy)</div><div class="ttdef"><b>Definition</b> layer_norm_fused_op_bwd_xe.hpp:299</div></div>
<div class="ttc" id="astructgpu_1_1xetla_1_1group_1_1ln__bwd__fused__op__t_3_01ln__bwd__fused__kind_1_1ln__dropout__gra92c7b1e7d0db3d047617e99aa09b9df_html_a8e779e9623c98e1eca8e970df691bf4d"><div class="ttname"><a href="structgpu_1_1xetla_1_1group_1_1ln__bwd__fused__op__t_3_01ln__bwd__fused__kind_1_1ln__dropout__gra92c7b1e7d0db3d047617e99aa09b9df.html#a8e779e9623c98e1eca8e970df691bf4d">gpu::xetla::group::ln_bwd_fused_op_t&lt; ln_bwd_fused_kind::ln_dropout_gradAdd, dtype_in_, dtype_out_, dtype_acc_, layer_norm_attr_, gpu_arch::Xe &gt;::mask_in</a></div><div class="ttdeci">mask_in_t mask_in</div><div class="ttdef"><b>Definition</b> layer_norm_fused_op_bwd_xe.hpp:281</div></div>
<div class="ttc" id="astructgpu_1_1xetla_1_1group_1_1ln__bwd__fused__op__t_3_01ln__bwd__fused__kind_1_1ln__dropout__gra92c7b1e7d0db3d047617e99aa09b9df_html_aac13aca6669fa3a5f200da168d3d9403"><div class="ttname"><a href="structgpu_1_1xetla_1_1group_1_1ln__bwd__fused__op__t_3_01ln__bwd__fused__kind_1_1ln__dropout__gra92c7b1e7d0db3d047617e99aa09b9df.html#aac13aca6669fa3a5f200da168d3d9403">gpu::xetla::group::ln_bwd_fused_op_t&lt; ln_bwd_fused_kind::ln_dropout_gradAdd, dtype_in_, dtype_out_, dtype_acc_, layer_norm_attr_, gpu_arch::Xe &gt;::mat_ld</a></div><div class="ttdeci">uint32_t mat_ld</div><div class="ttdef"><b>Definition</b> layer_norm_fused_op_bwd_xe.hpp:284</div></div>
<div class="ttc" id="astructgpu_1_1xetla_1_1group_1_1ln__bwd__fused__op__t_3_01ln__bwd__fused__kind_1_1ln__dropout__gra92c7b1e7d0db3d047617e99aa09b9df_html_aacc702fde978a0d71dca4d3d18c48353"><div class="ttname"><a href="structgpu_1_1xetla_1_1group_1_1ln__bwd__fused__op__t_3_01ln__bwd__fused__kind_1_1ln__dropout__gra92c7b1e7d0db3d047617e99aa09b9df.html#aacc702fde978a0d71dca4d3d18c48353">gpu::xetla::group::ln_bwd_fused_op_t&lt; ln_bwd_fused_kind::ln_dropout_gradAdd, dtype_in_, dtype_out_, dtype_acc_, layer_norm_attr_, gpu_arch::Xe &gt;::grad_in_payload</a></div><div class="ttdeci">grad_in_payload_t grad_in_payload</div><div class="ttdef"><b>Definition</b> layer_norm_fused_op_bwd_xe.hpp:280</div></div>
<div class="ttc" id="astructgpu_1_1xetla_1_1group_1_1ln__bwd__fused__op__t_3_01ln__bwd__fused__kind_1_1ln__dropout__gra92c7b1e7d0db3d047617e99aa09b9df_html_aae312d3b6e98182efda44dc5b3b4566f"><div class="ttname"><a href="structgpu_1_1xetla_1_1group_1_1ln__bwd__fused__op__t_3_01ln__bwd__fused__kind_1_1ln__dropout__gra92c7b1e7d0db3d047617e99aa09b9df.html#aae312d3b6e98182efda44dc5b3b4566f">gpu::xetla::group::ln_bwd_fused_op_t&lt; ln_bwd_fused_kind::ln_dropout_gradAdd, dtype_in_, dtype_out_, dtype_acc_, layer_norm_attr_, gpu_arch::Xe &gt;::dtype_in</a></div><div class="ttdeci">dtype_in_ dtype_in</div><div class="ttdef"><b>Definition</b> layer_norm_fused_op_bwd_xe.hpp:249</div></div>
<div class="ttc" id="astructgpu_1_1xetla_1_1group_1_1ln__bwd__fused__op__t_3_01ln__bwd__fused__kind_1_1ln__dropout__gra92c7b1e7d0db3d047617e99aa09b9df_html_abfe8bc45d22c8d44102eb42b82140007"><div class="ttname"><a href="structgpu_1_1xetla_1_1group_1_1ln__bwd__fused__op__t_3_01ln__bwd__fused__kind_1_1ln__dropout__gra92c7b1e7d0db3d047617e99aa09b9df.html#abfe8bc45d22c8d44102eb42b82140007">gpu::xetla::group::ln_bwd_fused_op_t&lt; ln_bwd_fused_kind::ln_dropout_gradAdd, dtype_in_, dtype_out_, dtype_acc_, layer_norm_attr_, gpu_arch::Xe &gt;::dtype_acc</a></div><div class="ttdeci">dtype_acc_ dtype_acc</div><div class="ttdef"><b>Definition</b> layer_norm_fused_op_bwd_xe.hpp:248</div></div>
<div class="ttc" id="astructgpu_1_1xetla_1_1group_1_1ln__bwd__fused__op__t_3_01ln__bwd__fused__kind_1_1ln__dropout__gra92c7b1e7d0db3d047617e99aa09b9df_html_ae043679a0bd25c90b2b28b43bd1235f0"><div class="ttname"><a href="structgpu_1_1xetla_1_1group_1_1ln__bwd__fused__op__t_3_01ln__bwd__fused__kind_1_1ln__dropout__gra92c7b1e7d0db3d047617e99aa09b9df.html#ae043679a0bd25c90b2b28b43bd1235f0">gpu::xetla::group::ln_bwd_fused_op_t&lt; ln_bwd_fused_kind::ln_dropout_gradAdd, dtype_in_, dtype_out_, dtype_acc_, layer_norm_attr_, gpu_arch::Xe &gt;::post_op</a></div><div class="ttdeci">__XETLA_API xetla_vector&lt; dtype_acc, sg_tile_n &gt; post_op(xetla_vector&lt; dtype_acc, sg_tile_n &gt; input)</div><div class="ttdef"><b>Definition</b> layer_norm_fused_op_bwd_xe.hpp:344</div></div>
<div class="ttc" id="astructgpu_1_1xetla_1_1group_1_1ln__bwd__fused__op__t_3_01ln__bwd__fused__kind_1_1ln__dropout__gra92c7b1e7d0db3d047617e99aa09b9df_html_af151883a5375464a4a74bfd1ccc89253"><div class="ttname"><a href="structgpu_1_1xetla_1_1group_1_1ln__bwd__fused__op__t_3_01ln__bwd__fused__kind_1_1ln__dropout__gra92c7b1e7d0db3d047617e99aa09b9df.html#af151883a5375464a4a74bfd1ccc89253">gpu::xetla::group::ln_bwd_fused_op_t&lt; ln_bwd_fused_kind::ln_dropout_gradAdd, dtype_in_, dtype_out_, dtype_acc_, layer_norm_attr_, gpu_arch::Xe &gt;::final_op</a></div><div class="ttdeci">__XETLA_API void final_op(reduce_t &amp;ln_group_row_reduce)</div><div class="ttdef"><b>Definition</b> layer_norm_fused_op_bwd_xe.hpp:355</div></div>
<div class="ttc" id="astructgpu_1_1xetla_1_1group_1_1ln__bwd__fused__op__t_3_01ln__fused__op__kind___00_01dtype__in___b59b7c4dd4da8b28b7c493261d10e46c_html_a3dc25d7c5cb27ae71b87487f439a0819"><div class="ttname"><a href="structgpu_1_1xetla_1_1group_1_1ln__bwd__fused__op__t_3_01ln__fused__op__kind___00_01dtype__in___b59b7c4dd4da8b28b7c493261d10e46c.html#a3dc25d7c5cb27ae71b87487f439a0819">gpu::xetla::group::ln_bwd_fused_op_t&lt; ln_fused_op_kind_, dtype_in_, dtype_out_, dtype_acc_, layer_norm_attr_, gpu_arch::Xe &gt;::dtype_out</a></div><div class="ttdeci">dtype_out_ dtype_out</div><div class="ttdef"><b>Definition</b> layer_norm_fused_op_bwd_xe.hpp:60</div></div>
<div class="ttc" id="astructgpu_1_1xetla_1_1group_1_1ln__bwd__fused__op__t_3_01ln__fused__op__kind___00_01dtype__in___b59b7c4dd4da8b28b7c493261d10e46c_html_a423fd986fc4426e9715af652e2cdae04"><div class="ttname"><a href="structgpu_1_1xetla_1_1group_1_1ln__bwd__fused__op__t_3_01ln__fused__op__kind___00_01dtype__in___b59b7c4dd4da8b28b7c493261d10e46c.html#a423fd986fc4426e9715af652e2cdae04">gpu::xetla::group::ln_bwd_fused_op_t&lt; ln_fused_op_kind_, dtype_in_, dtype_out_, dtype_acc_, layer_norm_attr_, gpu_arch::Xe &gt;::post_op</a></div><div class="ttdeci">__XETLA_API xetla_vector&lt; dtype_acc, sg_tile_n &gt; post_op(xetla_vector&lt; dtype_acc, sg_tile_n &gt; input)</div><div class="ttdef"><b>Definition</b> layer_norm_fused_op_bwd_xe.hpp:94</div></div>
<div class="ttc" id="astructgpu_1_1xetla_1_1group_1_1ln__bwd__fused__op__t_3_01ln__fused__op__kind___00_01dtype__in___b59b7c4dd4da8b28b7c493261d10e46c_html_a4cc029084f87bccafbf897bdb7b47186"><div class="ttname"><a href="structgpu_1_1xetla_1_1group_1_1ln__bwd__fused__op__t_3_01ln__fused__op__kind___00_01dtype__in___b59b7c4dd4da8b28b7c493261d10e46c.html#a4cc029084f87bccafbf897bdb7b47186">gpu::xetla::group::ln_bwd_fused_op_t&lt; ln_fused_op_kind_, dtype_in_, dtype_out_, dtype_acc_, layer_norm_attr_, gpu_arch::Xe &gt;::dtype_acc</a></div><div class="ttdeci">dtype_acc_ dtype_acc</div><div class="ttdef"><b>Definition</b> layer_norm_fused_op_bwd_xe.hpp:58</div></div>
<div class="ttc" id="astructgpu_1_1xetla_1_1group_1_1ln__bwd__fused__op__t_3_01ln__fused__op__kind___00_01dtype__in___b59b7c4dd4da8b28b7c493261d10e46c_html_abb2181bf89db8eb4f5db03d72f38a33e"><div class="ttname"><a href="structgpu_1_1xetla_1_1group_1_1ln__bwd__fused__op__t_3_01ln__fused__op__kind___00_01dtype__in___b59b7c4dd4da8b28b7c493261d10e46c.html#abb2181bf89db8eb4f5db03d72f38a33e">gpu::xetla::group::ln_bwd_fused_op_t&lt; ln_fused_op_kind_, dtype_in_, dtype_out_, dtype_acc_, layer_norm_attr_, gpu_arch::Xe &gt;::init</a></div><div class="ttdeci">__XETLA_API void init(arguments_t *args, uint32_t wg_idx, uint32_t wg_idy, uint32_t sg_idx, uint32_t sg_idy)</div><div class="ttdef"><b>Definition</b> layer_norm_fused_op_bwd_xe.hpp:78</div></div>
<div class="ttc" id="astructgpu_1_1xetla_1_1group_1_1ln__bwd__fused__op__t_3_01ln__fused__op__kind___00_01dtype__in___b59b7c4dd4da8b28b7c493261d10e46c_html_acc4b5834c43d8fea62f2f48f9fab1481"><div class="ttname"><a href="structgpu_1_1xetla_1_1group_1_1ln__bwd__fused__op__t_3_01ln__fused__op__kind___00_01dtype__in___b59b7c4dd4da8b28b7c493261d10e46c.html#acc4b5834c43d8fea62f2f48f9fab1481">gpu::xetla::group::ln_bwd_fused_op_t&lt; ln_fused_op_kind_, dtype_in_, dtype_out_, dtype_acc_, layer_norm_attr_, gpu_arch::Xe &gt;::pre_op</a></div><div class="ttdeci">__XETLA_API xetla_vector&lt; dtype_acc, sg_tile_n &gt; pre_op(xetla_vector&lt; dtype_acc, sg_tile_n &gt; input)</div><div class="ttdef"><b>Definition</b> layer_norm_fused_op_bwd_xe.hpp:85</div></div>
<div class="ttc" id="astructgpu_1_1xetla_1_1group_1_1ln__bwd__fused__op__t_3_01ln__fused__op__kind___00_01dtype__in___b59b7c4dd4da8b28b7c493261d10e46c_html_ad76e6922044a1343887b9bcca414ecbb"><div class="ttname"><a href="structgpu_1_1xetla_1_1group_1_1ln__bwd__fused__op__t_3_01ln__fused__op__kind___00_01dtype__in___b59b7c4dd4da8b28b7c493261d10e46c.html#ad76e6922044a1343887b9bcca414ecbb">gpu::xetla::group::ln_bwd_fused_op_t&lt; ln_fused_op_kind_, dtype_in_, dtype_out_, dtype_acc_, layer_norm_attr_, gpu_arch::Xe &gt;::final_op</a></div><div class="ttdeci">__XETLA_API void final_op(reduce_t &amp;ln_group_row_reduce)</div><div class="ttdef"><b>Definition</b> layer_norm_fused_op_bwd_xe.hpp:105</div></div>
<div class="ttc" id="astructgpu_1_1xetla_1_1group_1_1ln__bwd__fused__op__t_3_01ln__fused__op__kind___00_01dtype__in___b59b7c4dd4da8b28b7c493261d10e46c_html_adaafd4f82e71bf4fd958c543a336f77c"><div class="ttname"><a href="structgpu_1_1xetla_1_1group_1_1ln__bwd__fused__op__t_3_01ln__fused__op__kind___00_01dtype__in___b59b7c4dd4da8b28b7c493261d10e46c.html#adaafd4f82e71bf4fd958c543a336f77c">gpu::xetla::group::ln_bwd_fused_op_t&lt; ln_fused_op_kind_, dtype_in_, dtype_out_, dtype_acc_, layer_norm_attr_, gpu_arch::Xe &gt;::dtype_in</a></div><div class="ttdeci">dtype_in_ dtype_in</div><div class="ttdef"><b>Definition</b> layer_norm_fused_op_bwd_xe.hpp:59</div></div>
<div class="ttc" id="astructgpu_1_1xetla_1_1group_1_1ln__bwd__fused__op__t_html"><div class="ttname"><a href="structgpu_1_1xetla_1_1group_1_1ln__bwd__fused__op__t.html">gpu::xetla::group::ln_bwd_fused_op_t</a></div><div class="ttdef"><b>Definition</b> layer_norm_fused_op_api.hpp:73</div></div>
<div class="ttc" id="astructgpu_1_1xetla_1_1mem__desc__t_html"><div class="ttname"><a href="structgpu_1_1xetla_1_1mem__desc__t.html">gpu::xetla::mem_desc_t</a></div><div class="ttdef"><b>Definition</b> memory_descriptor.hpp:139</div></div>
<div class="ttc" id="astructgpu_1_1xetla_1_1subgroup_1_1mem__payload__t_html"><div class="ttname"><a href="structgpu_1_1xetla_1_1subgroup_1_1mem__payload__t.html">gpu::xetla::subgroup::mem_payload_t&lt; mem_desc_t&lt; dtype_out, mem_layout::row_major, mem_space::global &gt;, ln_bwd_tile_desc_t, msg_type::block_1d, gpu_arch::Xe &gt;</a></div></div>
<div class="ttc" id="astructgpu_1_1xetla_1_1subgroup_1_1tile__desc__t_html"><div class="ttname"><a href="structgpu_1_1xetla_1_1subgroup_1_1tile__desc__t.html">gpu::xetla::subgroup::tile_desc_t</a></div><div class="ttdoc">Is to illustrate the tile information about a sub matrix.</div><div class="ttdef"><b>Definition</b> api.hpp:64</div></div>
<div class="ttc" id="astructgpu_1_1xetla_1_1subgroup_1_1tile__t_html"><div class="ttname"><a href="structgpu_1_1xetla_1_1subgroup_1_1tile__t.html">gpu::xetla::subgroup::tile_t&lt; dtype_out, ln_bwd_tile_desc_t &gt;</a></div></div>
<div class="ttc" id="astructgpu_1_1xetla_1_1subgroup_1_1tile__t_html_a7985ceac15e399ebf3000e5693d8801e"><div class="ttname"><a href="structgpu_1_1xetla_1_1subgroup_1_1tile__t.html#a7985ceac15e399ebf3000e5693d8801e">gpu::xetla::subgroup::tile_t::reg</a></div><div class="ttdeci">xetla_vector&lt; dtype, tile_desc::tile_elems &gt; reg</div><div class="ttdef"><b>Definition</b> api.hpp:102</div></div>
</div><!-- fragment --></div><!-- contents -->
</div><!-- doc-content -->
<!-- start footer part -->
<div id="nav-path" class="navpath"><!-- id is needed for treeview function! -->
  <ul>
    <li class="navelem"><a class="el" href="dir_d44c64559bbebec7f509842c48db8b23.html">include</a></li><li class="navelem"><a class="el" href="dir_8966848d4591654ab1db845bb311f08b.html">experimental</a></li><li class="navelem"><a class="el" href="dir_6cebb349e4d63b3d4aebac2b846d4ac3.html">group</a></li><li class="navelem"><a class="el" href="dir_410b5e7dd5c4254b7aeadfca8c7d2ce8.html">fused_op</a></li><li class="navelem"><a class="el" href="layer__norm__fused__op__bwd__xe_8hpp.html">layer_norm_fused_op_bwd_xe.hpp</a></li>
    <li class="footer">Generated by <a href="https://www.doxygen.org/index.html"><img class="footer" src="doxygen.svg" width="104" height="31" alt="doxygen"/></a> 1.9.7 </li>
  </ul>
</div>
</body>
</html>
