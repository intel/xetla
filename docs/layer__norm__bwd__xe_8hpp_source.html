<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "https://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" lang="en-US">
<head>
<meta http-equiv="Content-Type" content="text/xhtml;charset=UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=11"/>
<meta name="generator" content="Doxygen 1.9.5"/>
<meta name="viewport" content="width=device-width, initial-scale=1"/>
<title>XeTLA: include/experimental/kernel/layer_norm/layer_norm_bwd_xe.hpp Source File</title>
<link href="tabs.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="jquery.js"></script>
<script type="text/javascript" src="dynsections.js"></script>
<link href="navtree.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="resize.js"></script>
<script type="text/javascript" src="navtreedata.js"></script>
<script type="text/javascript" src="navtree.js"></script>
<link href="search/search.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="search/searchdata.js"></script>
<script type="text/javascript" src="search/search.js"></script>
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:d3d9a9a6595521f9666a5e94cc830dab83b65699&amp;dn=expat.txt MIT */
  $(document).ready(function() { init_search(); });
/* @license-end */
</script>
<script type="text/x-mathjax-config">
MathJax.Hub.Config({
  extensions: ["tex2jax.js"],
  jax: ["input/TeX","output/HTML-CSS"],
});
</script>
<script type="text/javascript" async="async" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js"></script>
<link href="doxygen.css" rel="stylesheet" type="text/css" />
</head>
<body>
<div id="top"><!-- do not remove this div, it is closed by doxygen! -->
<div id="titlearea">
<table cellspacing="0" cellpadding="0">
 <tbody>
 <tr id="projectrow">
  <td id="projectalign">
   <div id="projectname">XeTLA<span id="projectnumber">&#160;v0.3.4</span>
   </div>
   <div id="projectbrief">IntelÂ® Xe Templates for Linear Algebra - API Definition Document</div>
  </td>
    <td>        <div id="MSearchBox" class="MSearchBoxInactive">
        <span class="left">
          <span id="MSearchSelect"                onmouseover="return searchBox.OnSearchSelectShow()"                onmouseout="return searchBox.OnSearchSelectHide()">&#160;</span>
          <input type="text" id="MSearchField" value="" placeholder="Search" accesskey="S"
               onfocus="searchBox.OnSearchFieldFocus(true)" 
               onblur="searchBox.OnSearchFieldFocus(false)" 
               onkeyup="searchBox.OnSearchFieldChange(event)"/>
          </span><span class="right">
            <a id="MSearchClose" href="javascript:searchBox.CloseResultsWindow()"><img id="MSearchCloseImg" border="0" src="search/close.svg" alt=""/></a>
          </span>
        </div>
</td>
 </tr>
 </tbody>
</table>
</div>
<!-- end header part -->
<!-- Generated by Doxygen 1.9.5 -->
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:d3d9a9a6595521f9666a5e94cc830dab83b65699&amp;dn=expat.txt MIT */
var searchBox = new SearchBox("searchBox", "search/",'.html');
/* @license-end */
</script>
</div><!-- top -->
<div id="side-nav" class="ui-resizable side-nav-resizable">
  <div id="nav-tree">
    <div id="nav-tree-contents">
      <div id="nav-sync" class="sync"></div>
    </div>
  </div>
  <div id="splitbar" style="-moz-user-select:none;" 
       class="ui-resizable-handle">
  </div>
</div>
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:d3d9a9a6595521f9666a5e94cc830dab83b65699&amp;dn=expat.txt MIT */
$(document).ready(function(){initNavTree('layer__norm__bwd__xe_8hpp_source.html',''); initResizable(); });
/* @license-end */
</script>
<div id="doc-content">
<!-- window showing the filter options -->
<div id="MSearchSelectWindow"
     onmouseover="return searchBox.OnSearchSelectShow()"
     onmouseout="return searchBox.OnSearchSelectHide()"
     onkeydown="return searchBox.OnSearchSelectKey(event)">
</div>

<!-- iframe showing the search results (closed by default) -->
<div id="MSearchResultsWindow">
<div id="MSearchResults">
<div class="SRPage">
<div id="SRIndex">
<div id="SRResults"></div>
<div class="SRStatus" id="Loading">Loading...</div>
<div class="SRStatus" id="Searching">Searching...</div>
<div class="SRStatus" id="NoMatches">No Matches</div>
</div>
</div>
</div>
</div>

<div class="header">
  <div class="headertitle"><div class="title">layer_norm_bwd_xe.hpp</div></div>
</div><!--header-->
<div class="contents">
<a href="layer__norm__bwd__xe_8hpp.html">Go to the documentation of this file.</a><div class="fragment"><div class="line"><a id="l00001" name="l00001"></a><span class="lineno">    1</span><span class="comment">/*******************************************************************************</span></div>
<div class="line"><a id="l00002" name="l00002"></a><span class="lineno">    2</span><span class="comment">* Copyright (c) 2022-2023 Intel Corporation</span></div>
<div class="line"><a id="l00003" name="l00003"></a><span class="lineno">    3</span><span class="comment">*</span></div>
<div class="line"><a id="l00004" name="l00004"></a><span class="lineno">    4</span><span class="comment">* Licensed under the Apache License, Version 2.0 (the &quot;License&quot;);</span></div>
<div class="line"><a id="l00005" name="l00005"></a><span class="lineno">    5</span><span class="comment">* you may not use this file except in compliance with the License.</span></div>
<div class="line"><a id="l00006" name="l00006"></a><span class="lineno">    6</span><span class="comment">* You may obtain a copy of the License at</span></div>
<div class="line"><a id="l00007" name="l00007"></a><span class="lineno">    7</span><span class="comment">*</span></div>
<div class="line"><a id="l00008" name="l00008"></a><span class="lineno">    8</span><span class="comment">*     http://www.apache.org/licenses/LICENSE-2.0</span></div>
<div class="line"><a id="l00009" name="l00009"></a><span class="lineno">    9</span><span class="comment">*</span></div>
<div class="line"><a id="l00010" name="l00010"></a><span class="lineno">   10</span><span class="comment">* Unless required by applicable law or agreed to in writing, software</span></div>
<div class="line"><a id="l00011" name="l00011"></a><span class="lineno">   11</span><span class="comment">* distributed under the License is distributed on an &quot;AS IS&quot; BASIS,</span></div>
<div class="line"><a id="l00012" name="l00012"></a><span class="lineno">   12</span><span class="comment">* WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.</span></div>
<div class="line"><a id="l00013" name="l00013"></a><span class="lineno">   13</span><span class="comment">* See the License for the specific language governing permissions and</span></div>
<div class="line"><a id="l00014" name="l00014"></a><span class="lineno">   14</span><span class="comment">* limitations under the License.</span></div>
<div class="line"><a id="l00015" name="l00015"></a><span class="lineno">   15</span><span class="comment">*******************************************************************************/</span></div>
<div class="line"><a id="l00016" name="l00016"></a><span class="lineno">   16</span> </div>
<div class="line"><a id="l00019" name="l00019"></a><span class="lineno">   19</span> </div>
<div class="line"><a id="l00020" name="l00020"></a><span class="lineno">   20</span><span class="preprocessor">#pragma once</span></div>
<div class="line"><a id="l00021" name="l00021"></a><span class="lineno">   21</span> </div>
<div class="line"><a id="l00022" name="l00022"></a><span class="lineno">   22</span><span class="preprocessor">#include &quot;<a class="code" href="layer__norm__fused__op__bwd__xe_8hpp.html">experimental/group/fused_op/layer_norm_fused_op_bwd_xe.hpp</a>&quot;</span></div>
<div class="line"><a id="l00023" name="l00023"></a><span class="lineno">   23</span><span class="preprocessor">#include &quot;<a class="code" href="experimental_2kernel_2layer__norm_2api_8hpp.html">experimental/kernel/layer_norm/api.hpp</a>&quot;</span></div>
<div class="line"><a id="l00024" name="l00024"></a><span class="lineno">   24</span><span class="preprocessor">#include &quot;<a class="code" href="experimental_2kernel_2layer__norm_2common_8hpp.html">experimental/kernel/layer_norm/common.hpp</a>&quot;</span></div>
<div class="line"><a id="l00025" name="l00025"></a><span class="lineno">   25</span><span class="preprocessor">#include &quot;<a class="code" href="layer__norm_2config_8hpp.html">experimental/kernel/layer_norm/config.hpp</a>&quot;</span></div>
<div class="line"><a id="l00026" name="l00026"></a><span class="lineno">   26</span> </div>
<div class="line"><a id="l00027" name="l00027"></a><span class="lineno">   27</span><span class="keyword">namespace </span><a class="code hl_namespace" href="namespacegpu_1_1xetla_1_1kernel.html">gpu::xetla::kernel</a> {</div>
<div class="line"><a id="l00028" name="l00028"></a><span class="lineno">   28</span> </div>
<div class="line"><a id="l00037" name="l00037"></a><span class="lineno">   37</span><span class="keyword">template</span> &lt;<span class="keyword">typename</span> dtype_x_, <span class="keyword">typename</span> dtype_y_, <span class="keyword">typename</span> dtype_weight_,</div>
<div class="line"><a id="l00038" name="l00038"></a><span class="lineno">   38</span>        <span class="keyword">typename</span> dtype_acc_, <span class="keyword">typename</span> layer_norm_attr_,</div>
<div class="line"><a id="l00039" name="l00039"></a><span class="lineno">   39</span>        <span class="keyword">typename</span> ln_bwd_fused_op_&gt;</div>
<div class="line"><a id="l00040" name="l00040"></a><span class="lineno"><a class="line" href="structgpu_1_1xetla_1_1kernel_1_1layer__norm__bwd__t_3_01dtype__x___00_01dtype__y___00_01dtype__w5e223ea0bd3a3851e47c460f10bccc84.html">   40</a></span><span class="keyword">struct </span><a class="code hl_struct" href="structgpu_1_1xetla_1_1kernel_1_1layer__norm__bwd__t.html">layer_norm_bwd_t</a>&lt;dtype_x_, dtype_y_, dtype_weight_, dtype_acc_,</div>
<div class="line"><a id="l00041" name="l00041"></a><span class="lineno">   41</span>        layer_norm_attr_, <a class="code hl_enumeration" href="group__xetla__core__arch__config.html#gaa5a2713edb27d6fed88a3c61673556f1">gpu_arch</a>::<a class="code hl_enumvalue" href="group__xetla__core__arch__config.html#ggaa5a2713edb27d6fed88a3c61673556f1a8fde9df1bf2567b76160d1beedca3130">Xe</a>, ln_bwd_fused_op_&gt; {</div>
<div class="line"><a id="l00042" name="l00042"></a><span class="lineno"><a class="line" href="structgpu_1_1xetla_1_1kernel_1_1layer__norm__bwd__t_3_01dtype__x___00_01dtype__y___00_01dtype__w5e223ea0bd3a3851e47c460f10bccc84.html#ace04ac4e6f750e6dc131157a3250d5b3">   42</a></span>    <span class="keyword">using </span><a class="code hl_typedef" href="structgpu_1_1xetla_1_1kernel_1_1layer__norm__bwd__t_3_01dtype__x___00_01dtype__y___00_01dtype__w5e223ea0bd3a3851e47c460f10bccc84.html#ace04ac4e6f750e6dc131157a3250d5b3">dtype_x</a> = dtype_x_;</div>
<div class="line"><a id="l00043" name="l00043"></a><span class="lineno"><a class="line" href="structgpu_1_1xetla_1_1kernel_1_1layer__norm__bwd__t_3_01dtype__x___00_01dtype__y___00_01dtype__w5e223ea0bd3a3851e47c460f10bccc84.html#a65c0ca9026ee5e6887929571e292c927">   43</a></span>    <span class="keyword">using </span><a class="code hl_typedef" href="structgpu_1_1xetla_1_1kernel_1_1layer__norm__bwd__t_3_01dtype__x___00_01dtype__y___00_01dtype__w5e223ea0bd3a3851e47c460f10bccc84.html#a65c0ca9026ee5e6887929571e292c927">dtype_y</a> = dtype_y_;</div>
<div class="line"><a id="l00044" name="l00044"></a><span class="lineno"><a class="line" href="structgpu_1_1xetla_1_1kernel_1_1layer__norm__bwd__t_3_01dtype__x___00_01dtype__y___00_01dtype__w5e223ea0bd3a3851e47c460f10bccc84.html#a6e3963e378066c5d245fe66f74738797">   44</a></span>    <span class="keyword">using </span><a class="code hl_typedef" href="structgpu_1_1xetla_1_1kernel_1_1layer__norm__bwd__t_3_01dtype__x___00_01dtype__y___00_01dtype__w5e223ea0bd3a3851e47c460f10bccc84.html#a6e3963e378066c5d245fe66f74738797">dtype_weight</a> = dtype_weight_;</div>
<div class="line"><a id="l00045" name="l00045"></a><span class="lineno"><a class="line" href="structgpu_1_1xetla_1_1kernel_1_1layer__norm__bwd__t_3_01dtype__x___00_01dtype__y___00_01dtype__w5e223ea0bd3a3851e47c460f10bccc84.html#a5c5444009eda1cc73b8538d63dc78f94">   45</a></span>    <span class="keyword">using </span><a class="code hl_typedef" href="structgpu_1_1xetla_1_1kernel_1_1layer__norm__bwd__t_3_01dtype__x___00_01dtype__y___00_01dtype__w5e223ea0bd3a3851e47c460f10bccc84.html#a5c5444009eda1cc73b8538d63dc78f94">dtype_acc</a> = dtype_acc_;</div>
<div class="line"><a id="l00046" name="l00046"></a><span class="lineno"><a class="line" href="structgpu_1_1xetla_1_1kernel_1_1layer__norm__bwd__t_3_01dtype__x___00_01dtype__y___00_01dtype__w5e223ea0bd3a3851e47c460f10bccc84.html#a6643584dccd935324777d22721c9e924">   46</a></span>    <span class="keyword">using </span><a class="code hl_typedef" href="structgpu_1_1xetla_1_1kernel_1_1layer__norm__bwd__t_3_01dtype__x___00_01dtype__y___00_01dtype__w5e223ea0bd3a3851e47c460f10bccc84.html#a6643584dccd935324777d22721c9e924">layer_norm_attr</a> = layer_norm_attr_;</div>
<div class="line"><a id="l00047" name="l00047"></a><span class="lineno"><a class="line" href="structgpu_1_1xetla_1_1kernel_1_1layer__norm__bwd__t_3_01dtype__x___00_01dtype__y___00_01dtype__w5e223ea0bd3a3851e47c460f10bccc84.html#abb73d94fccf7341dd998753a3a6978c2">   47</a></span>    <span class="keyword">using </span><a class="code hl_typedef" href="structgpu_1_1xetla_1_1kernel_1_1layer__norm__bwd__t_3_01dtype__x___00_01dtype__y___00_01dtype__w5e223ea0bd3a3851e47c460f10bccc84.html#abb73d94fccf7341dd998753a3a6978c2">ln_bwd_fused_op</a> = ln_bwd_fused_op_;</div>
<div class="line"><a id="l00048" name="l00048"></a><span class="lineno"><a class="line" href="structgpu_1_1xetla_1_1kernel_1_1layer__norm__bwd__t_3_01dtype__x___00_01dtype__y___00_01dtype__w5e223ea0bd3a3851e47c460f10bccc84.html#a856d703aca448075c793a40d821d87ca">   48</a></span>    <span class="keyword">using </span><a class="code hl_typedef" href="structgpu_1_1xetla_1_1kernel_1_1layer__norm__bwd__t_3_01dtype__x___00_01dtype__y___00_01dtype__w5e223ea0bd3a3851e47c460f10bccc84.html#a856d703aca448075c793a40d821d87ca">ln_fused_op_arguments_t</a> = <span class="keyword">typename</span> ln_bwd_fused_op::arguments_t;</div>
<div class="line"><a id="l00049" name="l00049"></a><span class="lineno"><a class="line" href="structgpu_1_1xetla_1_1kernel_1_1layer__norm__bwd__t_3_01dtype__x___00_01dtype__y___00_01dtype__w5e223ea0bd3a3851e47c460f10bccc84.html#a4d829e18c3385c242611dc3f9ccbeaa1">   49</a></span>    <span class="keyword">static</span> <span class="keyword">constexpr</span> uint32_t wg_tile_m = layer_norm_attr::wg_tile_m;</div>
<div class="line"><a id="l00050" name="l00050"></a><span class="lineno"><a class="line" href="structgpu_1_1xetla_1_1kernel_1_1layer__norm__bwd__t_3_01dtype__x___00_01dtype__y___00_01dtype__w5e223ea0bd3a3851e47c460f10bccc84.html#a232c83a64b954c25df8a051fc908f17b">   50</a></span>    <span class="keyword">static</span> <span class="keyword">constexpr</span> uint32_t wg_tile_n = layer_norm_attr::wg_tile_n;</div>
<div class="line"><a id="l00051" name="l00051"></a><span class="lineno"><a class="line" href="structgpu_1_1xetla_1_1kernel_1_1layer__norm__bwd__t_3_01dtype__x___00_01dtype__y___00_01dtype__w5e223ea0bd3a3851e47c460f10bccc84.html#aeaad28e03b6dfd955dc6f01f1ca3cccb">   51</a></span>    <span class="keyword">static</span> <span class="keyword">constexpr</span> uint32_t sg_tile_m = layer_norm_attr::sg_tile_m;</div>
<div class="line"><a id="l00052" name="l00052"></a><span class="lineno"><a class="line" href="structgpu_1_1xetla_1_1kernel_1_1layer__norm__bwd__t_3_01dtype__x___00_01dtype__y___00_01dtype__w5e223ea0bd3a3851e47c460f10bccc84.html#a520b02f991de3d35f9b0566bcd8113f4">   52</a></span>    <span class="keyword">static</span> <span class="keyword">constexpr</span> uint32_t sg_tile_n = layer_norm_attr::sg_tile_n;</div>
<div class="line"><a id="l00053" name="l00053"></a><span class="lineno"><a class="line" href="structgpu_1_1xetla_1_1kernel_1_1layer__norm__bwd__t_3_01dtype__x___00_01dtype__y___00_01dtype__w5e223ea0bd3a3851e47c460f10bccc84.html#ac660b68f44e6dc24d2c39aeb3c003303">   53</a></span>    <span class="keyword">static</span> <span class="keyword">constexpr</span> uint32_t wg_num_m = layer_norm_attr::wg_num_m;</div>
<div class="line"><a id="l00054" name="l00054"></a><span class="lineno"><a class="line" href="structgpu_1_1xetla_1_1kernel_1_1layer__norm__bwd__t_3_01dtype__x___00_01dtype__y___00_01dtype__w5e223ea0bd3a3851e47c460f10bccc84.html#a2e99b95f0de59cd33ca039b22a59bd65">   54</a></span>    <span class="keyword">static</span> <span class="keyword">constexpr</span> uint32_t wg_num_n = layer_norm_attr::wg_num_n;</div>
<div class="line"><a id="l00055" name="l00055"></a><span class="lineno">   55</span> </div>
<div class="line"><a id="l00056" name="l00056"></a><span class="lineno"><a class="line" href="structgpu_1_1xetla_1_1kernel_1_1layer__norm__bwd__t_3_01dtype__x___00_01dtype__y___00_01dtype__w5e223ea0bd3a3851e47c460f10bccc84.html#a5b67a65f9986ade4dd05655ff1ed54c5">   56</a></span>    <span class="keyword">static</span> <span class="keyword">constexpr</span> uint32_t wg_size_x</div>
<div class="line"><a id="l00057" name="l00057"></a><span class="lineno">   57</span>            = (wg_tile_n + sg_tile_n - 1) / sg_tile_n;</div>
<div class="line"><a id="l00058" name="l00058"></a><span class="lineno"><a class="line" href="structgpu_1_1xetla_1_1kernel_1_1layer__norm__bwd__t_3_01dtype__x___00_01dtype__y___00_01dtype__w5e223ea0bd3a3851e47c460f10bccc84.html#aabb460b4f30acd89d232bd2a5cf1d00a">   58</a></span>    <span class="keyword">static</span> <span class="keyword">constexpr</span> uint32_t wg_size_y</div>
<div class="line"><a id="l00059" name="l00059"></a><span class="lineno">   59</span>            = (wg_tile_m + sg_tile_m - 1) / sg_tile_m;</div>
<div class="line"><a id="l00060" name="l00060"></a><span class="lineno"><a class="line" href="structgpu_1_1xetla_1_1kernel_1_1layer__norm__bwd__t_3_01dtype__x___00_01dtype__y___00_01dtype__w5e223ea0bd3a3851e47c460f10bccc84.html#ab8f68b77c72bf88647ee8f0f4194b86f">   60</a></span>    <span class="keyword">using </span><a class="code hl_typedef" href="structgpu_1_1xetla_1_1kernel_1_1layer__norm__bwd__t_3_01dtype__x___00_01dtype__y___00_01dtype__w5e223ea0bd3a3851e47c460f10bccc84.html#ab8f68b77c72bf88647ee8f0f4194b86f">work_group_t</a> = <a class="code hl_typedef" href="structgpu_1_1xetla_1_1kernel_1_1layer__norm__bwd__t_3_01dtype__x___00_01dtype__y___00_01dtype__w5e223ea0bd3a3851e47c460f10bccc84.html#ab8f68b77c72bf88647ee8f0f4194b86f">work_group_t&lt;wg_size_x * wg_size_y&gt;</a>;</div>
<div class="line"><a id="l00061" name="l00061"></a><span class="lineno">   61</span>    <span class="keyword">static_assert</span>((wg_size_x &lt;= 32) &amp;&amp; ((wg_size_x &amp; (wg_size_x - 1)) == 0),</div>
<div class="line"><a id="l00062" name="l00062"></a><span class="lineno">   62</span>            <span class="stringliteral">&quot;Current only support wg_size_x &lt;=32&quot;</span>);</div>
<div class="line"><a id="l00063" name="l00063"></a><span class="lineno"><a class="line" href="structgpu_1_1xetla_1_1kernel_1_1layer__norm__bwd__t_3_01dtype__x___00_01dtype__y___00_01dtype__w5e223ea0bd3a3851e47c460f10bccc84.html#ae08cc5e93259229d714c3eda427ae494">   63</a></span>    <span class="keyword">static</span> <span class="keyword">constexpr</span> uint32_t count_col_reduce</div>
<div class="line"><a id="l00064" name="l00064"></a><span class="lineno">   64</span>            = (wg_size_x &gt; 1) ? wg_size_y : 0;</div>
<div class="line"><a id="l00065" name="l00065"></a><span class="lineno"><a class="line" href="structgpu_1_1xetla_1_1kernel_1_1layer__norm__bwd__t_3_01dtype__x___00_01dtype__y___00_01dtype__w5e223ea0bd3a3851e47c460f10bccc84.html#a64e3bbf3c62bd21ce07e6c0e41571d02">   65</a></span>    <span class="keyword">static</span> <span class="keyword">constexpr</span> uint32_t count_row_reduce</div>
<div class="line"><a id="l00066" name="l00066"></a><span class="lineno">   66</span>            = (wg_size_y &gt; 1) ? wg_size_x : 0;</div>
<div class="line"><a id="l00067" name="l00067"></a><span class="lineno"><a class="line" href="structgpu_1_1xetla_1_1kernel_1_1layer__norm__bwd__t_3_01dtype__x___00_01dtype__y___00_01dtype__wc6027ac29965333ffa97f8b5703c2982.html">   67</a></span>    <span class="keyword">struct </span>get_barrier_count {</div>
<div class="line"><a id="l00068" name="l00068"></a><span class="lineno"><a class="line" href="structgpu_1_1xetla_1_1kernel_1_1layer__norm__bwd__t_3_01dtype__x___00_01dtype__y___00_01dtype__wc6027ac29965333ffa97f8b5703c2982.html#aae7b18734bc9fbf021aba715994d70b7">   68</a></span>        <span class="keyword">static</span> <span class="keyword">constexpr</span> uint32_t count = count_col_reduce + count_row_reduce;</div>
<div class="line"><a id="l00069" name="l00069"></a><span class="lineno">   69</span>    };</div>
<div class="line"><a id="l00070" name="l00070"></a><span class="lineno">   70</span>    <span class="comment">// 4 = (grad0 + grad1) * double buffering</span></div>
<div class="line"><a id="l00071" name="l00071"></a><span class="lineno"><a class="line" href="structgpu_1_1xetla_1_1kernel_1_1layer__norm__bwd__t_3_01dtype__x___00_01dtype__y___00_01dtype__w5e223ea0bd3a3851e47c460f10bccc84.html#a5b2bd5e37aa86abab3788b0c98ca68f7">   71</a></span>    <span class="keyword">static</span> <span class="keyword">constexpr</span> uint32_t size_col_reduce = (wg_size_x &gt; 1)</div>
<div class="line"><a id="l00072" name="l00072"></a><span class="lineno">   72</span>            ? wg_size_x * wg_size_y * 4 * <span class="keyword">sizeof</span>(<a class="code hl_typedef" href="structgpu_1_1xetla_1_1kernel_1_1layer__norm__bwd__t_3_01dtype__x___00_01dtype__y___00_01dtype__w5e223ea0bd3a3851e47c460f10bccc84.html#a5c5444009eda1cc73b8538d63dc78f94">dtype_acc</a>)</div>
<div class="line"><a id="l00073" name="l00073"></a><span class="lineno">   73</span>            : 0;</div>
<div class="line"><a id="l00074" name="l00074"></a><span class="lineno">   74</span>    <span class="comment">// wg_size_y * rows</span></div>
<div class="line"><a id="l00075" name="l00075"></a><span class="lineno"><a class="line" href="structgpu_1_1xetla_1_1kernel_1_1layer__norm__bwd__t_3_01dtype__x___00_01dtype__y___00_01dtype__w5e223ea0bd3a3851e47c460f10bccc84.html#ac5cc3fa24cd50f968118e847d29eb968">   75</a></span>    <span class="keyword">static</span> <span class="keyword">constexpr</span> uint32_t size_row_reduce = (wg_size_y &gt; 1)</div>
<div class="line"><a id="l00076" name="l00076"></a><span class="lineno">   76</span>            ? wg_size_y * wg_size_x * sg_tile_n * <span class="keyword">sizeof</span>(<a class="code hl_typedef" href="structgpu_1_1xetla_1_1kernel_1_1layer__norm__bwd__t_3_01dtype__x___00_01dtype__y___00_01dtype__w5e223ea0bd3a3851e47c460f10bccc84.html#a5c5444009eda1cc73b8538d63dc78f94">dtype_acc</a>)</div>
<div class="line"><a id="l00077" name="l00077"></a><span class="lineno">   77</span>            : 0;</div>
<div class="line"><a id="l00078" name="l00078"></a><span class="lineno"><a class="line" href="structgpu_1_1xetla_1_1kernel_1_1layer__norm__bwd__t_3_01dtype__x___00_01dtype__y___00_01dtype__wd8d91116cddf28aca893d04fd21e65d8.html">   78</a></span>    <span class="keyword">struct </span>get_slm_size {</div>
<div class="line"><a id="l00079" name="l00079"></a><span class="lineno"><a class="line" href="structgpu_1_1xetla_1_1kernel_1_1layer__norm__bwd__t_3_01dtype__x___00_01dtype__y___00_01dtype__wd8d91116cddf28aca893d04fd21e65d8.html#a022a5f95ffa42146bfe49b070e4d8ae4">   79</a></span>        <span class="keyword">static</span> <span class="keyword">constexpr</span> uint32_t size = size_col_reduce + size_row_reduce;</div>
<div class="line"><a id="l00080" name="l00080"></a><span class="lineno">   80</span>    };</div>
<div class="line"><a id="l00081" name="l00081"></a><span class="lineno">   81</span> </div>
<div class="line"><a id="l00082" name="l00082"></a><span class="lineno"><a class="line" href="structgpu_1_1xetla_1_1kernel_1_1layer__norm__bwd__t_3_01dtype__x___00_01dtype__y___00_01dtype__w5e223ea0bd3a3851e47c460f10bccc84.html#a3055d5cf9fadbb695c6539e530a4fa37">   82</a></span>    <span class="keyword">using </span><a class="code hl_struct" href="structgpu_1_1xetla_1_1subgroup_1_1tile__desc__t.html">ln_bwd_tile_desc_t</a> = <a class="code hl_struct" href="structgpu_1_1xetla_1_1subgroup_1_1tile__desc__t.html">subgroup::tile_desc_t</a>&lt;sg_tile_n, 1, sg_tile_n, 1,</div>
<div class="line"><a id="l00083" name="l00083"></a><span class="lineno">   83</span>            <a class="code hl_enumvalue" href="namespacegpu_1_1xetla.html#a51137fd81d0d9d2156525a1e279432aaa78506882d645395a052df8b01a927395">reg_layout::tiled</a>&gt;;</div>
<div class="line"><a id="l00084" name="l00084"></a><span class="lineno"><a class="line" href="structgpu_1_1xetla_1_1kernel_1_1layer__norm__bwd__t_3_01dtype__x___00_01dtype__y___00_01dtype__w5e223ea0bd3a3851e47c460f10bccc84.html#add61cc0691c45d3c9019565ccb336d69">   84</a></span>    <span class="keyword">using </span><a class="code hl_struct" href="structgpu_1_1xetla_1_1subgroup_1_1tile__t.html">dy_in_t</a> = <a class="code hl_struct" href="structgpu_1_1xetla_1_1subgroup_1_1tile__t.html">subgroup::tile_t&lt;dtype_y, ln_bwd_tile_desc_t&gt;</a>;</div>
<div class="line"><a id="l00085" name="l00085"></a><span class="lineno"><a class="line" href="structgpu_1_1xetla_1_1kernel_1_1layer__norm__bwd__t_3_01dtype__x___00_01dtype__y___00_01dtype__w5e223ea0bd3a3851e47c460f10bccc84.html#a30925312d8fbb91257bfafad218a8435">   85</a></span>    <span class="keyword">using </span><a class="code hl_struct" href="structgpu_1_1xetla_1_1subgroup_1_1tile__t.html">x_in_t</a> = <a class="code hl_struct" href="structgpu_1_1xetla_1_1subgroup_1_1tile__t.html">subgroup::tile_t&lt;dtype_x, ln_bwd_tile_desc_t&gt;</a>;</div>
<div class="line"><a id="l00086" name="l00086"></a><span class="lineno"><a class="line" href="structgpu_1_1xetla_1_1kernel_1_1layer__norm__bwd__t_3_01dtype__x___00_01dtype__y___00_01dtype__w5e223ea0bd3a3851e47c460f10bccc84.html#ac8f8804762c357730f2b9d49377c8486">   86</a></span>    <span class="keyword">using </span><a class="code hl_struct" href="structgpu_1_1xetla_1_1subgroup_1_1tile__t.html">gamma_in_t</a> = <a class="code hl_struct" href="structgpu_1_1xetla_1_1subgroup_1_1tile__t.html">subgroup::tile_t&lt;dtype_weight, ln_bwd_tile_desc_t&gt;</a>;</div>
<div class="line"><a id="l00087" name="l00087"></a><span class="lineno"><a class="line" href="structgpu_1_1xetla_1_1kernel_1_1layer__norm__bwd__t_3_01dtype__x___00_01dtype__y___00_01dtype__w5e223ea0bd3a3851e47c460f10bccc84.html#a4d0483865997c4db80dc50aaed79dc8c">   87</a></span>    <span class="keyword">using </span><a class="code hl_struct" href="structgpu_1_1xetla_1_1subgroup_1_1tile__t.html">dx_out_t</a> = <a class="code hl_struct" href="structgpu_1_1xetla_1_1subgroup_1_1tile__t.html">subgroup::tile_t&lt;dtype_x, ln_bwd_tile_desc_t&gt;</a>;</div>
<div class="line"><a id="l00088" name="l00088"></a><span class="lineno">   88</span> </div>
<div class="line"><a id="l00089" name="l00089"></a><span class="lineno"><a class="line" href="structgpu_1_1xetla_1_1kernel_1_1layer__norm__bwd__t_3_01dtype__x___00_01dtype__y___00_01dtype__w5e223ea0bd3a3851e47c460f10bccc84.html#af898e3b363f782a5a2713f3b377351d8">   89</a></span>    <span class="keyword">using </span><a class="code hl_struct" href="structgpu_1_1xetla_1_1subgroup_1_1mem__payload__t.html">dy_in_payload_t</a> = <a class="code hl_struct" href="structgpu_1_1xetla_1_1subgroup_1_1mem__payload__t.html">subgroup::mem_payload_t</a>&lt;<a class="code hl_typedef" href="structgpu_1_1xetla_1_1kernel_1_1layer__norm__bwd__t_3_01dtype__x___00_01dtype__y___00_01dtype__w5e223ea0bd3a3851e47c460f10bccc84.html#a65c0ca9026ee5e6887929571e292c927">dtype_y</a>, <a class="code hl_struct" href="structgpu_1_1xetla_1_1subgroup_1_1tile__desc__t.html">ln_bwd_tile_desc_t</a>,</div>
<div class="line"><a id="l00090" name="l00090"></a><span class="lineno">   90</span>            subgroup::msg_type_v&lt;ln_bwd_tile_desc_t, mem_space::global&gt;,</div>
<div class="line"><a id="l00091" name="l00091"></a><span class="lineno">   91</span>            <a class="code hl_enumvalue" href="namespacegpu_1_1xetla.html#af4a355a1806510c5515fad16f5910561a641fabb8e5e7d1d0333e2c9c384f959c">mem_layout::row_major</a>, <a class="code hl_enumvalue" href="namespacegpu_1_1xetla.html#a7f225ed816e841c1d31414d872dae59da9c70933aff6b2a6d08c687a6cbb6b765">mem_space::global</a>, <a class="code hl_enumvalue" href="group__xetla__core__arch__config.html#ggaa5a2713edb27d6fed88a3c61673556f1a8fde9df1bf2567b76160d1beedca3130">gpu_arch::Xe</a>&gt;;</div>
<div class="line"><a id="l00092" name="l00092"></a><span class="lineno"><a class="line" href="structgpu_1_1xetla_1_1kernel_1_1layer__norm__bwd__t_3_01dtype__x___00_01dtype__y___00_01dtype__w5e223ea0bd3a3851e47c460f10bccc84.html#a0650614bd474bd69affffef2ed39d4ae">   92</a></span>    <span class="keyword">using </span><a class="code hl_struct" href="structgpu_1_1xetla_1_1subgroup_1_1mem__payload__t.html">x_in_payload_t</a> = <a class="code hl_struct" href="structgpu_1_1xetla_1_1subgroup_1_1mem__payload__t.html">subgroup::mem_payload_t</a>&lt;<a class="code hl_typedef" href="structgpu_1_1xetla_1_1kernel_1_1layer__norm__bwd__t_3_01dtype__x___00_01dtype__y___00_01dtype__w5e223ea0bd3a3851e47c460f10bccc84.html#ace04ac4e6f750e6dc131157a3250d5b3">dtype_x</a>, <a class="code hl_struct" href="structgpu_1_1xetla_1_1subgroup_1_1tile__desc__t.html">ln_bwd_tile_desc_t</a>,</div>
<div class="line"><a id="l00093" name="l00093"></a><span class="lineno">   93</span>            subgroup::msg_type_v&lt;ln_bwd_tile_desc_t, mem_space::global&gt;,</div>
<div class="line"><a id="l00094" name="l00094"></a><span class="lineno">   94</span>            <a class="code hl_enumvalue" href="namespacegpu_1_1xetla.html#af4a355a1806510c5515fad16f5910561a641fabb8e5e7d1d0333e2c9c384f959c">mem_layout::row_major</a>, <a class="code hl_enumvalue" href="namespacegpu_1_1xetla.html#a7f225ed816e841c1d31414d872dae59da9c70933aff6b2a6d08c687a6cbb6b765">mem_space::global</a>, <a class="code hl_enumvalue" href="group__xetla__core__arch__config.html#ggaa5a2713edb27d6fed88a3c61673556f1a8fde9df1bf2567b76160d1beedca3130">gpu_arch::Xe</a>&gt;;</div>
<div class="line"><a id="l00095" name="l00095"></a><span class="lineno"><a class="line" href="structgpu_1_1xetla_1_1kernel_1_1layer__norm__bwd__t_3_01dtype__x___00_01dtype__y___00_01dtype__w5e223ea0bd3a3851e47c460f10bccc84.html#a2f05c10d0be4dc98b6aab412c922a0a4">   95</a></span>    <span class="keyword">using </span><a class="code hl_struct" href="structgpu_1_1xetla_1_1subgroup_1_1mem__payload__t.html">gamma_in_payload_t</a></div>
<div class="line"><a id="l00096" name="l00096"></a><span class="lineno">   96</span>            = <a class="code hl_struct" href="structgpu_1_1xetla_1_1subgroup_1_1mem__payload__t.html">subgroup::mem_payload_t</a>&lt;<a class="code hl_typedef" href="structgpu_1_1xetla_1_1kernel_1_1layer__norm__bwd__t_3_01dtype__x___00_01dtype__y___00_01dtype__w5e223ea0bd3a3851e47c460f10bccc84.html#a6e3963e378066c5d245fe66f74738797">dtype_weight</a>, <a class="code hl_struct" href="structgpu_1_1xetla_1_1subgroup_1_1tile__desc__t.html">ln_bwd_tile_desc_t</a>,</div>
<div class="line"><a id="l00097" name="l00097"></a><span class="lineno">   97</span>                    subgroup::msg_type_v&lt;ln_bwd_tile_desc_t, mem_space::global&gt;,</div>
<div class="line"><a id="l00098" name="l00098"></a><span class="lineno">   98</span>                    <a class="code hl_enumvalue" href="namespacegpu_1_1xetla.html#af4a355a1806510c5515fad16f5910561a641fabb8e5e7d1d0333e2c9c384f959c">mem_layout::row_major</a>, <a class="code hl_enumvalue" href="namespacegpu_1_1xetla.html#a7f225ed816e841c1d31414d872dae59da9c70933aff6b2a6d08c687a6cbb6b765">mem_space::global</a>, <a class="code hl_enumvalue" href="group__xetla__core__arch__config.html#ggaa5a2713edb27d6fed88a3c61673556f1a8fde9df1bf2567b76160d1beedca3130">gpu_arch::Xe</a>&gt;;</div>
<div class="line"><a id="l00099" name="l00099"></a><span class="lineno"><a class="line" href="structgpu_1_1xetla_1_1kernel_1_1layer__norm__bwd__t_3_01dtype__x___00_01dtype__y___00_01dtype__w5e223ea0bd3a3851e47c460f10bccc84.html#a2b98d2cb045bdd5be0732612d0adbc86">   99</a></span>    <span class="keyword">using </span><a class="code hl_struct" href="structgpu_1_1xetla_1_1subgroup_1_1mem__payload__t.html">dx_out_payload_t</a> = <a class="code hl_struct" href="structgpu_1_1xetla_1_1subgroup_1_1mem__payload__t.html">subgroup::mem_payload_t</a>&lt;<a class="code hl_typedef" href="structgpu_1_1xetla_1_1kernel_1_1layer__norm__bwd__t_3_01dtype__x___00_01dtype__y___00_01dtype__w5e223ea0bd3a3851e47c460f10bccc84.html#ace04ac4e6f750e6dc131157a3250d5b3">dtype_x</a>,</div>
<div class="line"><a id="l00100" name="l00100"></a><span class="lineno">  100</span>            <a class="code hl_struct" href="structgpu_1_1xetla_1_1subgroup_1_1tile__desc__t.html">ln_bwd_tile_desc_t</a>, <a class="code hl_enumvalue" href="namespacegpu_1_1xetla.html#aa8afe1d12e7777419fb6ea09534a0aa7a5baf9a1aba8e4b6fa44c20aafacc4233">msg_type::block_1d</a>, <a class="code hl_enumvalue" href="namespacegpu_1_1xetla.html#af4a355a1806510c5515fad16f5910561a641fabb8e5e7d1d0333e2c9c384f959c">mem_layout::row_major</a>,</div>
<div class="line"><a id="l00101" name="l00101"></a><span class="lineno">  101</span>            <a class="code hl_enumvalue" href="namespacegpu_1_1xetla.html#a7f225ed816e841c1d31414d872dae59da9c70933aff6b2a6d08c687a6cbb6b765">mem_space::global</a>, <a class="code hl_enumvalue" href="group__xetla__core__arch__config.html#ggaa5a2713edb27d6fed88a3c61673556f1a8fde9df1bf2567b76160d1beedca3130">gpu_arch::Xe</a>&gt;;</div>
<div class="line"><a id="l00102" name="l00102"></a><span class="lineno">  102</span> </div>
<div class="line"><a id="l00103" name="l00103"></a><span class="lineno"><a class="line" href="structgpu_1_1xetla_1_1kernel_1_1layer__norm__bwd__t_3_01dtype__x___00_01dtype__y___00_01dtype__w5e223ea0bd3a3851e47c460f10bccc84.html#ac86328b2cecc88f01c67b37649e8703d">  103</a></span>    <span class="keyword">using </span><a class="code hl_struct" href="structgpu_1_1xetla_1_1group_1_1group__row__reduce__store__t.html">ln_group_row_reduce_store_t</a></div>
<div class="line"><a id="l00104" name="l00104"></a><span class="lineno">  104</span>            = <a class="code hl_struct" href="structgpu_1_1xetla_1_1group_1_1group__row__reduce__store__t.html">group::group_row_reduce_store_t</a>&lt;<a class="code hl_typedef" href="structgpu_1_1xetla_1_1kernel_1_1layer__norm__bwd__t_3_01dtype__x___00_01dtype__y___00_01dtype__w5e223ea0bd3a3851e47c460f10bccc84.html#a5c5444009eda1cc73b8538d63dc78f94">dtype_acc</a>, <a class="code hl_typedef" href="structgpu_1_1xetla_1_1kernel_1_1layer__norm__bwd__t_3_01dtype__x___00_01dtype__y___00_01dtype__w5e223ea0bd3a3851e47c460f10bccc84.html#a5c5444009eda1cc73b8538d63dc78f94">dtype_acc</a>, sg_tile_n,</div>
<div class="line"><a id="l00105" name="l00105"></a><span class="lineno">  105</span>                    wg_size_x, wg_size_y, 32, <a class="code hl_enumvalue" href="group__xetla__core__arch__config.html#ggaa5a2713edb27d6fed88a3c61673556f1a8fde9df1bf2567b76160d1beedca3130">gpu_arch::Xe</a>&gt;;</div>
<div class="line"><a id="l00106" name="l00106"></a><span class="lineno">  106</span> </div>
<div class="line"><a id="l00109" name="l00109"></a><span class="lineno"><a class="line" href="structgpu_1_1xetla_1_1kernel_1_1layer__norm__bwd__t_3_01dtype__x___00_01dtype__y___00_01dtype__w8c870e0747f737257129382bb64d56e0.html">  109</a></span>    <span class="keyword">struct </span>arguments_t {</div>
<div class="line"><a id="l00110" name="l00110"></a><span class="lineno"><a class="line" href="structgpu_1_1xetla_1_1kernel_1_1layer__norm__bwd__t_3_01dtype__x___00_01dtype__y___00_01dtype__w8c870e0747f737257129382bb64d56e0.html#a9f6d76f79fec3db6f9ea545fb7fecbed">  110</a></span>        <a class="code hl_typedef" href="structgpu_1_1xetla_1_1kernel_1_1layer__norm__bwd__t_3_01dtype__x___00_01dtype__y___00_01dtype__w5e223ea0bd3a3851e47c460f10bccc84.html#a65c0ca9026ee5e6887929571e292c927">dtype_y</a> *<a class="code hl_variable" href="structgpu_1_1xetla_1_1kernel_1_1layer__norm__bwd__t_3_01dtype__x___00_01dtype__y___00_01dtype__w8c870e0747f737257129382bb64d56e0.html#a9f6d76f79fec3db6f9ea545fb7fecbed">dy_in_ptr</a>;</div>
<div class="line"><a id="l00111" name="l00111"></a><span class="lineno"><a class="line" href="structgpu_1_1xetla_1_1kernel_1_1layer__norm__bwd__t_3_01dtype__x___00_01dtype__y___00_01dtype__w8c870e0747f737257129382bb64d56e0.html#a2440a2de9804d0bf12c9c6f0da428698">  111</a></span>        <a class="code hl_typedef" href="structgpu_1_1xetla_1_1kernel_1_1layer__norm__bwd__t_3_01dtype__x___00_01dtype__y___00_01dtype__w5e223ea0bd3a3851e47c460f10bccc84.html#ace04ac4e6f750e6dc131157a3250d5b3">dtype_x</a> *<a class="code hl_variable" href="structgpu_1_1xetla_1_1kernel_1_1layer__norm__bwd__t_3_01dtype__x___00_01dtype__y___00_01dtype__w8c870e0747f737257129382bb64d56e0.html#a2440a2de9804d0bf12c9c6f0da428698">x_in_ptr</a>;</div>
<div class="line"><a id="l00112" name="l00112"></a><span class="lineno"><a class="line" href="structgpu_1_1xetla_1_1kernel_1_1layer__norm__bwd__t_3_01dtype__x___00_01dtype__y___00_01dtype__w8c870e0747f737257129382bb64d56e0.html#a972d3ed415731797b47198b8c60f5604">  112</a></span>        <a class="code hl_typedef" href="structgpu_1_1xetla_1_1kernel_1_1layer__norm__bwd__t_3_01dtype__x___00_01dtype__y___00_01dtype__w5e223ea0bd3a3851e47c460f10bccc84.html#a6e3963e378066c5d245fe66f74738797">dtype_weight</a> *<a class="code hl_variable" href="structgpu_1_1xetla_1_1kernel_1_1layer__norm__bwd__t_3_01dtype__x___00_01dtype__y___00_01dtype__w8c870e0747f737257129382bb64d56e0.html#a972d3ed415731797b47198b8c60f5604">gamma_in_ptr</a>;</div>
<div class="line"><a id="l00113" name="l00113"></a><span class="lineno"><a class="line" href="structgpu_1_1xetla_1_1kernel_1_1layer__norm__bwd__t_3_01dtype__x___00_01dtype__y___00_01dtype__w8c870e0747f737257129382bb64d56e0.html#ad8b8a0898fd653db197f4a3561d8fa8c">  113</a></span>        <a class="code hl_typedef" href="structgpu_1_1xetla_1_1kernel_1_1layer__norm__bwd__t_3_01dtype__x___00_01dtype__y___00_01dtype__w5e223ea0bd3a3851e47c460f10bccc84.html#a5c5444009eda1cc73b8538d63dc78f94">dtype_acc</a> *<a class="code hl_variable" href="structgpu_1_1xetla_1_1kernel_1_1layer__norm__bwd__t_3_01dtype__x___00_01dtype__y___00_01dtype__w8c870e0747f737257129382bb64d56e0.html#ad8b8a0898fd653db197f4a3561d8fa8c">rs_ptr</a>;</div>
<div class="line"><a id="l00114" name="l00114"></a><span class="lineno"><a class="line" href="structgpu_1_1xetla_1_1kernel_1_1layer__norm__bwd__t_3_01dtype__x___00_01dtype__y___00_01dtype__w8c870e0747f737257129382bb64d56e0.html#ae6c41c4182fd92948ebd77dbe2902b9e">  114</a></span>        <a class="code hl_typedef" href="structgpu_1_1xetla_1_1kernel_1_1layer__norm__bwd__t_3_01dtype__x___00_01dtype__y___00_01dtype__w5e223ea0bd3a3851e47c460f10bccc84.html#a5c5444009eda1cc73b8538d63dc78f94">dtype_acc</a> *<a class="code hl_variable" href="structgpu_1_1xetla_1_1kernel_1_1layer__norm__bwd__t_3_01dtype__x___00_01dtype__y___00_01dtype__w8c870e0747f737257129382bb64d56e0.html#ae6c41c4182fd92948ebd77dbe2902b9e">mu_ptr</a>;</div>
<div class="line"><a id="l00115" name="l00115"></a><span class="lineno">  115</span> </div>
<div class="line"><a id="l00116" name="l00116"></a><span class="lineno"><a class="line" href="structgpu_1_1xetla_1_1kernel_1_1layer__norm__bwd__t_3_01dtype__x___00_01dtype__y___00_01dtype__w8c870e0747f737257129382bb64d56e0.html#afd79f60c87a238015d9fe02e81becc55">  116</a></span>        <a class="code hl_typedef" href="structgpu_1_1xetla_1_1kernel_1_1layer__norm__bwd__t_3_01dtype__x___00_01dtype__y___00_01dtype__w5e223ea0bd3a3851e47c460f10bccc84.html#ace04ac4e6f750e6dc131157a3250d5b3">dtype_x</a> *<a class="code hl_variable" href="structgpu_1_1xetla_1_1kernel_1_1layer__norm__bwd__t_3_01dtype__x___00_01dtype__y___00_01dtype__w8c870e0747f737257129382bb64d56e0.html#afd79f60c87a238015d9fe02e81becc55">dx_out_ptr</a>;</div>
<div class="line"><a id="l00117" name="l00117"></a><span class="lineno"><a class="line" href="structgpu_1_1xetla_1_1kernel_1_1layer__norm__bwd__t_3_01dtype__x___00_01dtype__y___00_01dtype__w8c870e0747f737257129382bb64d56e0.html#a1a7cbaf46cae468d8d31698f62d0371d">  117</a></span>        <a class="code hl_typedef" href="structgpu_1_1xetla_1_1kernel_1_1layer__norm__bwd__t_3_01dtype__x___00_01dtype__y___00_01dtype__w5e223ea0bd3a3851e47c460f10bccc84.html#a5c5444009eda1cc73b8538d63dc78f94">dtype_acc</a> *<a class="code hl_variable" href="structgpu_1_1xetla_1_1kernel_1_1layer__norm__bwd__t_3_01dtype__x___00_01dtype__y___00_01dtype__w8c870e0747f737257129382bb64d56e0.html#a1a7cbaf46cae468d8d31698f62d0371d">dgamma_acc_ptr</a>;</div>
<div class="line"><a id="l00118" name="l00118"></a><span class="lineno"><a class="line" href="structgpu_1_1xetla_1_1kernel_1_1layer__norm__bwd__t_3_01dtype__x___00_01dtype__y___00_01dtype__w8c870e0747f737257129382bb64d56e0.html#ae6ed860b5d25e0256c7497e3c9bd8619">  118</a></span>        <a class="code hl_typedef" href="structgpu_1_1xetla_1_1kernel_1_1layer__norm__bwd__t_3_01dtype__x___00_01dtype__y___00_01dtype__w5e223ea0bd3a3851e47c460f10bccc84.html#a5c5444009eda1cc73b8538d63dc78f94">dtype_acc</a> *<a class="code hl_variable" href="structgpu_1_1xetla_1_1kernel_1_1layer__norm__bwd__t_3_01dtype__x___00_01dtype__y___00_01dtype__w8c870e0747f737257129382bb64d56e0.html#ae6ed860b5d25e0256c7497e3c9bd8619">dbeta_acc_ptr</a>;</div>
<div class="line"><a id="l00119" name="l00119"></a><span class="lineno">  119</span> </div>
<div class="line"><a id="l00120" name="l00120"></a><span class="lineno"><a class="line" href="structgpu_1_1xetla_1_1kernel_1_1layer__norm__bwd__t_3_01dtype__x___00_01dtype__y___00_01dtype__w8c870e0747f737257129382bb64d56e0.html#a387fb818e436a001d36c23707e16aca0">  120</a></span>        uint32_t <a class="code hl_variable" href="structgpu_1_1xetla_1_1kernel_1_1layer__norm__bwd__t_3_01dtype__x___00_01dtype__y___00_01dtype__w8c870e0747f737257129382bb64d56e0.html#a387fb818e436a001d36c23707e16aca0">matrix_m</a>;</div>
<div class="line"><a id="l00121" name="l00121"></a><span class="lineno"><a class="line" href="structgpu_1_1xetla_1_1kernel_1_1layer__norm__bwd__t_3_01dtype__x___00_01dtype__y___00_01dtype__w8c870e0747f737257129382bb64d56e0.html#adc3aed8897d33aa95b9593334f23798e">  121</a></span>        uint32_t <a class="code hl_variable" href="structgpu_1_1xetla_1_1kernel_1_1layer__norm__bwd__t_3_01dtype__x___00_01dtype__y___00_01dtype__w8c870e0747f737257129382bb64d56e0.html#adc3aed8897d33aa95b9593334f23798e">matrix_n</a>;</div>
<div class="line"><a id="l00122" name="l00122"></a><span class="lineno"><a class="line" href="structgpu_1_1xetla_1_1kernel_1_1layer__norm__bwd__t_3_01dtype__x___00_01dtype__y___00_01dtype__w8c870e0747f737257129382bb64d56e0.html#ac970c1b9a64dd16c9c46ead0b24cd769">  122</a></span>        uint32_t <a class="code hl_variable" href="structgpu_1_1xetla_1_1kernel_1_1layer__norm__bwd__t_3_01dtype__x___00_01dtype__y___00_01dtype__w8c870e0747f737257129382bb64d56e0.html#ac970c1b9a64dd16c9c46ead0b24cd769">mat_ld</a>;</div>
<div class="line"><a id="l00123" name="l00123"></a><span class="lineno"><a class="line" href="structgpu_1_1xetla_1_1kernel_1_1layer__norm__bwd__t_3_01dtype__x___00_01dtype__y___00_01dtype__w8c870e0747f737257129382bb64d56e0.html#a1ab637021d8f7b7b3e5727f81f33a628">  123</a></span>        <a class="code hl_typedef" href="structgpu_1_1xetla_1_1kernel_1_1layer__norm__bwd__t_3_01dtype__x___00_01dtype__y___00_01dtype__w5e223ea0bd3a3851e47c460f10bccc84.html#a5c5444009eda1cc73b8538d63dc78f94">dtype_acc</a> epsilon = 1e-5;</div>
<div class="line"><a id="l00124" name="l00124"></a><span class="lineno">  124</span>    };</div>
<div class="line"><a id="l00125" name="l00125"></a><span class="lineno">  125</span> </div>
<div class="line"><a id="l00126" name="l00126"></a><span class="lineno">  126</span><span class="keyword">private</span>:</div>
<div class="line"><a id="l00136" name="l00136"></a><span class="lineno">  136</span>    <span class="keyword">template</span> &lt;<span class="keyword">typename</span> T, uint32_t SZ, uint32_t N, <a class="code hl_enumeration" href="namespacegpu_1_1xetla.html#a7bbd70f1164d3a7251729e89fffc0609">reduce_op</a> Op,</div>
<div class="line"><a id="l00137" name="l00137"></a><span class="lineno">  137</span>            uint32_t wg_size_x, uint32_t wg_size_y,</div>
<div class="line"><a id="l00138" name="l00138"></a><span class="lineno">  138</span>            <a class="code hl_enumeration" href="group__xetla__core__arch__config.html#gaa5a2713edb27d6fed88a3c61673556f1">gpu_arch</a> arch_ = <a class="code hl_enumvalue" href="group__xetla__core__arch__config.html#ggaa5a2713edb27d6fed88a3c61673556f1a8fde9df1bf2567b76160d1beedca3130">gpu_arch::Xe</a>&gt;</div>
<div class="line"><a id="l00139" name="l00139"></a><span class="lineno">  139</span>    <span class="keyword">struct </span>ln_group_all_reduce_t {</div>
<div class="line"><a id="l00140" name="l00140"></a><span class="lineno">  140</span>        uint32_t itr_count;</div>
<div class="line"><a id="l00141" name="l00141"></a><span class="lineno">  141</span>        uint32_t slm_base_0;</div>
<div class="line"><a id="l00142" name="l00142"></a><span class="lineno">  142</span>        uint32_t slm_base_1;</div>
<div class="line"><a id="l00143" name="l00143"></a><span class="lineno">  143</span> </div>
<div class="line"><a id="l00144" name="l00144"></a><span class="lineno">  144</span>        <a class="code hl_struct" href="structgpu_1_1xetla_1_1group_1_1group__reduce__t.html">group::group_reduce_t&lt;T, SZ, N, Op, wg_size_x, true, arch_&gt;</a></div>
<div class="line"><a id="l00145" name="l00145"></a><span class="lineno">  145</span>                group_reduce;</div>
<div class="line"><a id="l00146" name="l00146"></a><span class="lineno">  146</span> </div>
<div class="line"><a id="l00153" name="l00153"></a><span class="lineno">  153</span>        <span class="keyword">inline</span> ln_group_all_reduce_t(uint32_t sg_idx = 0, uint32_t sg_idy = 0,</div>
<div class="line"><a id="l00154" name="l00154"></a><span class="lineno">  154</span>                uint32_t slm_base = 0, uint32_t nbarrier_base = 0) {</div>
<div class="line"><a id="l00155" name="l00155"></a><span class="lineno">  155</span>            slm_base_0 = slm_base + sg_idy * wg_size_x * N * <span class="keyword">sizeof</span>(T);</div>
<div class="line"><a id="l00156" name="l00156"></a><span class="lineno">  156</span>            slm_base_1 = slm_base_0 + wg_size_x * wg_size_y * N * <span class="keyword">sizeof</span>(T);</div>
<div class="line"><a id="l00157" name="l00157"></a><span class="lineno">  157</span>            itr_count = 0;</div>
<div class="line"><a id="l00158" name="l00158"></a><span class="lineno">  158</span>            group_reduce.init(sg_idx, sg_idy + nbarrier_base, slm_base_0);</div>
<div class="line"><a id="l00159" name="l00159"></a><span class="lineno">  159</span>        }</div>
<div class="line"><a id="l00160" name="l00160"></a><span class="lineno">  160</span> </div>
<div class="line"><a id="l00165" name="l00165"></a><span class="lineno">  165</span>        <span class="keyword">inline</span> <a class="code hl_define" href="group__xetla__core.html#gafb2a0442e367d71b79a2f932d0d39c8b">KERNEL_FUNC</a> <a class="code hl_typedef" href="group__xetla__core__base__types.html#ga8cf5d016d24c8870706e20c376287e04">xetla_vector&lt;T, N&gt;</a> operator()(</div>
<div class="line"><a id="l00166" name="l00166"></a><span class="lineno">  166</span>                <a class="code hl_typedef" href="group__xetla__core__base__types.html#ga8cf5d016d24c8870706e20c376287e04">xetla_vector&lt;T, N * SZ&gt;</a> buffer) {</div>
<div class="line"><a id="l00167" name="l00167"></a><span class="lineno">  167</span>            uint32_t slm_base = (itr_count &amp; 1) ? slm_base_1 : slm_base_0;</div>
<div class="line"><a id="l00168" name="l00168"></a><span class="lineno">  168</span>            group_reduce.set_slm_base(slm_base);</div>
<div class="line"><a id="l00169" name="l00169"></a><span class="lineno">  169</span>            <a class="code hl_typedef" href="group__xetla__core__base__types.html#ga8cf5d016d24c8870706e20c376287e04">xetla_vector&lt;T, N&gt;</a> ret = group_reduce(buffer);</div>
<div class="line"><a id="l00170" name="l00170"></a><span class="lineno">  170</span>            itr_count += 1;</div>
<div class="line"><a id="l00171" name="l00171"></a><span class="lineno">  171</span>            <span class="keywordflow">return</span> ret;</div>
<div class="line"><a id="l00172" name="l00172"></a><span class="lineno">  172</span>        }</div>
<div class="line"><a id="l00173" name="l00173"></a><span class="lineno">  173</span>    };</div>
<div class="line"><a id="l00174" name="l00174"></a><span class="lineno">  174</span> </div>
<div class="line"><a id="l00182" name="l00182"></a><span class="lineno">  182</span>    <span class="keyword">template</span> &lt;uint32_t <a class="code hl_define" href="gemm__softmax_8cpp.html#ad1ab836291a12a078c0b378699e1de73">SIMD</a> = 64 / <span class="keyword">sizeof</span>(dtype_acc)&gt;</div>
<div class="line"><a id="l00183" name="l00183"></a><span class="lineno">  183</span>    <a class="code hl_define" href="common_2core_2common_8hpp.html#a9ed53999886ec13b86a4fe2e0fc16765">__XETLA_API</a> <span class="keyword">static</span> xetla_vector&lt;dtype_acc, sg_tile_n&gt; get_x_temp(</div>
<div class="line"><a id="l00184" name="l00184"></a><span class="lineno">  184</span>            xetla_vector&lt;dtype_x, sg_tile_n&gt; x, dtype_acc rs, dtype_acc mu) {</div>
<div class="line"><a id="l00185" name="l00185"></a><span class="lineno">  185</span>        xetla_vector&lt;dtype_acc, sg_tile_n&gt; x_temp;</div>
<div class="line"><a id="l00186" name="l00186"></a><span class="lineno">  186</span>        xetla_vector&lt;dtype_acc, sg_tile_n&gt; x_acc</div>
<div class="line"><a id="l00187" name="l00187"></a><span class="lineno">  187</span>                = xetla_cvt&lt;dtype_acc, dtype_x&gt;(x);</div>
<div class="line"><a id="l00189" name="l00189"></a><span class="lineno">  189</span><span class="preprocessor">#pragma unroll</span></div>
<div class="line"><a id="l00190" name="l00190"></a><span class="lineno">  190</span>        <span class="keywordflow">for</span> (<span class="keywordtype">int</span> i = 0; i &lt; sg_tile_n / <a class="code hl_define" href="gemm__softmax_8cpp.html#ad1ab836291a12a078c0b378699e1de73">SIMD</a>; i++) {</div>
<div class="line"><a id="l00191" name="l00191"></a><span class="lineno">  191</span>            x_temp.xetla_select&lt;<a class="code hl_define" href="gemm__softmax_8cpp.html#ad1ab836291a12a078c0b378699e1de73">SIMD</a>, 1&gt;(i * <a class="code hl_define" href="gemm__softmax_8cpp.html#ad1ab836291a12a078c0b378699e1de73">SIMD</a>)</div>
<div class="line"><a id="l00192" name="l00192"></a><span class="lineno">  192</span>                    = rs * (x_acc.xetla_select&lt;<a class="code hl_define" href="gemm__softmax_8cpp.html#ad1ab836291a12a078c0b378699e1de73">SIMD</a>, 1&gt;(i * <a class="code hl_define" href="gemm__softmax_8cpp.html#ad1ab836291a12a078c0b378699e1de73">SIMD</a>) - mu);</div>
<div class="line"><a id="l00193" name="l00193"></a><span class="lineno">  193</span>        }</div>
<div class="line"><a id="l00194" name="l00194"></a><span class="lineno">  194</span>        <span class="keywordflow">if</span> <span class="keyword">constexpr</span> ((sg_tile_n % <a class="code hl_define" href="gemm__softmax_8cpp.html#ad1ab836291a12a078c0b378699e1de73">SIMD</a>) != 0) {</div>
<div class="line"><a id="l00195" name="l00195"></a><span class="lineno">  195</span>            <span class="keyword">constexpr</span> uint32_t start = sg_tile_n / <a class="code hl_define" href="gemm__softmax_8cpp.html#ad1ab836291a12a078c0b378699e1de73">SIMD</a> * <a class="code hl_define" href="gemm__softmax_8cpp.html#ad1ab836291a12a078c0b378699e1de73">SIMD</a>;</div>
<div class="line"><a id="l00196" name="l00196"></a><span class="lineno">  196</span>            <span class="keyword">constexpr</span> uint32_t SIMD_tail = sg_tile_n % <a class="code hl_define" href="gemm__softmax_8cpp.html#ad1ab836291a12a078c0b378699e1de73">SIMD</a>;</div>
<div class="line"><a id="l00197" name="l00197"></a><span class="lineno">  197</span>            x_temp.xetla_select&lt;SIMD_tail, 1&gt;(start)</div>
<div class="line"><a id="l00198" name="l00198"></a><span class="lineno">  198</span>                    = rs * (x_acc.xetla_select&lt;SIMD_tail, 1&gt;(start) - mu);</div>
<div class="line"><a id="l00199" name="l00199"></a><span class="lineno">  199</span>        }</div>
<div class="line"><a id="l00200" name="l00200"></a><span class="lineno">  200</span>        <span class="keywordflow">return</span> x_temp;</div>
<div class="line"><a id="l00201" name="l00201"></a><span class="lineno">  201</span>    }</div>
<div class="line"><a id="l00202" name="l00202"></a><span class="lineno">  202</span> </div>
<div class="line"><a id="l00209" name="l00209"></a><span class="lineno">  209</span>    <span class="keyword">template</span> &lt;uint32_t <a class="code hl_define" href="gemm__softmax_8cpp.html#ad1ab836291a12a078c0b378699e1de73">SIMD</a> = 64 / <span class="keyword">sizeof</span>(dtype_acc)&gt;</div>
<div class="line"><a id="l00210" name="l00210"></a><span class="lineno">  210</span>    <a class="code hl_define" href="common_2core_2common_8hpp.html#a9ed53999886ec13b86a4fe2e0fc16765">__XETLA_API</a> <span class="keyword">static</span> xetla_vector&lt;dtype_acc, sg_tile_n&gt; get_dy_temp(</div>
<div class="line"><a id="l00211" name="l00211"></a><span class="lineno">  211</span>            xetla_vector&lt;dtype_weight, sg_tile_n&gt; gamma,</div>
<div class="line"><a id="l00212" name="l00212"></a><span class="lineno">  212</span>            xetla_vector&lt;dtype_acc, sg_tile_n&gt; dy) {</div>
<div class="line"><a id="l00213" name="l00213"></a><span class="lineno">  213</span>        xetla_vector&lt;dtype_acc, sg_tile_n&gt; dy_temp;</div>
<div class="line"><a id="l00214" name="l00214"></a><span class="lineno">  214</span>        xetla_vector&lt;dtype_acc, sg_tile_n&gt; gamma_acc</div>
<div class="line"><a id="l00215" name="l00215"></a><span class="lineno">  215</span>                = xetla_cvt&lt;dtype_acc, dtype_weight&gt;(gamma);</div>
<div class="line"><a id="l00217" name="l00217"></a><span class="lineno">  217</span><span class="preprocessor">#pragma unroll</span></div>
<div class="line"><a id="l00218" name="l00218"></a><span class="lineno">  218</span>        <span class="keywordflow">for</span> (<span class="keywordtype">int</span> i = 0; i &lt; sg_tile_n / <a class="code hl_define" href="gemm__softmax_8cpp.html#ad1ab836291a12a078c0b378699e1de73">SIMD</a>; i++) {</div>
<div class="line"><a id="l00219" name="l00219"></a><span class="lineno">  219</span>            dy_temp.xetla_select&lt;<a class="code hl_define" href="gemm__softmax_8cpp.html#ad1ab836291a12a078c0b378699e1de73">SIMD</a>, 1&gt;(i * <a class="code hl_define" href="gemm__softmax_8cpp.html#ad1ab836291a12a078c0b378699e1de73">SIMD</a>)</div>
<div class="line"><a id="l00220" name="l00220"></a><span class="lineno">  220</span>                    = gamma_acc.xetla_select&lt;<a class="code hl_define" href="gemm__softmax_8cpp.html#ad1ab836291a12a078c0b378699e1de73">SIMD</a>, 1&gt;(i * <a class="code hl_define" href="gemm__softmax_8cpp.html#ad1ab836291a12a078c0b378699e1de73">SIMD</a>)</div>
<div class="line"><a id="l00221" name="l00221"></a><span class="lineno">  221</span>                    * dy.xetla_select&lt;<a class="code hl_define" href="gemm__softmax_8cpp.html#ad1ab836291a12a078c0b378699e1de73">SIMD</a>, 1&gt;(i * <a class="code hl_define" href="gemm__softmax_8cpp.html#ad1ab836291a12a078c0b378699e1de73">SIMD</a>);</div>
<div class="line"><a id="l00222" name="l00222"></a><span class="lineno">  222</span>        }</div>
<div class="line"><a id="l00223" name="l00223"></a><span class="lineno">  223</span>        <span class="keywordflow">if</span> <span class="keyword">constexpr</span> ((sg_tile_n % <a class="code hl_define" href="gemm__softmax_8cpp.html#ad1ab836291a12a078c0b378699e1de73">SIMD</a>) != 0) {</div>
<div class="line"><a id="l00224" name="l00224"></a><span class="lineno">  224</span>            <span class="keyword">constexpr</span> uint32_t start = sg_tile_n / <a class="code hl_define" href="gemm__softmax_8cpp.html#ad1ab836291a12a078c0b378699e1de73">SIMD</a> * <a class="code hl_define" href="gemm__softmax_8cpp.html#ad1ab836291a12a078c0b378699e1de73">SIMD</a>;</div>
<div class="line"><a id="l00225" name="l00225"></a><span class="lineno">  225</span>            <span class="keyword">constexpr</span> uint32_t SIMD_tail = sg_tile_n % <a class="code hl_define" href="gemm__softmax_8cpp.html#ad1ab836291a12a078c0b378699e1de73">SIMD</a>;</div>
<div class="line"><a id="l00226" name="l00226"></a><span class="lineno">  226</span>            dy_temp.xetla_select&lt;SIMD_tail, 1&gt;(start)</div>
<div class="line"><a id="l00227" name="l00227"></a><span class="lineno">  227</span>                    = gamma_acc.xetla_select&lt;SIMD_tail, 1&gt;(start)</div>
<div class="line"><a id="l00228" name="l00228"></a><span class="lineno">  228</span>                    * dy.xetla_select&lt;SIMD_tail, 1&gt;(start);</div>
<div class="line"><a id="l00229" name="l00229"></a><span class="lineno">  229</span>        }</div>
<div class="line"><a id="l00230" name="l00230"></a><span class="lineno">  230</span>        <span class="keywordflow">return</span> dy_temp;</div>
<div class="line"><a id="l00231" name="l00231"></a><span class="lineno">  231</span>    }</div>
<div class="line"><a id="l00232" name="l00232"></a><span class="lineno">  232</span>    <span class="keyword">using </span>wg_col_reduce_t = ln_group_all_reduce_t&lt;dtype_acc, sg_tile_n, 2,</div>
<div class="line"><a id="l00233" name="l00233"></a><span class="lineno">  233</span>            <a class="code hl_enumvalue" href="namespacegpu_1_1xetla.html#a7bbd70f1164d3a7251729e89fffc0609a1d623b89683f9ce4e074de1676d12416">reduce_op::sum</a>, wg_size_x, wg_size_y, <a class="code hl_enumvalue" href="group__xetla__core__arch__config.html#ggaa5a2713edb27d6fed88a3c61673556f1a8fde9df1bf2567b76160d1beedca3130">gpu_arch::Xe</a>&gt;;</div>
<div class="line"><a id="l00234" name="l00234"></a><span class="lineno">  234</span> </div>
<div class="line"><a id="l00235" name="l00235"></a><span class="lineno">  235</span><span class="keyword">public</span>:</div>
<div class="line"><a id="l00236" name="l00236"></a><span class="lineno"><a class="line" href="structgpu_1_1xetla_1_1kernel_1_1layer__norm__bwd__t_3_01dtype__x___00_01dtype__y___00_01dtype__w5e223ea0bd3a3851e47c460f10bccc84.html#a10a5dbca611a06d6ef29b741824cdc22">  236</a></span>    <a class="code hl_define" href="common_2core_2common_8hpp.html#a9ed53999886ec13b86a4fe2e0fc16765">__XETLA_API</a> <span class="keyword">static</span> <span class="keywordtype">void</span> <a class="code hl_function" href="structgpu_1_1xetla_1_1kernel_1_1layer__norm__bwd__t_3_01dtype__x___00_01dtype__y___00_01dtype__w5e223ea0bd3a3851e47c460f10bccc84.html#a10a5dbca611a06d6ef29b741824cdc22">call</a>(<a class="code hl_class" href="classgpu_1_1xetla_1_1xetla__exec__item.html">xetla_exec_item&lt;3&gt;</a> &amp;ei, arguments_t *args,</div>
<div class="line"><a id="l00237" name="l00237"></a><span class="lineno">  237</span>            uint32_t slm_base = 0, uint32_t nbarrier_base = 0,</div>
<div class="line"><a id="l00238" name="l00238"></a><span class="lineno">  238</span>            <a class="code hl_typedef" href="structgpu_1_1xetla_1_1kernel_1_1layer__norm__bwd__t_3_01dtype__x___00_01dtype__y___00_01dtype__w5e223ea0bd3a3851e47c460f10bccc84.html#a856d703aca448075c793a40d821d87ca">ln_fused_op_arguments_t</a> *fused_op_args = <span class="keyword">nullptr</span>) {</div>
<div class="line"><a id="l00239" name="l00239"></a><span class="lineno">  239</span>        <a class="code hl_typedef" href="structgpu_1_1xetla_1_1kernel_1_1layer__norm__bwd__t_3_01dtype__x___00_01dtype__y___00_01dtype__w5e223ea0bd3a3851e47c460f10bccc84.html#ab8f68b77c72bf88647ee8f0f4194b86f">work_group_t</a> g;</div>
<div class="line"><a id="l00240" name="l00240"></a><span class="lineno">  240</span>        g.init(ei.<a class="code hl_function" href="classgpu_1_1xetla_1_1xetla__exec__item.html#a740f63e18f312690bfae48783da27644">get_local_linear_id</a>());</div>
<div class="line"><a id="l00241" name="l00241"></a><span class="lineno">  241</span>        uint32_t sg_idx = g.get_id() % wg_size_x;</div>
<div class="line"><a id="l00242" name="l00242"></a><span class="lineno">  242</span>        uint32_t sg_idy = g.get_id() / wg_size_x;</div>
<div class="line"><a id="l00243" name="l00243"></a><span class="lineno">  243</span>        uint32_t wg_idx = ei.<a class="code hl_function" href="classgpu_1_1xetla_1_1xetla__exec__item.html#ac46733b57cc482439c9f7e13916c1514">get_group</a>(2);</div>
<div class="line"><a id="l00244" name="l00244"></a><span class="lineno">  244</span>        uint32_t wg_idy = ei.<a class="code hl_function" href="classgpu_1_1xetla_1_1xetla__exec__item.html#ac46733b57cc482439c9f7e13916c1514">get_group</a>(1);</div>
<div class="line"><a id="l00245" name="l00245"></a><span class="lineno">  245</span>        <span class="keywordtype">int</span> start_n = wg_idx * wg_tile_n + sg_idx * sg_tile_n;</div>
<div class="line"><a id="l00246" name="l00246"></a><span class="lineno">  246</span>        <span class="keywordtype">int</span> start_m = wg_idy * wg_tile_m + sg_idy * sg_tile_m;</div>
<div class="line"><a id="l00247" name="l00247"></a><span class="lineno">  247</span> </div>
<div class="line"><a id="l00248" name="l00248"></a><span class="lineno">  248</span>        <a class="code hl_struct" href="structgpu_1_1xetla_1_1subgroup_1_1tile__t.html">x_in_t</a> x_in;</div>
<div class="line"><a id="l00249" name="l00249"></a><span class="lineno">  249</span>        <a class="code hl_struct" href="structgpu_1_1xetla_1_1subgroup_1_1mem__payload__t.html">x_in_payload_t</a> x_in_payload;</div>
<div class="line"><a id="l00250" name="l00250"></a><span class="lineno">  250</span>        <a class="code hl_struct" href="structgpu_1_1xetla_1_1subgroup_1_1tile__t.html">dy_in_t</a> dy_in;</div>
<div class="line"><a id="l00251" name="l00251"></a><span class="lineno">  251</span>        <a class="code hl_struct" href="structgpu_1_1xetla_1_1subgroup_1_1mem__payload__t.html">dy_in_payload_t</a> dy_in_payload;</div>
<div class="line"><a id="l00252" name="l00252"></a><span class="lineno">  252</span>        <a class="code hl_struct" href="structgpu_1_1xetla_1_1subgroup_1_1tile__t.html">gamma_in_t</a> gamma_in;</div>
<div class="line"><a id="l00253" name="l00253"></a><span class="lineno">  253</span>        <a class="code hl_struct" href="structgpu_1_1xetla_1_1subgroup_1_1mem__payload__t.html">gamma_in_payload_t</a> gamma_in_payload;</div>
<div class="line"><a id="l00254" name="l00254"></a><span class="lineno">  254</span>        <a class="code hl_struct" href="structgpu_1_1xetla_1_1subgroup_1_1tile__t.html">dx_out_t</a> dx_out;</div>
<div class="line"><a id="l00255" name="l00255"></a><span class="lineno">  255</span>        <a class="code hl_struct" href="structgpu_1_1xetla_1_1subgroup_1_1mem__payload__t.html">dx_out_payload_t</a> dx_out_payload;</div>
<div class="line"><a id="l00256" name="l00256"></a><span class="lineno">  256</span>        <a class="code hl_typedef" href="structgpu_1_1xetla_1_1kernel_1_1layer__norm__bwd__t_3_01dtype__x___00_01dtype__y___00_01dtype__w5e223ea0bd3a3851e47c460f10bccc84.html#abb73d94fccf7341dd998753a3a6978c2">ln_bwd_fused_op</a> fused_op;</div>
<div class="line"><a id="l00257" name="l00257"></a><span class="lineno">  257</span>        x_in_payload.init(args-&gt;x_in_ptr, args-&gt;matrix_n, args-&gt;matrix_m,</div>
<div class="line"><a id="l00258" name="l00258"></a><span class="lineno">  258</span>                args-&gt;mat_ld, start_n, start_m);</div>
<div class="line"><a id="l00259" name="l00259"></a><span class="lineno">  259</span>        dy_in_payload.init(args-&gt;dy_in_ptr, args-&gt;matrix_n, args-&gt;matrix_m,</div>
<div class="line"><a id="l00260" name="l00260"></a><span class="lineno">  260</span>                args-&gt;mat_ld, start_n, start_m);</div>
<div class="line"><a id="l00261" name="l00261"></a><span class="lineno">  261</span>        gamma_in_payload.init(args-&gt;gamma_in_ptr, args-&gt;matrix_n, 1,</div>
<div class="line"><a id="l00262" name="l00262"></a><span class="lineno">  262</span>                args-&gt;mat_ld, start_n, 0);</div>
<div class="line"><a id="l00263" name="l00263"></a><span class="lineno">  263</span>        dx_out_payload.init(args-&gt;dx_out_ptr, args-&gt;matrix_n, args-&gt;matrix_m,</div>
<div class="line"><a id="l00264" name="l00264"></a><span class="lineno">  264</span>                args-&gt;mat_ld, start_n, start_m);</div>
<div class="line"><a id="l00265" name="l00265"></a><span class="lineno">  265</span>        fused_op.init(fused_op_args, wg_idx, wg_idy, sg_idx, sg_idy);</div>
<div class="line"><a id="l00266" name="l00266"></a><span class="lineno">  266</span>        <a class="code hl_function" href="namespacegpu_1_1xetla_1_1subgroup.html#ae110043dd5332ce2a7ef91d2c8ae79ef">subgroup::tile_load</a>(gamma_in, gamma_in_payload);</div>
<div class="line"><a id="l00267" name="l00267"></a><span class="lineno">  267</span> </div>
<div class="line"><a id="l00268" name="l00268"></a><span class="lineno">  268</span>        <span class="keyword">const</span> <a class="code hl_typedef" href="structgpu_1_1xetla_1_1kernel_1_1layer__norm__bwd__t_3_01dtype__x___00_01dtype__y___00_01dtype__w5e223ea0bd3a3851e47c460f10bccc84.html#a5c5444009eda1cc73b8538d63dc78f94">dtype_acc</a> wg_rn = 1.0f / wg_tile_n;</div>
<div class="line"><a id="l00269" name="l00269"></a><span class="lineno">  269</span> </div>
<div class="line"><a id="l00270" name="l00270"></a><span class="lineno">  270</span>        wg_col_reduce_t wg_col_reduce(sg_idx, sg_idy, slm_base, nbarrier_base);</div>
<div class="line"><a id="l00271" name="l00271"></a><span class="lineno">  271</span> </div>
<div class="line"><a id="l00272" name="l00272"></a><span class="lineno">  272</span>        <a class="code hl_typedef" href="group__xetla__core__base__types.html#ga8cf5d016d24c8870706e20c376287e04">xetla_vector&lt;dtype_acc, sg_tile_n&gt;</a> dgamma = 0;</div>
<div class="line"><a id="l00273" name="l00273"></a><span class="lineno">  273</span>        <a class="code hl_typedef" href="group__xetla__core__base__types.html#ga8cf5d016d24c8870706e20c376287e04">xetla_vector&lt;dtype_acc, sg_tile_n&gt;</a> dbeta = 0;</div>
<div class="line"><a id="l00274" name="l00274"></a><span class="lineno">  274</span> </div>
<div class="line"><a id="l00275" name="l00275"></a><span class="lineno">  275</span>        <span class="keywordflow">for</span> (<span class="keywordtype">int</span> row = start_m; row &lt; args-&gt;matrix_m;</div>
<div class="line"><a id="l00276" name="l00276"></a><span class="lineno">  276</span>                row += wg_num_m * wg_tile_m) {</div>
<div class="line"><a id="l00277" name="l00277"></a><span class="lineno">  277</span>            <a class="code hl_function" href="namespacegpu_1_1xetla_1_1subgroup.html#ae110043dd5332ce2a7ef91d2c8ae79ef">subgroup::tile_load</a>(dy_in, dy_in_payload);</div>
<div class="line"><a id="l00278" name="l00278"></a><span class="lineno">  278</span>            <a class="code hl_function" href="namespacegpu_1_1xetla_1_1subgroup.html#ae110043dd5332ce2a7ef91d2c8ae79ef">subgroup::tile_load</a>(x_in, x_in_payload);</div>
<div class="line"><a id="l00279" name="l00279"></a><span class="lineno">  279</span>            <a class="code hl_typedef" href="group__xetla__core__base__types.html#ga8cf5d016d24c8870706e20c376287e04">xetla_vector&lt;dtype_acc, 1&gt;</a> mu_v</div>
<div class="line"><a id="l00280" name="l00280"></a><span class="lineno">  280</span>                    = <a class="code hl_function" href="group__xetla__core__memory.html#ga103379b76c960b4967704e057b7969ba">xetla_load_global</a>&lt;<a class="code hl_typedef" href="structgpu_1_1xetla_1_1kernel_1_1layer__norm__bwd__t_3_01dtype__x___00_01dtype__y___00_01dtype__w5e223ea0bd3a3851e47c460f10bccc84.html#a5c5444009eda1cc73b8538d63dc78f94">dtype_acc</a>, 1, <a class="code hl_enumvalue" href="namespacegpu_1_1xetla.html#a2cf716afc0eaf0c0a87c572193d7ca76a6bad67b5e8990b5f40b54dddd984ea08">data_size::default_size</a>,</div>
<div class="line"><a id="l00281" name="l00281"></a><span class="lineno">  281</span>                            <a class="code hl_enumvalue" href="namespacegpu_1_1xetla.html#a23ee6c8b836eb63360633951d75d7e30a1fb1a060534164a18a99494122825190">cache_hint::cached</a>, <a class="code hl_enumvalue" href="namespacegpu_1_1xetla.html#a23ee6c8b836eb63360633951d75d7e30a1fb1a060534164a18a99494122825190">cache_hint::cached</a>&gt;(</div>
<div class="line"><a id="l00282" name="l00282"></a><span class="lineno">  282</span>                            args-&gt;mu_ptr, row * <span class="keyword">sizeof</span>(<a class="code hl_typedef" href="structgpu_1_1xetla_1_1kernel_1_1layer__norm__bwd__t_3_01dtype__x___00_01dtype__y___00_01dtype__w5e223ea0bd3a3851e47c460f10bccc84.html#a5c5444009eda1cc73b8538d63dc78f94">dtype_acc</a>));</div>
<div class="line"><a id="l00283" name="l00283"></a><span class="lineno">  283</span>            <a class="code hl_typedef" href="group__xetla__core__base__types.html#ga8cf5d016d24c8870706e20c376287e04">xetla_vector&lt;dtype_acc, 1&gt;</a> rs_v</div>
<div class="line"><a id="l00284" name="l00284"></a><span class="lineno">  284</span>                    = <a class="code hl_function" href="group__xetla__core__memory.html#ga103379b76c960b4967704e057b7969ba">xetla_load_global</a>&lt;<a class="code hl_typedef" href="structgpu_1_1xetla_1_1kernel_1_1layer__norm__bwd__t_3_01dtype__x___00_01dtype__y___00_01dtype__w5e223ea0bd3a3851e47c460f10bccc84.html#a5c5444009eda1cc73b8538d63dc78f94">dtype_acc</a>, 1, <a class="code hl_enumvalue" href="namespacegpu_1_1xetla.html#a2cf716afc0eaf0c0a87c572193d7ca76a6bad67b5e8990b5f40b54dddd984ea08">data_size::default_size</a>,</div>
<div class="line"><a id="l00285" name="l00285"></a><span class="lineno">  285</span>                            <a class="code hl_enumvalue" href="namespacegpu_1_1xetla.html#a23ee6c8b836eb63360633951d75d7e30a1fb1a060534164a18a99494122825190">cache_hint::cached</a>, <a class="code hl_enumvalue" href="namespacegpu_1_1xetla.html#a23ee6c8b836eb63360633951d75d7e30a1fb1a060534164a18a99494122825190">cache_hint::cached</a>&gt;(</div>
<div class="line"><a id="l00286" name="l00286"></a><span class="lineno">  286</span>                            args-&gt;rs_ptr, row * <span class="keyword">sizeof</span>(<a class="code hl_typedef" href="structgpu_1_1xetla_1_1kernel_1_1layer__norm__bwd__t_3_01dtype__x___00_01dtype__y___00_01dtype__w5e223ea0bd3a3851e47c460f10bccc84.html#a5c5444009eda1cc73b8538d63dc78f94">dtype_acc</a>));</div>
<div class="line"><a id="l00287" name="l00287"></a><span class="lineno">  287</span>            <a class="code hl_typedef" href="structgpu_1_1xetla_1_1kernel_1_1layer__norm__bwd__t_3_01dtype__x___00_01dtype__y___00_01dtype__w5e223ea0bd3a3851e47c460f10bccc84.html#a5c5444009eda1cc73b8538d63dc78f94">dtype_acc</a> mu = mu_v[0];</div>
<div class="line"><a id="l00288" name="l00288"></a><span class="lineno">  288</span>            <a class="code hl_typedef" href="structgpu_1_1xetla_1_1kernel_1_1layer__norm__bwd__t_3_01dtype__x___00_01dtype__y___00_01dtype__w5e223ea0bd3a3851e47c460f10bccc84.html#a5c5444009eda1cc73b8538d63dc78f94">dtype_acc</a> rs = rs_v[0];</div>
<div class="line"><a id="l00289" name="l00289"></a><span class="lineno">  289</span>            dy_in_payload.update_tdesc(wg_num_m * wg_tile_m * args-&gt;mat_ld);</div>
<div class="line"><a id="l00290" name="l00290"></a><span class="lineno">  290</span>            x_in_payload.update_tdesc(wg_num_m * wg_tile_m * args-&gt;mat_ld);</div>
<div class="line"><a id="l00291" name="l00291"></a><span class="lineno">  291</span> </div>
<div class="line"><a id="l00292" name="l00292"></a><span class="lineno">  292</span>            <a class="code hl_typedef" href="group__xetla__core__base__types.html#ga8cf5d016d24c8870706e20c376287e04">xetla_vector&lt;dtype_acc, sg_tile_n&gt;</a> dy</div>
<div class="line"><a id="l00293" name="l00293"></a><span class="lineno">  293</span>                    = xetla_cvt&lt;dtype_acc, dtype_y&gt;(dy_in.<a class="code hl_variable" href="structgpu_1_1xetla_1_1subgroup_1_1tile__t.html#a7985ceac15e399ebf3000e5693d8801e">reg</a>);</div>
<div class="line"><a id="l00294" name="l00294"></a><span class="lineno">  294</span>            dy = fused_op.pre_op(dy);</div>
<div class="line"><a id="l00295" name="l00295"></a><span class="lineno">  295</span>            <a class="code hl_typedef" href="group__xetla__core__base__types.html#ga8cf5d016d24c8870706e20c376287e04">xetla_vector&lt;dtype_acc, sg_tile_n&gt;</a> x_temp</div>
<div class="line"><a id="l00296" name="l00296"></a><span class="lineno">  296</span>                    = get_x_temp(x_in.<a class="code hl_variable" href="structgpu_1_1xetla_1_1subgroup_1_1tile__t.html#a7985ceac15e399ebf3000e5693d8801e">reg</a>, rs, mu);</div>
<div class="line"><a id="l00297" name="l00297"></a><span class="lineno">  297</span>            <a class="code hl_typedef" href="group__xetla__core__base__types.html#ga8cf5d016d24c8870706e20c376287e04">xetla_vector&lt;dtype_acc, sg_tile_n&gt;</a> dy_temp</div>
<div class="line"><a id="l00298" name="l00298"></a><span class="lineno">  298</span>                    = get_dy_temp(gamma_in.<a class="code hl_variable" href="structgpu_1_1xetla_1_1subgroup_1_1tile__t.html#a7985ceac15e399ebf3000e5693d8801e">reg</a>, dy);</div>
<div class="line"><a id="l00299" name="l00299"></a><span class="lineno">  299</span>            dgamma += dy * x_temp;</div>
<div class="line"><a id="l00300" name="l00300"></a><span class="lineno">  300</span>            dbeta += dy;</div>
<div class="line"><a id="l00301" name="l00301"></a><span class="lineno">  301</span>            <a class="code hl_typedef" href="group__xetla__core__base__types.html#ga8cf5d016d24c8870706e20c376287e04">xetla_vector&lt;dtype_acc, sg_tile_n * 2&gt;</a> buffer;</div>
<div class="line"><a id="l00302" name="l00302"></a><span class="lineno">  302</span>            <span class="keyword">auto</span> buffer_2d = buffer.xetla_format&lt;<a class="code hl_typedef" href="structgpu_1_1xetla_1_1kernel_1_1layer__norm__bwd__t_3_01dtype__x___00_01dtype__y___00_01dtype__w5e223ea0bd3a3851e47c460f10bccc84.html#a5c5444009eda1cc73b8538d63dc78f94">dtype_acc</a>, 2, sg_tile_n&gt;();</div>
<div class="line"><a id="l00303" name="l00303"></a><span class="lineno">  303</span>            buffer_2d.row(0) = dy_temp;</div>
<div class="line"><a id="l00304" name="l00304"></a><span class="lineno">  304</span>            buffer_2d.row(1) = x_temp * dy_temp;</div>
<div class="line"><a id="l00305" name="l00305"></a><span class="lineno">  305</span>            <a class="code hl_typedef" href="group__xetla__core__base__types.html#ga8cf5d016d24c8870706e20c376287e04">xetla_vector&lt;dtype_acc, 2&gt;</a> grad_0_1 = wg_col_reduce(buffer);</div>
<div class="line"><a id="l00306" name="l00306"></a><span class="lineno">  306</span>            <a class="code hl_typedef" href="structgpu_1_1xetla_1_1kernel_1_1layer__norm__bwd__t_3_01dtype__x___00_01dtype__y___00_01dtype__w5e223ea0bd3a3851e47c460f10bccc84.html#a5c5444009eda1cc73b8538d63dc78f94">dtype_acc</a> grad_0 = grad_0_1[0] * wg_rn;</div>
<div class="line"><a id="l00307" name="l00307"></a><span class="lineno">  307</span>            <a class="code hl_typedef" href="structgpu_1_1xetla_1_1kernel_1_1layer__norm__bwd__t_3_01dtype__x___00_01dtype__y___00_01dtype__w5e223ea0bd3a3851e47c460f10bccc84.html#a5c5444009eda1cc73b8538d63dc78f94">dtype_acc</a> grad_1 = grad_0_1[1] * wg_rn;</div>
<div class="line"><a id="l00308" name="l00308"></a><span class="lineno">  308</span>            <a class="code hl_typedef" href="group__xetla__core__base__types.html#ga8cf5d016d24c8870706e20c376287e04">xetla_vector&lt;dtype_acc, sg_tile_n&gt;</a> dx</div>
<div class="line"><a id="l00309" name="l00309"></a><span class="lineno">  309</span>                    = rs * (dy_temp - (grad_1 * x_temp + grad_0));</div>
<div class="line"><a id="l00310" name="l00310"></a><span class="lineno">  310</span>            dx = fused_op.post_op(dx);</div>
<div class="line"><a id="l00311" name="l00311"></a><span class="lineno">  311</span>            dx_out.<a class="code hl_variable" href="structgpu_1_1xetla_1_1subgroup_1_1tile__t.html#a7985ceac15e399ebf3000e5693d8801e">reg</a> = xetla_cvt&lt;dtype_x, dtype_acc&gt;(dx);</div>
<div class="line"><a id="l00312" name="l00312"></a><span class="lineno">  312</span>            subgroup::tile_store&lt;cache_hint::uncached&gt;(dx_out, dx_out_payload);</div>
<div class="line"><a id="l00313" name="l00313"></a><span class="lineno">  313</span>            dx_out_payload.update_tdesc(wg_num_m * wg_tile_m * args-&gt;mat_ld);</div>
<div class="line"><a id="l00314" name="l00314"></a><span class="lineno">  314</span>        }</div>
<div class="line"><a id="l00315" name="l00315"></a><span class="lineno">  315</span> </div>
<div class="line"><a id="l00316" name="l00316"></a><span class="lineno">  316</span>        <a class="code hl_struct" href="structgpu_1_1xetla_1_1group_1_1group__row__reduce__store__t.html">ln_group_row_reduce_store_t</a> ln_group_row_reduce;</div>
<div class="line"><a id="l00317" name="l00317"></a><span class="lineno">  317</span>        uint32_t slm_row_reduce_base = slm_base + size_col_reduce;</div>
<div class="line"><a id="l00318" name="l00318"></a><span class="lineno">  318</span>        uint32_t nbarrier_row_reduce_base = nbarrier_base + count_col_reduce;</div>
<div class="line"><a id="l00319" name="l00319"></a><span class="lineno">  319</span>        ln_group_row_reduce.init(</div>
<div class="line"><a id="l00320" name="l00320"></a><span class="lineno">  320</span>                sg_idx, sg_idy, slm_row_reduce_base, nbarrier_row_reduce_base);</div>
<div class="line"><a id="l00322" name="l00322"></a><span class="lineno">  322</span>        ln_group_row_reduce(args-&gt;dgamma_acc_ptr, args-&gt;matrix_n, wg_num_m,</div>
<div class="line"><a id="l00323" name="l00323"></a><span class="lineno">  323</span>                args-&gt;matrix_n, start_n, wg_idy, dgamma);</div>
<div class="line"><a id="l00324" name="l00324"></a><span class="lineno">  324</span>        ln_group_row_reduce(args-&gt;dbeta_acc_ptr, args-&gt;matrix_n, wg_num_m,</div>
<div class="line"><a id="l00325" name="l00325"></a><span class="lineno">  325</span>                args-&gt;matrix_n, start_n, wg_idy, dbeta);</div>
<div class="line"><a id="l00326" name="l00326"></a><span class="lineno">  326</span>        fused_op.final_op(ln_group_row_reduce);</div>
<div class="line"><a id="l00327" name="l00327"></a><span class="lineno">  327</span>    }</div>
<div class="line"><a id="l00328" name="l00328"></a><span class="lineno">  328</span>};</div>
<div class="line"><a id="l00329" name="l00329"></a><span class="lineno">  329</span> </div>
<div class="line"><a id="l00330" name="l00330"></a><span class="lineno">  330</span>} <span class="comment">// namespace gpu::xetla::kernel</span></div>
<div class="ttc" id="aclassgpu_1_1xetla_1_1xetla__exec__item_html"><div class="ttname"><a href="classgpu_1_1xetla_1_1xetla__exec__item.html">gpu::xetla::xetla_exec_item</a></div><div class="ttdoc">The item struct to explict identify the group / local id information.</div><div class="ttdef"><b>Definition:</b> execution_item.hpp:31</div></div>
<div class="ttc" id="aclassgpu_1_1xetla_1_1xetla__exec__item_html_a740f63e18f312690bfae48783da27644"><div class="ttname"><a href="classgpu_1_1xetla_1_1xetla__exec__item.html#a740f63e18f312690bfae48783da27644">gpu::xetla::xetla_exec_item::get_local_linear_id</a></div><div class="ttdeci">uint32_t get_local_linear_id() const</div><div class="ttdoc">Returns local linear id in the work group.</div><div class="ttdef"><b>Definition:</b> execution_item.hpp:66</div></div>
<div class="ttc" id="aclassgpu_1_1xetla_1_1xetla__exec__item_html_ac46733b57cc482439c9f7e13916c1514"><div class="ttname"><a href="classgpu_1_1xetla_1_1xetla__exec__item.html#ac46733b57cc482439c9f7e13916c1514">gpu::xetla::xetla_exec_item::get_group</a></div><div class="ttdeci">uint32_t get_group(int dimension) const</div><div class="ttdoc">Returns the group id for the requested dimensions.</div><div class="ttdef"><b>Definition:</b> execution_item.hpp:40</div></div>
<div class="ttc" id="acommon_2core_2common_8hpp_html_a9ed53999886ec13b86a4fe2e0fc16765"><div class="ttname"><a href="common_2core_2common_8hpp.html#a9ed53999886ec13b86a4fe2e0fc16765">__XETLA_API</a></div><div class="ttdeci">#define __XETLA_API</div><div class="ttdef"><b>Definition:</b> common.hpp:43</div></div>
<div class="ttc" id="aexperimental_2kernel_2layer__norm_2api_8hpp_html"><div class="ttname"><a href="experimental_2kernel_2layer__norm_2api_8hpp.html">api.hpp</a></div><div class="ttdoc">C++ API.</div></div>
<div class="ttc" id="aexperimental_2kernel_2layer__norm_2common_8hpp_html"><div class="ttname"><a href="experimental_2kernel_2layer__norm_2common_8hpp.html">common.hpp</a></div><div class="ttdoc">C++ API.</div></div>
<div class="ttc" id="agemm__softmax_8cpp_html_ad1ab836291a12a078c0b378699e1de73"><div class="ttname"><a href="gemm__softmax_8cpp.html#ad1ab836291a12a078c0b378699e1de73">SIMD</a></div><div class="ttdeci">#define SIMD</div><div class="ttdef"><b>Definition:</b> gemm_softmax.cpp:23</div></div>
<div class="ttc" id="agroup__xetla__core__arch__config_html_gaa5a2713edb27d6fed88a3c61673556f1"><div class="ttname"><a href="group__xetla__core__arch__config.html#gaa5a2713edb27d6fed88a3c61673556f1">gpu::xetla::gpu_arch</a></div><div class="ttdeci">gpu_arch</div><div class="ttdef"><b>Definition:</b> arch_config.hpp:28</div></div>
<div class="ttc" id="agroup__xetla__core__arch__config_html_ggaa5a2713edb27d6fed88a3c61673556f1a8fde9df1bf2567b76160d1beedca3130"><div class="ttname"><a href="group__xetla__core__arch__config.html#ggaa5a2713edb27d6fed88a3c61673556f1a8fde9df1bf2567b76160d1beedca3130">gpu::xetla::gpu_arch::Xe</a></div><div class="ttdeci">@ Xe</div></div>
<div class="ttc" id="agroup__xetla__core__base__types_html_ga8cf5d016d24c8870706e20c376287e04"><div class="ttname"><a href="group__xetla__core__base__types.html#ga8cf5d016d24c8870706e20c376287e04">gpu::xetla::xetla_vector</a></div><div class="ttdeci">__ESIMD_NS::simd&lt; native_type_t&lt; Ty &gt;, N &gt; xetla_vector</div><div class="ttdoc">wrapper for xetla_vector.</div><div class="ttdef"><b>Definition:</b> base_types.hpp:167</div></div>
<div class="ttc" id="agroup__xetla__core__memory_html_ga103379b76c960b4967704e057b7969ba"><div class="ttname"><a href="group__xetla__core__memory.html#ga103379b76c960b4967704e057b7969ba">gpu::xetla::xetla_load_global</a></div><div class="ttdeci">__XETLA_API xetla_vector&lt; Ty, N *NElts &gt; xetla_load_global(Ty *p, xetla_vector&lt; uint32_t, N &gt; offsets, xetla_mask&lt; N &gt; pred=1)</div><div class="ttdoc">Stateless scattered load.</div><div class="ttdef"><b>Definition:</b> memory.hpp:242</div></div>
<div class="ttc" id="agroup__xetla__core_html_gafb2a0442e367d71b79a2f932d0d39c8b"><div class="ttname"><a href="group__xetla__core.html#gafb2a0442e367d71b79a2f932d0d39c8b">KERNEL_FUNC</a></div><div class="ttdeci">#define KERNEL_FUNC</div><div class="ttdoc">KERNEL_FUNC macro.</div><div class="ttdef"><b>Definition:</b> common.hpp:39</div></div>
<div class="ttc" id="alayer__norm_2config_8hpp_html"><div class="ttname"><a href="layer__norm_2config_8hpp.html">config.hpp</a></div><div class="ttdoc">C++ API.</div></div>
<div class="ttc" id="alayer__norm__fused__op__bwd__xe_8hpp_html"><div class="ttname"><a href="layer__norm__fused__op__bwd__xe_8hpp.html">layer_norm_fused_op_bwd_xe.hpp</a></div><div class="ttdoc">C++ API.</div></div>
<div class="ttc" id="anamespacegpu_1_1xetla_1_1kernel_html"><div class="ttname"><a href="namespacegpu_1_1xetla_1_1kernel.html">gpu::xetla::kernel</a></div><div class="ttdef"><b>Definition:</b> api.hpp:24</div></div>
<div class="ttc" id="anamespacegpu_1_1xetla_1_1subgroup_html_ae110043dd5332ce2a7ef91d2c8ae79ef"><div class="ttname"><a href="namespacegpu_1_1xetla_1_1subgroup.html#ae110043dd5332ce2a7ef91d2c8ae79ef">gpu::xetla::subgroup::tile_load</a></div><div class="ttdeci">__XETLA_API std::enable_if_t&lt; detail::check_load_type&lt; tile_t, payload_t &gt;::is_global_2d_xe &gt; tile_load(tile_t &amp;tile, payload_t &amp;payload)</div><div class="ttdoc">This function loads data from 2D memory surface.</div><div class="ttdef"><b>Definition:</b> load_xe.hpp:126</div></div>
<div class="ttc" id="anamespacegpu_1_1xetla_html_a23ee6c8b836eb63360633951d75d7e30a1fb1a060534164a18a99494122825190"><div class="ttname"><a href="namespacegpu_1_1xetla.html#a23ee6c8b836eb63360633951d75d7e30a1fb1a060534164a18a99494122825190">gpu::xetla::cache_hint::cached</a></div><div class="ttdeci">@ cached</div></div>
<div class="ttc" id="anamespacegpu_1_1xetla_html_a2cf716afc0eaf0c0a87c572193d7ca76a6bad67b5e8990b5f40b54dddd984ea08"><div class="ttname"><a href="namespacegpu_1_1xetla.html#a2cf716afc0eaf0c0a87c572193d7ca76a6bad67b5e8990b5f40b54dddd984ea08">gpu::xetla::data_size::default_size</a></div><div class="ttdeci">@ default_size</div></div>
<div class="ttc" id="anamespacegpu_1_1xetla_html_a51137fd81d0d9d2156525a1e279432aaa78506882d645395a052df8b01a927395"><div class="ttname"><a href="namespacegpu_1_1xetla.html#a51137fd81d0d9d2156525a1e279432aaa78506882d645395a052df8b01a927395">gpu::xetla::reg_layout::tiled</a></div><div class="ttdeci">@ tiled</div></div>
<div class="ttc" id="anamespacegpu_1_1xetla_html_a7bbd70f1164d3a7251729e89fffc0609"><div class="ttname"><a href="namespacegpu_1_1xetla.html#a7bbd70f1164d3a7251729e89fffc0609">gpu::xetla::reduce_op</a></div><div class="ttdeci">reduce_op</div><div class="ttdoc">xetla reduce op</div><div class="ttdef"><b>Definition:</b> common.hpp:246</div></div>
<div class="ttc" id="anamespacegpu_1_1xetla_html_a7bbd70f1164d3a7251729e89fffc0609a1d623b89683f9ce4e074de1676d12416"><div class="ttname"><a href="namespacegpu_1_1xetla.html#a7bbd70f1164d3a7251729e89fffc0609a1d623b89683f9ce4e074de1676d12416">gpu::xetla::reduce_op::sum</a></div><div class="ttdeci">@ sum</div></div>
<div class="ttc" id="anamespacegpu_1_1xetla_html_a7f225ed816e841c1d31414d872dae59da9c70933aff6b2a6d08c687a6cbb6b765"><div class="ttname"><a href="namespacegpu_1_1xetla.html#a7f225ed816e841c1d31414d872dae59da9c70933aff6b2a6d08c687a6cbb6b765">gpu::xetla::mem_space::global</a></div><div class="ttdeci">@ global</div></div>
<div class="ttc" id="anamespacegpu_1_1xetla_html_aa8afe1d12e7777419fb6ea09534a0aa7a5baf9a1aba8e4b6fa44c20aafacc4233"><div class="ttname"><a href="namespacegpu_1_1xetla.html#aa8afe1d12e7777419fb6ea09534a0aa7a5baf9a1aba8e4b6fa44c20aafacc4233">gpu::xetla::msg_type::block_1d</a></div><div class="ttdeci">@ block_1d</div></div>
<div class="ttc" id="anamespacegpu_1_1xetla_html_af4a355a1806510c5515fad16f5910561a641fabb8e5e7d1d0333e2c9c384f959c"><div class="ttname"><a href="namespacegpu_1_1xetla.html#af4a355a1806510c5515fad16f5910561a641fabb8e5e7d1d0333e2c9c384f959c">gpu::xetla::mem_layout::row_major</a></div><div class="ttdeci">@ row_major</div></div>
<div class="ttc" id="astructgpu_1_1xetla_1_1group_1_1group__reduce__t_html"><div class="ttname"><a href="structgpu_1_1xetla_1_1group_1_1group__reduce__t.html">gpu::xetla::group::group_reduce_t</a></div><div class="ttdoc">This is the group reduction.</div><div class="ttdef"><b>Definition:</b> reduction_api.hpp:51</div></div>
<div class="ttc" id="astructgpu_1_1xetla_1_1group_1_1group__row__reduce__store__t_html"><div class="ttname"><a href="structgpu_1_1xetla_1_1group_1_1group__row__reduce__store__t.html">gpu::xetla::group::group_row_reduce_store_t</a></div><div class="ttdoc">This is the group row reduction(reduce_sum) + cooperative write out.</div><div class="ttdef"><b>Definition:</b> reduction_api.hpp:39</div></div>
<div class="ttc" id="astructgpu_1_1xetla_1_1kernel_1_1layer__norm__bwd__t_3_01dtype__x___00_01dtype__y___00_01dtype__w5e223ea0bd3a3851e47c460f10bccc84_html_a10a5dbca611a06d6ef29b741824cdc22"><div class="ttname"><a href="structgpu_1_1xetla_1_1kernel_1_1layer__norm__bwd__t_3_01dtype__x___00_01dtype__y___00_01dtype__w5e223ea0bd3a3851e47c460f10bccc84.html#a10a5dbca611a06d6ef29b741824cdc22">gpu::xetla::kernel::layer_norm_bwd_t&lt; dtype_x_, dtype_y_, dtype_weight_, dtype_acc_, layer_norm_attr_, gpu_arch::Xe, ln_bwd_fused_op_ &gt;::call</a></div><div class="ttdeci">static __XETLA_API void call(xetla_exec_item&lt; 3 &gt; &amp;ei, arguments_t *args, uint32_t slm_base=0, uint32_t nbarrier_base=0, ln_fused_op_arguments_t *fused_op_args=nullptr)</div><div class="ttdef"><b>Definition:</b> layer_norm_bwd_xe.hpp:236</div></div>
<div class="ttc" id="astructgpu_1_1xetla_1_1kernel_1_1layer__norm__bwd__t_3_01dtype__x___00_01dtype__y___00_01dtype__w5e223ea0bd3a3851e47c460f10bccc84_html_a5c5444009eda1cc73b8538d63dc78f94"><div class="ttname"><a href="structgpu_1_1xetla_1_1kernel_1_1layer__norm__bwd__t_3_01dtype__x___00_01dtype__y___00_01dtype__w5e223ea0bd3a3851e47c460f10bccc84.html#a5c5444009eda1cc73b8538d63dc78f94">gpu::xetla::kernel::layer_norm_bwd_t&lt; dtype_x_, dtype_y_, dtype_weight_, dtype_acc_, layer_norm_attr_, gpu_arch::Xe, ln_bwd_fused_op_ &gt;::dtype_acc</a></div><div class="ttdeci">dtype_acc_ dtype_acc</div><div class="ttdef"><b>Definition:</b> layer_norm_bwd_xe.hpp:45</div></div>
<div class="ttc" id="astructgpu_1_1xetla_1_1kernel_1_1layer__norm__bwd__t_3_01dtype__x___00_01dtype__y___00_01dtype__w5e223ea0bd3a3851e47c460f10bccc84_html_a65c0ca9026ee5e6887929571e292c927"><div class="ttname"><a href="structgpu_1_1xetla_1_1kernel_1_1layer__norm__bwd__t_3_01dtype__x___00_01dtype__y___00_01dtype__w5e223ea0bd3a3851e47c460f10bccc84.html#a65c0ca9026ee5e6887929571e292c927">gpu::xetla::kernel::layer_norm_bwd_t&lt; dtype_x_, dtype_y_, dtype_weight_, dtype_acc_, layer_norm_attr_, gpu_arch::Xe, ln_bwd_fused_op_ &gt;::dtype_y</a></div><div class="ttdeci">dtype_y_ dtype_y</div><div class="ttdef"><b>Definition:</b> layer_norm_bwd_xe.hpp:43</div></div>
<div class="ttc" id="astructgpu_1_1xetla_1_1kernel_1_1layer__norm__bwd__t_3_01dtype__x___00_01dtype__y___00_01dtype__w5e223ea0bd3a3851e47c460f10bccc84_html_a6643584dccd935324777d22721c9e924"><div class="ttname"><a href="structgpu_1_1xetla_1_1kernel_1_1layer__norm__bwd__t_3_01dtype__x___00_01dtype__y___00_01dtype__w5e223ea0bd3a3851e47c460f10bccc84.html#a6643584dccd935324777d22721c9e924">gpu::xetla::kernel::layer_norm_bwd_t&lt; dtype_x_, dtype_y_, dtype_weight_, dtype_acc_, layer_norm_attr_, gpu_arch::Xe, ln_bwd_fused_op_ &gt;::layer_norm_attr</a></div><div class="ttdeci">layer_norm_attr_ layer_norm_attr</div><div class="ttdef"><b>Definition:</b> layer_norm_bwd_xe.hpp:46</div></div>
<div class="ttc" id="astructgpu_1_1xetla_1_1kernel_1_1layer__norm__bwd__t_3_01dtype__x___00_01dtype__y___00_01dtype__w5e223ea0bd3a3851e47c460f10bccc84_html_a6e3963e378066c5d245fe66f74738797"><div class="ttname"><a href="structgpu_1_1xetla_1_1kernel_1_1layer__norm__bwd__t_3_01dtype__x___00_01dtype__y___00_01dtype__w5e223ea0bd3a3851e47c460f10bccc84.html#a6e3963e378066c5d245fe66f74738797">gpu::xetla::kernel::layer_norm_bwd_t&lt; dtype_x_, dtype_y_, dtype_weight_, dtype_acc_, layer_norm_attr_, gpu_arch::Xe, ln_bwd_fused_op_ &gt;::dtype_weight</a></div><div class="ttdeci">dtype_weight_ dtype_weight</div><div class="ttdef"><b>Definition:</b> layer_norm_bwd_xe.hpp:44</div></div>
<div class="ttc" id="astructgpu_1_1xetla_1_1kernel_1_1layer__norm__bwd__t_3_01dtype__x___00_01dtype__y___00_01dtype__w5e223ea0bd3a3851e47c460f10bccc84_html_a856d703aca448075c793a40d821d87ca"><div class="ttname"><a href="structgpu_1_1xetla_1_1kernel_1_1layer__norm__bwd__t_3_01dtype__x___00_01dtype__y___00_01dtype__w5e223ea0bd3a3851e47c460f10bccc84.html#a856d703aca448075c793a40d821d87ca">gpu::xetla::kernel::layer_norm_bwd_t&lt; dtype_x_, dtype_y_, dtype_weight_, dtype_acc_, layer_norm_attr_, gpu_arch::Xe, ln_bwd_fused_op_ &gt;::ln_fused_op_arguments_t</a></div><div class="ttdeci">typename ln_bwd_fused_op::arguments_t ln_fused_op_arguments_t</div><div class="ttdef"><b>Definition:</b> layer_norm_bwd_xe.hpp:48</div></div>
<div class="ttc" id="astructgpu_1_1xetla_1_1kernel_1_1layer__norm__bwd__t_3_01dtype__x___00_01dtype__y___00_01dtype__w5e223ea0bd3a3851e47c460f10bccc84_html_ab8f68b77c72bf88647ee8f0f4194b86f"><div class="ttname"><a href="structgpu_1_1xetla_1_1kernel_1_1layer__norm__bwd__t_3_01dtype__x___00_01dtype__y___00_01dtype__w5e223ea0bd3a3851e47c460f10bccc84.html#ab8f68b77c72bf88647ee8f0f4194b86f">gpu::xetla::kernel::layer_norm_bwd_t&lt; dtype_x_, dtype_y_, dtype_weight_, dtype_acc_, layer_norm_attr_, gpu_arch::Xe, ln_bwd_fused_op_ &gt;::work_group_t</a></div><div class="ttdeci">work_group_t&lt; wg_size_x *wg_size_y &gt; work_group_t</div><div class="ttdef"><b>Definition:</b> layer_norm_bwd_xe.hpp:60</div></div>
<div class="ttc" id="astructgpu_1_1xetla_1_1kernel_1_1layer__norm__bwd__t_3_01dtype__x___00_01dtype__y___00_01dtype__w5e223ea0bd3a3851e47c460f10bccc84_html_abb73d94fccf7341dd998753a3a6978c2"><div class="ttname"><a href="structgpu_1_1xetla_1_1kernel_1_1layer__norm__bwd__t_3_01dtype__x___00_01dtype__y___00_01dtype__w5e223ea0bd3a3851e47c460f10bccc84.html#abb73d94fccf7341dd998753a3a6978c2">gpu::xetla::kernel::layer_norm_bwd_t&lt; dtype_x_, dtype_y_, dtype_weight_, dtype_acc_, layer_norm_attr_, gpu_arch::Xe, ln_bwd_fused_op_ &gt;::ln_bwd_fused_op</a></div><div class="ttdeci">ln_bwd_fused_op_ ln_bwd_fused_op</div><div class="ttdef"><b>Definition:</b> layer_norm_bwd_xe.hpp:47</div></div>
<div class="ttc" id="astructgpu_1_1xetla_1_1kernel_1_1layer__norm__bwd__t_3_01dtype__x___00_01dtype__y___00_01dtype__w5e223ea0bd3a3851e47c460f10bccc84_html_ace04ac4e6f750e6dc131157a3250d5b3"><div class="ttname"><a href="structgpu_1_1xetla_1_1kernel_1_1layer__norm__bwd__t_3_01dtype__x___00_01dtype__y___00_01dtype__w5e223ea0bd3a3851e47c460f10bccc84.html#ace04ac4e6f750e6dc131157a3250d5b3">gpu::xetla::kernel::layer_norm_bwd_t&lt; dtype_x_, dtype_y_, dtype_weight_, dtype_acc_, layer_norm_attr_, gpu_arch::Xe, ln_bwd_fused_op_ &gt;::dtype_x</a></div><div class="ttdeci">dtype_x_ dtype_x</div><div class="ttdef"><b>Definition:</b> layer_norm_bwd_xe.hpp:42</div></div>
<div class="ttc" id="astructgpu_1_1xetla_1_1kernel_1_1layer__norm__bwd__t_3_01dtype__x___00_01dtype__y___00_01dtype__w8c870e0747f737257129382bb64d56e0_html_a1a7cbaf46cae468d8d31698f62d0371d"><div class="ttname"><a href="structgpu_1_1xetla_1_1kernel_1_1layer__norm__bwd__t_3_01dtype__x___00_01dtype__y___00_01dtype__w8c870e0747f737257129382bb64d56e0.html#a1a7cbaf46cae468d8d31698f62d0371d">gpu::xetla::kernel::layer_norm_bwd_t&lt; dtype_x_, dtype_y_, dtype_weight_, dtype_acc_, layer_norm_attr_, gpu_arch::Xe, ln_bwd_fused_op_ &gt;::arguments_t::dgamma_acc_ptr</a></div><div class="ttdeci">dtype_acc * dgamma_acc_ptr</div><div class="ttdef"><b>Definition:</b> layer_norm_bwd_xe.hpp:117</div></div>
<div class="ttc" id="astructgpu_1_1xetla_1_1kernel_1_1layer__norm__bwd__t_3_01dtype__x___00_01dtype__y___00_01dtype__w8c870e0747f737257129382bb64d56e0_html_a2440a2de9804d0bf12c9c6f0da428698"><div class="ttname"><a href="structgpu_1_1xetla_1_1kernel_1_1layer__norm__bwd__t_3_01dtype__x___00_01dtype__y___00_01dtype__w8c870e0747f737257129382bb64d56e0.html#a2440a2de9804d0bf12c9c6f0da428698">gpu::xetla::kernel::layer_norm_bwd_t&lt; dtype_x_, dtype_y_, dtype_weight_, dtype_acc_, layer_norm_attr_, gpu_arch::Xe, ln_bwd_fused_op_ &gt;::arguments_t::x_in_ptr</a></div><div class="ttdeci">dtype_x * x_in_ptr</div><div class="ttdef"><b>Definition:</b> layer_norm_bwd_xe.hpp:111</div></div>
<div class="ttc" id="astructgpu_1_1xetla_1_1kernel_1_1layer__norm__bwd__t_3_01dtype__x___00_01dtype__y___00_01dtype__w8c870e0747f737257129382bb64d56e0_html_a387fb818e436a001d36c23707e16aca0"><div class="ttname"><a href="structgpu_1_1xetla_1_1kernel_1_1layer__norm__bwd__t_3_01dtype__x___00_01dtype__y___00_01dtype__w8c870e0747f737257129382bb64d56e0.html#a387fb818e436a001d36c23707e16aca0">gpu::xetla::kernel::layer_norm_bwd_t&lt; dtype_x_, dtype_y_, dtype_weight_, dtype_acc_, layer_norm_attr_, gpu_arch::Xe, ln_bwd_fused_op_ &gt;::arguments_t::matrix_m</a></div><div class="ttdeci">uint32_t matrix_m</div><div class="ttdef"><b>Definition:</b> layer_norm_bwd_xe.hpp:120</div></div>
<div class="ttc" id="astructgpu_1_1xetla_1_1kernel_1_1layer__norm__bwd__t_3_01dtype__x___00_01dtype__y___00_01dtype__w8c870e0747f737257129382bb64d56e0_html_a972d3ed415731797b47198b8c60f5604"><div class="ttname"><a href="structgpu_1_1xetla_1_1kernel_1_1layer__norm__bwd__t_3_01dtype__x___00_01dtype__y___00_01dtype__w8c870e0747f737257129382bb64d56e0.html#a972d3ed415731797b47198b8c60f5604">gpu::xetla::kernel::layer_norm_bwd_t&lt; dtype_x_, dtype_y_, dtype_weight_, dtype_acc_, layer_norm_attr_, gpu_arch::Xe, ln_bwd_fused_op_ &gt;::arguments_t::gamma_in_ptr</a></div><div class="ttdeci">dtype_weight * gamma_in_ptr</div><div class="ttdef"><b>Definition:</b> layer_norm_bwd_xe.hpp:112</div></div>
<div class="ttc" id="astructgpu_1_1xetla_1_1kernel_1_1layer__norm__bwd__t_3_01dtype__x___00_01dtype__y___00_01dtype__w8c870e0747f737257129382bb64d56e0_html_a9f6d76f79fec3db6f9ea545fb7fecbed"><div class="ttname"><a href="structgpu_1_1xetla_1_1kernel_1_1layer__norm__bwd__t_3_01dtype__x___00_01dtype__y___00_01dtype__w8c870e0747f737257129382bb64d56e0.html#a9f6d76f79fec3db6f9ea545fb7fecbed">gpu::xetla::kernel::layer_norm_bwd_t&lt; dtype_x_, dtype_y_, dtype_weight_, dtype_acc_, layer_norm_attr_, gpu_arch::Xe, ln_bwd_fused_op_ &gt;::arguments_t::dy_in_ptr</a></div><div class="ttdeci">dtype_y * dy_in_ptr</div><div class="ttdef"><b>Definition:</b> layer_norm_bwd_xe.hpp:110</div></div>
<div class="ttc" id="astructgpu_1_1xetla_1_1kernel_1_1layer__norm__bwd__t_3_01dtype__x___00_01dtype__y___00_01dtype__w8c870e0747f737257129382bb64d56e0_html_ac970c1b9a64dd16c9c46ead0b24cd769"><div class="ttname"><a href="structgpu_1_1xetla_1_1kernel_1_1layer__norm__bwd__t_3_01dtype__x___00_01dtype__y___00_01dtype__w8c870e0747f737257129382bb64d56e0.html#ac970c1b9a64dd16c9c46ead0b24cd769">gpu::xetla::kernel::layer_norm_bwd_t&lt; dtype_x_, dtype_y_, dtype_weight_, dtype_acc_, layer_norm_attr_, gpu_arch::Xe, ln_bwd_fused_op_ &gt;::arguments_t::mat_ld</a></div><div class="ttdeci">uint32_t mat_ld</div><div class="ttdef"><b>Definition:</b> layer_norm_bwd_xe.hpp:122</div></div>
<div class="ttc" id="astructgpu_1_1xetla_1_1kernel_1_1layer__norm__bwd__t_3_01dtype__x___00_01dtype__y___00_01dtype__w8c870e0747f737257129382bb64d56e0_html_ad8b8a0898fd653db197f4a3561d8fa8c"><div class="ttname"><a href="structgpu_1_1xetla_1_1kernel_1_1layer__norm__bwd__t_3_01dtype__x___00_01dtype__y___00_01dtype__w8c870e0747f737257129382bb64d56e0.html#ad8b8a0898fd653db197f4a3561d8fa8c">gpu::xetla::kernel::layer_norm_bwd_t&lt; dtype_x_, dtype_y_, dtype_weight_, dtype_acc_, layer_norm_attr_, gpu_arch::Xe, ln_bwd_fused_op_ &gt;::arguments_t::rs_ptr</a></div><div class="ttdeci">dtype_acc * rs_ptr</div><div class="ttdef"><b>Definition:</b> layer_norm_bwd_xe.hpp:113</div></div>
<div class="ttc" id="astructgpu_1_1xetla_1_1kernel_1_1layer__norm__bwd__t_3_01dtype__x___00_01dtype__y___00_01dtype__w8c870e0747f737257129382bb64d56e0_html_adc3aed8897d33aa95b9593334f23798e"><div class="ttname"><a href="structgpu_1_1xetla_1_1kernel_1_1layer__norm__bwd__t_3_01dtype__x___00_01dtype__y___00_01dtype__w8c870e0747f737257129382bb64d56e0.html#adc3aed8897d33aa95b9593334f23798e">gpu::xetla::kernel::layer_norm_bwd_t&lt; dtype_x_, dtype_y_, dtype_weight_, dtype_acc_, layer_norm_attr_, gpu_arch::Xe, ln_bwd_fused_op_ &gt;::arguments_t::matrix_n</a></div><div class="ttdeci">uint32_t matrix_n</div><div class="ttdef"><b>Definition:</b> layer_norm_bwd_xe.hpp:121</div></div>
<div class="ttc" id="astructgpu_1_1xetla_1_1kernel_1_1layer__norm__bwd__t_3_01dtype__x___00_01dtype__y___00_01dtype__w8c870e0747f737257129382bb64d56e0_html_ae6c41c4182fd92948ebd77dbe2902b9e"><div class="ttname"><a href="structgpu_1_1xetla_1_1kernel_1_1layer__norm__bwd__t_3_01dtype__x___00_01dtype__y___00_01dtype__w8c870e0747f737257129382bb64d56e0.html#ae6c41c4182fd92948ebd77dbe2902b9e">gpu::xetla::kernel::layer_norm_bwd_t&lt; dtype_x_, dtype_y_, dtype_weight_, dtype_acc_, layer_norm_attr_, gpu_arch::Xe, ln_bwd_fused_op_ &gt;::arguments_t::mu_ptr</a></div><div class="ttdeci">dtype_acc * mu_ptr</div><div class="ttdef"><b>Definition:</b> layer_norm_bwd_xe.hpp:114</div></div>
<div class="ttc" id="astructgpu_1_1xetla_1_1kernel_1_1layer__norm__bwd__t_3_01dtype__x___00_01dtype__y___00_01dtype__w8c870e0747f737257129382bb64d56e0_html_ae6ed860b5d25e0256c7497e3c9bd8619"><div class="ttname"><a href="structgpu_1_1xetla_1_1kernel_1_1layer__norm__bwd__t_3_01dtype__x___00_01dtype__y___00_01dtype__w8c870e0747f737257129382bb64d56e0.html#ae6ed860b5d25e0256c7497e3c9bd8619">gpu::xetla::kernel::layer_norm_bwd_t&lt; dtype_x_, dtype_y_, dtype_weight_, dtype_acc_, layer_norm_attr_, gpu_arch::Xe, ln_bwd_fused_op_ &gt;::arguments_t::dbeta_acc_ptr</a></div><div class="ttdeci">dtype_acc * dbeta_acc_ptr</div><div class="ttdef"><b>Definition:</b> layer_norm_bwd_xe.hpp:118</div></div>
<div class="ttc" id="astructgpu_1_1xetla_1_1kernel_1_1layer__norm__bwd__t_3_01dtype__x___00_01dtype__y___00_01dtype__w8c870e0747f737257129382bb64d56e0_html_afd79f60c87a238015d9fe02e81becc55"><div class="ttname"><a href="structgpu_1_1xetla_1_1kernel_1_1layer__norm__bwd__t_3_01dtype__x___00_01dtype__y___00_01dtype__w8c870e0747f737257129382bb64d56e0.html#afd79f60c87a238015d9fe02e81becc55">gpu::xetla::kernel::layer_norm_bwd_t&lt; dtype_x_, dtype_y_, dtype_weight_, dtype_acc_, layer_norm_attr_, gpu_arch::Xe, ln_bwd_fused_op_ &gt;::arguments_t::dx_out_ptr</a></div><div class="ttdeci">dtype_x * dx_out_ptr</div><div class="ttdef"><b>Definition:</b> layer_norm_bwd_xe.hpp:116</div></div>
<div class="ttc" id="astructgpu_1_1xetla_1_1kernel_1_1layer__norm__bwd__t_html"><div class="ttname"><a href="structgpu_1_1xetla_1_1kernel_1_1layer__norm__bwd__t.html">gpu::xetla::kernel::layer_norm_bwd_t</a></div><div class="ttdef"><b>Definition:</b> api.hpp:61</div></div>
<div class="ttc" id="astructgpu_1_1xetla_1_1subgroup_1_1mem__payload__t_html"><div class="ttname"><a href="structgpu_1_1xetla_1_1subgroup_1_1mem__payload__t.html">gpu::xetla::subgroup::mem_payload_t</a></div><div class="ttdoc">Is to illustrate the memory information.</div><div class="ttdef"><b>Definition:</b> api.hpp:46</div></div>
<div class="ttc" id="astructgpu_1_1xetla_1_1subgroup_1_1tile__desc__t_html"><div class="ttname"><a href="structgpu_1_1xetla_1_1subgroup_1_1tile__desc__t.html">gpu::xetla::subgroup::tile_desc_t</a></div><div class="ttdoc">Is to illustrate the tile information about a sub matrix.</div><div class="ttdef"><b>Definition:</b> api.hpp:69</div></div>
<div class="ttc" id="astructgpu_1_1xetla_1_1subgroup_1_1tile__t_html"><div class="ttname"><a href="structgpu_1_1xetla_1_1subgroup_1_1tile__t.html">gpu::xetla::subgroup::tile_t</a></div><div class="ttdoc">Is a struct contains some register file.</div><div class="ttdef"><b>Definition:</b> api.hpp:104</div></div>
<div class="ttc" id="astructgpu_1_1xetla_1_1subgroup_1_1tile__t_html_a7985ceac15e399ebf3000e5693d8801e"><div class="ttname"><a href="structgpu_1_1xetla_1_1subgroup_1_1tile__t.html#a7985ceac15e399ebf3000e5693d8801e">gpu::xetla::subgroup::tile_t::reg</a></div><div class="ttdeci">xetla_vector&lt; dtype, tile_desc::tile_elems &gt; reg</div><div class="ttdef"><b>Definition:</b> api.hpp:107</div></div>
</div><!-- fragment --></div><!-- contents -->
</div><!-- doc-content -->
<!-- start footer part -->
<div id="nav-path" class="navpath"><!-- id is needed for treeview function! -->
  <ul>
    <li class="navelem"><a class="el" href="dir_d44c64559bbebec7f509842c48db8b23.html">include</a></li><li class="navelem"><a class="el" href="dir_8966848d4591654ab1db845bb311f08b.html">experimental</a></li><li class="navelem"><a class="el" href="dir_da6d88b16527b966b2bed57376e43e91.html">kernel</a></li><li class="navelem"><a class="el" href="dir_142ba5024da2864de75251985ba3a4cc.html">layer_norm</a></li><li class="navelem"><a class="el" href="layer__norm__bwd__xe_8hpp.html">layer_norm_bwd_xe.hpp</a></li>
    <li class="footer">Generated by <a href="https://www.doxygen.org/index.html"><img class="footer" src="doxygen.svg" width="104" height="31" alt="doxygen"/></a> 1.9.5 </li>
  </ul>
</div>
</body>
</html>
