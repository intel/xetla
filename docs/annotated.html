<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "https://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" lang="en-US">
<head>
<meta http-equiv="Content-Type" content="text/xhtml;charset=UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=11"/>
<meta name="generator" content="Doxygen 1.9.5"/>
<meta name="viewport" content="width=device-width, initial-scale=1"/>
<title>XeTLA: Class List</title>
<link href="tabs.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="jquery.js"></script>
<script type="text/javascript" src="dynsections.js"></script>
<link href="navtree.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="resize.js"></script>
<script type="text/javascript" src="navtreedata.js"></script>
<script type="text/javascript" src="navtree.js"></script>
<link href="search/search.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="search/searchdata.js"></script>
<script type="text/javascript" src="search/search.js"></script>
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:d3d9a9a6595521f9666a5e94cc830dab83b65699&amp;dn=expat.txt MIT */
  $(document).ready(function() { init_search(); });
/* @license-end */
</script>
<script type="text/x-mathjax-config">
MathJax.Hub.Config({
  extensions: ["tex2jax.js"],
  jax: ["input/TeX","output/HTML-CSS"],
});
</script>
<script type="text/javascript" async="async" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js"></script>
<link href="doxygen.css" rel="stylesheet" type="text/css" />
</head>
<body>
<div id="top"><!-- do not remove this div, it is closed by doxygen! -->
<div id="titlearea">
<table cellspacing="0" cellpadding="0">
 <tbody>
 <tr id="projectrow">
  <td id="projectalign">
   <div id="projectname">XeTLA<span id="projectnumber">&#160;v0.3.2</span>
   </div>
   <div id="projectbrief">IntelÂ® Xe Templates for Linear Algebra - API Definition Document</div>
  </td>
    <td>        <div id="MSearchBox" class="MSearchBoxInactive">
        <span class="left">
          <span id="MSearchSelect"                onmouseover="return searchBox.OnSearchSelectShow()"                onmouseout="return searchBox.OnSearchSelectHide()">&#160;</span>
          <input type="text" id="MSearchField" value="" placeholder="Search" accesskey="S"
               onfocus="searchBox.OnSearchFieldFocus(true)" 
               onblur="searchBox.OnSearchFieldFocus(false)" 
               onkeyup="searchBox.OnSearchFieldChange(event)"/>
          </span><span class="right">
            <a id="MSearchClose" href="javascript:searchBox.CloseResultsWindow()"><img id="MSearchCloseImg" border="0" src="search/close.svg" alt=""/></a>
          </span>
        </div>
</td>
 </tr>
 </tbody>
</table>
</div>
<!-- end header part -->
<!-- Generated by Doxygen 1.9.5 -->
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:d3d9a9a6595521f9666a5e94cc830dab83b65699&amp;dn=expat.txt MIT */
var searchBox = new SearchBox("searchBox", "search/",'.html');
/* @license-end */
</script>
</div><!-- top -->
<div id="side-nav" class="ui-resizable side-nav-resizable">
  <div id="nav-tree">
    <div id="nav-tree-contents">
      <div id="nav-sync" class="sync"></div>
    </div>
  </div>
  <div id="splitbar" style="-moz-user-select:none;" 
       class="ui-resizable-handle">
  </div>
</div>
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:d3d9a9a6595521f9666a5e94cc830dab83b65699&amp;dn=expat.txt MIT */
$(document).ready(function(){initNavTree('annotated.html',''); initResizable(); });
/* @license-end */
</script>
<div id="doc-content">
<!-- window showing the filter options -->
<div id="MSearchSelectWindow"
     onmouseover="return searchBox.OnSearchSelectShow()"
     onmouseout="return searchBox.OnSearchSelectHide()"
     onkeydown="return searchBox.OnSearchSelectKey(event)">
</div>

<!-- iframe showing the search results (closed by default) -->
<div id="MSearchResultsWindow">
<div id="MSearchResults">
<div class="SRPage">
<div id="SRIndex">
<div id="SRResults"></div>
<div class="SRStatus" id="Loading">Loading...</div>
<div class="SRStatus" id="Searching">Searching...</div>
<div class="SRStatus" id="NoMatches">No Matches</div>
</div>
</div>
</div>
</div>

<div class="header">
  <div class="headertitle"><div class="title">Class List</div></div>
</div><!--header-->
<div class="contents">
<div class="textblock">Here are the classes, structs, unions and interfaces with brief descriptions:</div><div class="directory">
<div class="levels">[detail level <span onclick="javascript:toggleLevel(1);">1</span><span onclick="javascript:toggleLevel(2);">2</span><span onclick="javascript:toggleLevel(3);">3</span><span onclick="javascript:toggleLevel(4);">4</span><span onclick="javascript:toggleLevel(5);">5</span>]</div><table class="directory">
<tr id="row_0_" class="even"><td class="entry"><span style="width:0px;display:inline-block;">&#160;</span><span id="arr_0_" class="arrow" onclick="toggleFolder('0_')">&#9660;</span><span class="icona"><span class="icon">N</span></span><a class="el" href="namespacegpu.html" target="_self">gpu</a></td><td class="desc"></td></tr>
<tr id="row_0_0_" class="odd"><td class="entry"><span style="width:16px;display:inline-block;">&#160;</span><span id="arr_0_0_" class="arrow" onclick="toggleFolder('0_0_')">&#9660;</span><span class="icona"><span class="icon">N</span></span><a class="el" href="namespacegpu_1_1xetla.html" target="_self">xetla</a></td><td class="desc"></td></tr>
<tr id="row_0_0_0_" class="even"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span id="arr_0_0_0_" class="arrow" onclick="toggleFolder('0_0_0_')">&#9658;</span><span class="icona"><span class="icon">N</span></span><a class="el" href="namespacegpu_1_1xetla_1_1group.html" target="_self">group</a></td><td class="desc"></td></tr>
<tr id="row_0_0_0_0_" class="odd" style="display:none;"><td class="entry"><span style="width:48px;display:inline-block;">&#160;</span><span id="arr_0_0_0_0_" class="arrow" onclick="toggleFolder('0_0_0_0_')">&#9658;</span><span class="icona"><span class="icon">N</span></span><a class="el" href="namespacegpu_1_1xetla_1_1group_1_1detail.html" target="_self">detail</a></td><td class="desc"></td></tr>
<tr id="row_0_0_0_0_0_" class="odd" style="display:none;"><td class="entry"><span style="width:80px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="structgpu_1_1xetla_1_1group_1_1detail_1_1check__dtype__default__fpu__xe.html" target="_self">check_dtype_default_fpu_xe</a></td><td class="desc"></td></tr>
<tr id="row_0_0_0_0_1_" class="odd" style="display:none;"><td class="entry"><span style="width:80px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="structgpu_1_1xetla_1_1group_1_1detail_1_1check__dtype__default__xmx__xe.html" target="_self">check_dtype_default_xmx_xe</a></td><td class="desc"></td></tr>
<tr id="row_0_0_0_0_2_" class="odd" style="display:none;"><td class="entry"><span style="width:80px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="structgpu_1_1xetla_1_1group_1_1detail_1_1check__memory__default__fpu__xe.html" target="_self">check_memory_default_fpu_xe</a></td><td class="desc"></td></tr>
<tr id="row_0_0_0_0_3_" class="odd" style="display:none;"><td class="entry"><span style="width:80px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="structgpu_1_1xetla_1_1group_1_1detail_1_1check__memory__default__xmx__xe.html" target="_self">check_memory_default_xmx_xe</a></td><td class="desc"></td></tr>
<tr id="row_0_0_0_0_4_" class="odd" style="display:none;"><td class="entry"><span style="width:80px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="structgpu_1_1xetla_1_1group_1_1detail_1_1check__tile__size__default__fpu__xe.html" target="_self">check_tile_size_default_fpu_xe</a></td><td class="desc"></td></tr>
<tr id="row_0_0_0_0_5_" class="odd" style="display:none;"><td class="entry"><span style="width:80px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="structgpu_1_1xetla_1_1group_1_1detail_1_1check__tile__size__default__xmx__xe.html" target="_self">check_tile_size_default_xmx_xe</a></td><td class="desc"></td></tr>
<tr id="row_0_0_0_1_" class="odd" style="display:none;"><td class="entry"><span style="width:64px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="classgpu_1_1xetla_1_1group_1_1brgemm__selector__t.html" target="_self">brgemm_selector_t</a></td><td class="desc">Brgemm selection functor </td></tr>
<tr id="row_0_0_0_2_" class="odd" style="display:none;"><td class="entry"><span style="width:64px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="classgpu_1_1xetla_1_1group_1_1brgemm__selector__t_3_01dtype__a_00_01dtype__b_00_01mem__layout__a386cb0b79347ebe3b83ae4c1287ebfe6.html" target="_self">brgemm_selector_t&lt; dtype_a, dtype_b, mem_layout_a, mem_layout_b, mem_space_a, mem_space_b, alignment_a, alignment_b, dtype_acc, tile_shape, k_stride, mma_engine::fpu, gpu_arch::Xe, stages, sync_freq, std::enable_if_t&lt;((sizeof(dtype_a) *alignment_a) % detail::alignment_bytes_xe==0) &amp;&amp;((sizeof(dtype_b) *alignment_b) % detail::alignment_bytes_xe==0)&gt; &gt;</a></td><td class="desc">Selects 2d block &amp;&amp; fpu based brgemm </td></tr>
<tr id="row_0_0_0_3_" class="odd" style="display:none;"><td class="entry"><span style="width:64px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="classgpu_1_1xetla_1_1group_1_1brgemm__selector__t_3_01dtype__a_00_01dtype__b_00_01mem__layout__ab0bba904540e3123bc567c0c77d1dc34.html" target="_self">brgemm_selector_t&lt; dtype_a, dtype_b, mem_layout_a, mem_layout_b, mem_space_a, mem_space_b, alignment_a, alignment_b, dtype_acc, tile_shape, k_stride, mma_engine::xmx, gpu_arch::Xe, stages, sync_freq, std::enable_if_t&lt;((sizeof(dtype_a) *alignment_a) % detail::alignment_bytes_xe==0) &amp;&amp;((sizeof(dtype_b) *alignment_b) % detail::alignment_bytes_xe==0)&gt; &gt;</a></td><td class="desc">Selects 2d block &amp;&amp; xmx based brgemm </td></tr>
<tr id="row_0_0_0_4_" class="odd" style="display:none;"><td class="entry"><span style="width:64px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="classgpu_1_1xetla_1_1group_1_1brgemm__t.html" target="_self">brgemm_t</a></td><td class="desc">Brgemm functor </td></tr>
<tr id="row_0_0_0_5_" class="odd" style="display:none;"><td class="entry"><span style="width:48px;display:inline-block;">&#160;</span><span id="arr_0_0_0_5_" class="arrow" onclick="toggleFolder('0_0_0_5_')">&#9658;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="classgpu_1_1xetla_1_1group_1_1brgemm__t_3_01compute__policy__default__fpu_3_01compute__attr___00e6ff7d3616a116a3ac4e9e017b87087d.html" target="_self">brgemm_t&lt; compute_policy_default_fpu&lt; compute_attr_, perf_tuning_knob_, gpu_arch::Xe &gt;, tile_shape_, mem_desc_a_t_, mem_desc_b_t_, pre_processing_t_ &gt;</a></td><td class="desc">Is the brgemm functor for Xe architecture and vector engine </td></tr>
<tr id="row_0_0_0_5_0_" class="odd" style="display:none;"><td class="entry"><span style="width:80px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="structgpu_1_1xetla_1_1group_1_1brgemm__t_3_01compute__policy__default__fpu_3_01compute__attr___090dc711a7784dd6c98fd990032c93cff.html" target="_self">arguments_t</a></td><td class="desc">Arguments for brgemm </td></tr>
<tr id="row_0_0_0_6_" class="odd" style="display:none;"><td class="entry"><span style="width:48px;display:inline-block;">&#160;</span><span id="arr_0_0_0_6_" class="arrow" onclick="toggleFolder('0_0_0_6_')">&#9658;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="classgpu_1_1xetla_1_1group_1_1brgemm__t_3_01compute__policy__default__xmx_3_01compute__attr___00cfb0805f04374331c75878919ee17cda.html" target="_self">brgemm_t&lt; compute_policy_default_xmx&lt; compute_attr_, perf_tuning_knob_, gpu_arch::Xe &gt;, tile_shape_, mem_desc_a_t_, mem_desc_b_t_, pre_processing_t_ &gt;</a></td><td class="desc">Is the brgemm functor for Xe architecture and matrix engine </td></tr>
<tr id="row_0_0_0_6_0_" class="odd" style="display:none;"><td class="entry"><span style="width:80px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="structgpu_1_1xetla_1_1group_1_1brgemm__t_3_01compute__policy__default__xmx_3_01compute__attr___07272e110706a71dc92be1177191b6e91.html" target="_self">arguments_t</a></td><td class="desc">Arguments for brgemm </td></tr>
<tr id="row_0_0_0_7_" class="odd" style="display:none;"><td class="entry"><span style="width:64px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="structgpu_1_1xetla_1_1group_1_1compute__attr__t.html" target="_self">compute_attr_t</a></td><td class="desc">Compute attribute for brgemm </td></tr>
<tr id="row_0_0_0_8_" class="odd" style="display:none;"><td class="entry"><span style="width:64px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="structgpu_1_1xetla_1_1group_1_1compute__policy__default__fpu.html" target="_self">compute_policy_default_fpu</a></td><td class="desc">Compute policy for fpu engine </td></tr>
<tr id="row_0_0_0_9_" class="odd" style="display:none;"><td class="entry"><span style="width:64px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="structgpu_1_1xetla_1_1group_1_1compute__policy__default__fpu_3_01compute__attr___00_01perf__tuni47256acf2d5985beff28b2772c102b96.html" target="_self">compute_policy_default_fpu&lt; compute_attr_, perf_tuning_knob_, gpu_arch::Xe &gt;</a></td><td class="desc">Specialized for Xe architecture </td></tr>
<tr id="row_0_0_0_10_" class="odd" style="display:none;"><td class="entry"><span style="width:64px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="structgpu_1_1xetla_1_1group_1_1compute__policy__default__xmx.html" target="_self">compute_policy_default_xmx</a></td><td class="desc">Compute policy for xmx engine </td></tr>
<tr id="row_0_0_0_11_" class="odd" style="display:none;"><td class="entry"><span style="width:64px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="structgpu_1_1xetla_1_1group_1_1compute__policy__default__xmx_3_01compute__attr___00_01perf__tuni99772a0774107d5e4cbc4d748cebc11b.html" target="_self">compute_policy_default_xmx&lt; compute_attr_, perf_tuning_knob_, gpu_arch::Xe &gt;</a></td><td class="desc">Specialized for Xe architecture </td></tr>
<tr id="row_0_0_0_12_" class="odd" style="display:none;"><td class="entry"><span style="width:64px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="classgpu_1_1xetla_1_1group_1_1cooperative__reduce__t.html" target="_self">cooperative_reduce_t</a></td><td class="desc">Workgroups to do the cooperative reduction </td></tr>
<tr id="row_0_0_0_13_" class="odd" style="display:none;"><td class="entry"><span style="width:64px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="classgpu_1_1xetla_1_1group_1_1cooperative__reduce__t_3_01reduce__kind_00_01tile__shape___00_01ma142eceda8d4b0cef3b9990847430423a.html" target="_self">cooperative_reduce_t&lt; reduce_kind, tile_shape_, matAcc_t, 1, gpu_arch::Xe &gt;</a></td><td class="desc">Workgroups to do the cooperative reduction </td></tr>
<tr id="row_0_0_0_14_" class="odd" style="display:none;"><td class="entry"><span style="width:64px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="classgpu_1_1xetla_1_1group_1_1cooperative__reduce__t_3_01reduce__kind_00_01tile__shape___00_01mad5d1adea938e137c96761a4611a4c7d3.html" target="_self">cooperative_reduce_t&lt; reduce_kind, tile_shape_, matAcc_t, num_cooperative_wg, gpu_arch::Xe &gt;</a></td><td class="desc">Workgroups to do the cooperative reduction. Specialized for Xe architecture </td></tr>
<tr id="row_0_0_0_15_" class="odd" style="display:none;"><td class="entry"><span style="width:64px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="structgpu_1_1xetla_1_1group_1_1epilogue__policy__default.html" target="_self">epilogue_policy_default</a></td><td class="desc">Default epilogue policy for store C </td></tr>
<tr id="row_0_0_0_16_" class="odd" style="display:none;"><td class="entry"><span style="width:64px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="structgpu_1_1xetla_1_1group_1_1epilogue__policy__quant__op.html" target="_self">epilogue_policy_quant_op</a></td><td class="desc">Epilogue functor, specialized for quantization operator </td></tr>
<tr id="row_0_0_0_17_" class="odd" style="display:none;"><td class="entry"><span style="width:64px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="structgpu_1_1xetla_1_1group_1_1epilogue__policy__tile__op.html" target="_self">epilogue_policy_tile_op</a></td><td class="desc">Epilogue policy for tile_op + store C fusion </td></tr>
<tr id="row_0_0_0_18_" class="odd" style="display:none;"><td class="entry"><span style="width:64px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="classgpu_1_1xetla_1_1group_1_1epilogue__t.html" target="_self">epilogue_t</a></td><td class="desc">Is the epilogue functor </td></tr>
<tr id="row_0_0_0_19_" class="odd" style="display:none;"><td class="entry"><span style="width:48px;display:inline-block;">&#160;</span><span id="arr_0_0_0_19_" class="arrow" onclick="toggleFolder('0_0_0_19_')">&#9658;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="classgpu_1_1xetla_1_1group_1_1epilogue__t_3_01epilogue__policy__default_3_01update__method___00_859d08e089de62b8785eb323001884e1.html" target="_self">epilogue_t&lt; epilogue_policy_default&lt; update_method_, gpu_arch::Xe &gt;, tile_shape_, mem_desc_c_t_ &gt;</a></td><td class="desc">Is the epilogue functor specialized for <a class="el" href="structgpu_1_1xetla_1_1group_1_1epilogue__policy__default.html" title="Default epilogue policy for store C.">epilogue_policy_default</a> and Xe architecture </td></tr>
<tr id="row_0_0_0_19_0_" class="odd" style="display:none;"><td class="entry"><span style="width:80px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="structgpu_1_1xetla_1_1group_1_1epilogue__t_3_01epilogue__policy__default_3_01update__method___0051e1da61b3bd9d28462310ba179a10e7.html" target="_self">arguments_t</a></td><td class="desc">Epilogue arguments </td></tr>
<tr id="row_0_0_0_20_" class="odd" style="display:none;"><td class="entry"><span style="width:48px;display:inline-block;">&#160;</span><span id="arr_0_0_0_20_" class="arrow" onclick="toggleFolder('0_0_0_20_')">&#9658;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="classgpu_1_1xetla_1_1group_1_1epilogue__t_3_01epilogue__policy__quant__op_3_01tile__op__t___00_0342488e5e34a93e1ec1669be28813e3c.html" target="_self">epilogue_t&lt; epilogue_policy_quant_op&lt; tile_op_t_, quant_op_t_, gpu_arch::Xe &gt;, tile_shape_, mem_desc_c_t_ &gt;</a></td><td class="desc">Is the epilogue functor specialized for <a class="el" href="structgpu_1_1xetla_1_1group_1_1epilogue__policy__quant__op.html" title="Epilogue functor, specialized for quantization operator.">epilogue_policy_quant_op</a> and Xe architecture </td></tr>
<tr id="row_0_0_0_20_0_" class="odd" style="display:none;"><td class="entry"><span style="width:80px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="structgpu_1_1xetla_1_1group_1_1epilogue__t_3_01epilogue__policy__quant__op_3_01tile__op__t___00_f13d07cec983a538669b91a1ed6ee4c6.html" target="_self">arguments_t</a></td><td class="desc">Epilogue arguments </td></tr>
<tr id="row_0_0_0_21_" class="odd" style="display:none;"><td class="entry"><span style="width:48px;display:inline-block;">&#160;</span><span id="arr_0_0_0_21_" class="arrow" onclick="toggleFolder('0_0_0_21_')">&#9658;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="classgpu_1_1xetla_1_1group_1_1epilogue__t_3_01epilogue__policy__tile__op_3_01tile__op__t___00_01fdfffbb48a21b909e0f0376722b8d7a2.html" target="_self">epilogue_t&lt; epilogue_policy_tile_op&lt; tile_op_t_, gpu_arch::Xe &gt;, tile_shape_, mem_desc_c_t_ &gt;</a></td><td class="desc">Is the epilogue functor specialized for <a class="el" href="structgpu_1_1xetla_1_1group_1_1epilogue__policy__tile__op.html" title="Epilogue policy for tile_op + store C fusion.">epilogue_policy_tile_op</a> and Xe architecture </td></tr>
<tr id="row_0_0_0_21_0_" class="odd" style="display:none;"><td class="entry"><span style="width:80px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="structgpu_1_1xetla_1_1group_1_1epilogue__t_3_01epilogue__policy__tile__op_3_01tile__op__t___00_0815fdfc5c1a66c2d9a8bcdc600e33585.html" target="_self">arguments_t</a></td><td class="desc">Epilogue arguments </td></tr>
<tr id="row_0_0_0_22_" class="odd" style="display:none;"><td class="entry"><span style="width:64px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="structgpu_1_1xetla_1_1group_1_1group__reduce__t.html" target="_self">group_reduce_t</a></td><td class="desc">This is the group reduction </td></tr>
<tr id="row_0_0_0_23_" class="odd" style="display:none;"><td class="entry"><span style="width:64px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="structgpu_1_1xetla_1_1group_1_1group__reduce__t_3_01T_00_01SZ_00_01N_00_01Op_00_011_00_01is__all91388879f880ff2671715a7c4fe8af7c.html" target="_self">group_reduce_t&lt; T, SZ, N, Op, 1, is_all_reduce, gpu_arch::Xe &gt;</a></td><td class="desc"></td></tr>
<tr id="row_0_0_0_24_" class="odd" style="display:none;"><td class="entry"><span style="width:64px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="structgpu_1_1xetla_1_1group_1_1group__reduce__t_3_01T_00_01SZ_00_01N_00_01Op_00_01N__SG_00_01is_312e6f1fad2d403551d4a5a4b4ddfc07.html" target="_self">group_reduce_t&lt; T, SZ, N, Op, N_SG, is_all_reduce, gpu_arch::Xe &gt;</a></td><td class="desc"></td></tr>
<tr id="row_0_0_0_25_" class="odd" style="display:none;"><td class="entry"><span style="width:64px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="structgpu_1_1xetla_1_1group_1_1group__row__reduce__store__t.html" target="_self">group_row_reduce_store_t</a></td><td class="desc">This is the group row reduction(reduce_sum) + cooperative write out </td></tr>
<tr id="row_0_0_0_26_" class="odd" style="display:none;"><td class="entry"><span style="width:64px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="structgpu_1_1xetla_1_1group_1_1group__row__reduce__store__t_3_01dtype__acc_00_01dtype__out_00_01d1fe9e626bc4adc90fe46288676b32cb.html" target="_self">group_row_reduce_store_t&lt; dtype_acc, dtype_out, row_size, wg_size_x, 1, max_simd_len, gpu_arch::Xe &gt;</a></td><td class="desc"></td></tr>
<tr id="row_0_0_0_27_" class="odd" style="display:none;"><td class="entry"><span style="width:64px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="structgpu_1_1xetla_1_1group_1_1group__row__reduce__store__t_3_01dtype__acc_00_01dtype__out_00_01f2ea596db41d958c37b7a7a52caa0906.html" target="_self">group_row_reduce_store_t&lt; dtype_acc, dtype_out, row_size, wg_size_x, wg_size_y, max_simd_len, gpu_arch::Xe &gt;</a></td><td class="desc"></td></tr>
<tr id="row_0_0_0_28_" class="odd" style="display:none;"><td class="entry"><span style="width:64px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="structgpu_1_1xetla_1_1group_1_1ln__bwd__fused__op__arguments__t.html" target="_self">ln_bwd_fused_op_arguments_t</a></td><td class="desc"></td></tr>
<tr id="row_0_0_0_29_" class="odd" style="display:none;"><td class="entry"><span style="width:64px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="structgpu_1_1xetla_1_1group_1_1ln__bwd__fused__op__t.html" target="_self">ln_bwd_fused_op_t</a></td><td class="desc"></td></tr>
<tr id="row_0_0_0_30_" class="odd" style="display:none;"><td class="entry"><span style="width:64px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="structgpu_1_1xetla_1_1group_1_1ln__bwd__fused__op__t_3_01ln__bwd__fused__kind_1_1bias__dropout__cb4d0474e0a28c140fa444d1da09a494.html" target="_self">ln_bwd_fused_op_t&lt; ln_bwd_fused_kind::bias_dropout_resAdd_ln, dtype_in_, dtype_out_, dtype_acc_, layer_norm_attr_, gpu_arch::Xe &gt;</a></td><td class="desc"></td></tr>
<tr id="row_0_0_0_31_" class="odd" style="display:none;"><td class="entry"><span style="width:64px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="structgpu_1_1xetla_1_1group_1_1ln__bwd__fused__op__t_3_01ln__bwd__fused__kind_1_1ln__dropout_00_85855d35f221cf3a31c3a01f77253cdf.html" target="_self">ln_bwd_fused_op_t&lt; ln_bwd_fused_kind::ln_dropout, dtype_in_, dtype_out_, dtype_acc_, layer_norm_attr_, gpu_arch::Xe &gt;</a></td><td class="desc"></td></tr>
<tr id="row_0_0_0_32_" class="odd" style="display:none;"><td class="entry"><span style="width:64px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="structgpu_1_1xetla_1_1group_1_1ln__bwd__fused__op__t_3_01ln__bwd__fused__kind_1_1ln__dropout__gra92c7b1e7d0db3d047617e99aa09b9df.html" target="_self">ln_bwd_fused_op_t&lt; ln_bwd_fused_kind::ln_dropout_gradAdd, dtype_in_, dtype_out_, dtype_acc_, layer_norm_attr_, gpu_arch::Xe &gt;</a></td><td class="desc"></td></tr>
<tr id="row_0_0_0_33_" class="odd" style="display:none;"><td class="entry"><span style="width:64px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="structgpu_1_1xetla_1_1group_1_1ln__bwd__fused__op__t_3_01ln__fused__op__kind___00_01dtype__in___b59b7c4dd4da8b28b7c493261d10e46c.html" target="_self">ln_bwd_fused_op_t&lt; ln_fused_op_kind_, dtype_in_, dtype_out_, dtype_acc_, layer_norm_attr_, gpu_arch::Xe &gt;</a></td><td class="desc"></td></tr>
<tr id="row_0_0_0_34_" class="odd" style="display:none;"><td class="entry"><span style="width:64px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="structgpu_1_1xetla_1_1group_1_1ln__fwd__fused__op__arguments__t.html" target="_self">ln_fwd_fused_op_arguments_t</a></td><td class="desc"></td></tr>
<tr id="row_0_0_0_35_" class="odd" style="display:none;"><td class="entry"><span style="width:64px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="structgpu_1_1xetla_1_1group_1_1ln__fwd__fused__op__t.html" target="_self">ln_fwd_fused_op_t</a></td><td class="desc"></td></tr>
<tr id="row_0_0_0_36_" class="odd" style="display:none;"><td class="entry"><span style="width:64px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="structgpu_1_1xetla_1_1group_1_1ln__fwd__fused__op__t_3_01ln__fused__op__kind___00_01dtype__in___d9ef3e21b9ea10bf2a0134a87c3add4a.html" target="_self">ln_fwd_fused_op_t&lt; ln_fused_op_kind_, dtype_in_, dtype_out_, dtype_acc_, layer_norm_attr_, gpu_arch::Xe &gt;</a></td><td class="desc"></td></tr>
<tr id="row_0_0_0_37_" class="odd" style="display:none;"><td class="entry"><span style="width:64px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="structgpu_1_1xetla_1_1group_1_1ln__fwd__fused__op__t_3_01ln__fwd__fused__kind_1_1bias__dropout__7bd6ac5d5274c089bfc0bfda44480c4d.html" target="_self">ln_fwd_fused_op_t&lt; ln_fwd_fused_kind::bias_dropout_resAdd_ln, dtype_in_, dtype_out_, dtype_acc_, layer_norm_attr_, gpu_arch::Xe &gt;</a></td><td class="desc"></td></tr>
<tr id="row_0_0_0_38_" class="odd" style="display:none;"><td class="entry"><span style="width:64px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="structgpu_1_1xetla_1_1group_1_1ln__fwd__fused__op__t_3_01ln__fwd__fused__kind_1_1bias__rng__dropf3eeeee8529b0a6363a01d09fe71097b.html" target="_self">ln_fwd_fused_op_t&lt; ln_fwd_fused_kind::bias_rng_dropout_resAdd_ln, dtype_in_, dtype_out_, dtype_acc_, layer_norm_attr_, gpu_arch::Xe &gt;</a></td><td class="desc"></td></tr>
<tr id="row_0_0_0_39_" class="odd" style="display:none;"><td class="entry"><span style="width:64px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="structgpu_1_1xetla_1_1group_1_1ln__fwd__fused__op__t_3_01ln__fwd__fused__kind_1_1ln__dropout_00_34050c7e3cd4aeb73d90116cb43adeb3.html" target="_self">ln_fwd_fused_op_t&lt; ln_fwd_fused_kind::ln_dropout, dtype_in_, dtype_out_, dtype_acc_, layer_norm_attr_, gpu_arch::Xe &gt;</a></td><td class="desc"></td></tr>
<tr id="row_0_0_0_40_" class="odd" style="display:none;"><td class="entry"><span style="width:64px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="structgpu_1_1xetla_1_1group_1_1ln__fwd__fused__op__t_3_01ln__fwd__fused__kind_1_1ln__rng__dropou7cd6e677abcfc7a2bed3e7feb170def7.html" target="_self">ln_fwd_fused_op_t&lt; ln_fwd_fused_kind::ln_rng_dropout, dtype_in_, dtype_out_, dtype_acc_, layer_norm_attr_, gpu_arch::Xe &gt;</a></td><td class="desc"></td></tr>
<tr id="row_0_0_0_41_" class="odd" style="display:none;"><td class="entry"><span style="width:48px;display:inline-block;">&#160;</span><span id="arr_0_0_0_41_" class="arrow" onclick="toggleFolder('0_0_0_41_')">&#9658;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="structgpu_1_1xetla_1_1group_1_1mask__gen__t.html" target="_self">mask_gen_t</a></td><td class="desc"></td></tr>
<tr id="row_0_0_0_41_0_" class="odd" style="display:none;"><td class="entry"><span style="width:80px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="structgpu_1_1xetla_1_1group_1_1mask__gen__t_1_1arguments__t.html" target="_self">arguments_t</a></td><td class="desc"></td></tr>
<tr id="row_0_0_0_42_" class="odd" style="display:none;"><td class="entry"><span style="width:64px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="structgpu_1_1xetla_1_1group_1_1perf__tuning__knob__t.html" target="_self">perf_tuning_knob_t</a></td><td class="desc">Fine-tune knobs for brgemm </td></tr>
<tr id="row_0_0_0_43_" class="odd" style="display:none;"><td class="entry"><span style="width:64px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="structgpu_1_1xetla_1_1group_1_1pre__processing__default__t.html" target="_self">pre_processing_default_t</a></td><td class="desc">Brgemm default pre_processing functor </td></tr>
<tr id="row_0_0_0_44_" class="odd" style="display:none;"><td class="entry"><span style="width:48px;display:inline-block;">&#160;</span><span id="arr_0_0_0_44_" class="arrow" onclick="toggleFolder('0_0_0_44_')">&#9658;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="classgpu_1_1xetla_1_1group_1_1pre__processing__default__t_3_01tile__shape___00_01gpu__arch_1_1Xe_01_4.html" target="_self">pre_processing_default_t&lt; tile_shape_, gpu_arch::Xe &gt;</a></td><td class="desc">Brgemm default pre_processing functor. Specialized for Xe architecture </td></tr>
<tr id="row_0_0_0_44_0_" class="odd" style="display:none;"><td class="entry"><span style="width:80px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="structgpu_1_1xetla_1_1group_1_1pre__processing__default__t_3_01tile__shape___00_01gpu__arch_1_1Xe_01_4_1_1arguments__t.html" target="_self">arguments_t</a></td><td class="desc"></td></tr>
<tr id="row_0_0_0_45_" class="odd" style="display:none;"><td class="entry"><span style="width:64px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="structgpu_1_1xetla_1_1group_1_1pre__processing__matA__neg__filter__t.html" target="_self">pre_processing_matA_neg_filter_t</a></td><td class="desc">Brgemm pre_processing functor with applying relu op to matA </td></tr>
<tr id="row_0_0_0_46_" class="odd" style="display:none;"><td class="entry"><span style="width:48px;display:inline-block;">&#160;</span><span id="arr_0_0_0_46_" class="arrow" onclick="toggleFolder('0_0_0_46_')">&#9658;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="classgpu_1_1xetla_1_1group_1_1pre__processing__matA__neg__filter__t_3_01tile__shape___00_01gpu__arch_1_1Xe_01_4.html" target="_self">pre_processing_matA_neg_filter_t&lt; tile_shape_, gpu_arch::Xe &gt;</a></td><td class="desc">Brgemm pre_processing functor with applying relu op to matA. Specialized for Xe architecture </td></tr>
<tr id="row_0_0_0_46_0_" class="odd" style="display:none;"><td class="entry"><span style="width:80px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="structgpu_1_1xetla_1_1group_1_1pre__processing__matA__neg__filter__t_3_01tile__shape___00_01gpu_958b6a3aa9171dc712d3e1f2d7ad35dd.html" target="_self">arguments_t</a></td><td class="desc"></td></tr>
<tr id="row_0_0_0_47_" class="odd" style="display:none;"><td class="entry"><span style="width:64px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="structgpu_1_1xetla_1_1group_1_1row__reduction__fused__op__t.html" target="_self">row_reduction_fused_op_t</a></td><td class="desc">Additional Ops that can be fused with row reduction processing flow </td></tr>
<tr id="row_0_0_0_48_" class="odd" style="display:none;"><td class="entry"><span style="width:64px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="structgpu_1_1xetla_1_1group_1_1row__reduction__fused__op__t_3_01fused__op__kind___00_01dtype__inf93d2b0c91f6c4d3d0687dc6743768bc.html" target="_self">row_reduction_fused_op_t&lt; fused_op_kind_, dtype_in_, dtype_out_, dtype_acc_, reduction_attr_, gpu_arch::Xe &gt;</a></td><td class="desc"></td></tr>
<tr id="row_0_0_0_49_" class="odd" style="display:none;"><td class="entry"><span style="width:64px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="structgpu_1_1xetla_1_1group_1_1row__reduction__fused__op__t_3_01reduction__fused__kind_1_1bias__6377f80bb195328d444af2dd5e7849c7.html" target="_self">row_reduction_fused_op_t&lt; reduction_fused_kind::bias_dropout_bwd, dtype_in_, dtype_out_, dtype_acc_, reduction_attr_, gpu_arch::Xe &gt;</a></td><td class="desc"></td></tr>
<tr id="row_0_0_0_50_" class="odd" style="display:none;"><td class="entry"><span style="width:64px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="structgpu_1_1xetla_1_1group_1_1row__reduction__fused__op__t_3_01reduction__fused__kind_1_1bias__c0f9f338d5e993265bcff2430f6030ee.html" target="_self">row_reduction_fused_op_t&lt; reduction_fused_kind::bias_gelu_w_bwd, dtype_in_, dtype_out_, dtype_acc_, reduction_attr_, gpu_arch::Xe &gt;</a></td><td class="desc"></td></tr>
<tr id="row_0_0_0_51_" class="odd" style="display:none;"><td class="entry"><span style="width:64px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="structgpu_1_1xetla_1_1group_1_1softmax__policy__bwd.html" target="_self">softmax_policy_bwd</a></td><td class="desc"></td></tr>
<tr id="row_0_0_0_52_" class="odd" style="display:none;"><td class="entry"><span style="width:64px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="structgpu_1_1xetla_1_1group_1_1softmax__policy__fwd.html" target="_self">softmax_policy_fwd</a></td><td class="desc"></td></tr>
<tr id="row_0_0_0_53_" class="odd" style="display:none;"><td class="entry"><span style="width:64px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="classgpu_1_1xetla_1_1group_1_1softmax__t.html" target="_self">softmax_t</a></td><td class="desc"></td></tr>
<tr id="row_0_0_0_54_" class="odd" style="display:none;"><td class="entry"><span style="width:48px;display:inline-block;">&#160;</span><span id="arr_0_0_0_54_" class="arrow" onclick="toggleFolder('0_0_0_54_')">&#9658;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="classgpu_1_1xetla_1_1group_1_1softmax__t_3_01softmax__policy__bwd_3_01dtype__in___00_01dtype__acda1a271441348bf3d3e23aa53bad6eb9.html" target="_self">softmax_t&lt; softmax_policy_bwd&lt; dtype_in_, dtype_acc_, gpu_arch::Xe &gt;, tile_shape_ &gt;</a></td><td class="desc"></td></tr>
<tr id="row_0_0_0_54_0_" class="odd" style="display:none;"><td class="entry"><span style="width:80px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="structgpu_1_1xetla_1_1group_1_1softmax__t_3_01softmax__policy__bwd_3_01dtype__in___00_01dtype__aaf2e5f57374d834d9b2f561be05ddd8c.html" target="_self">arguments_t</a></td><td class="desc"></td></tr>
<tr id="row_0_0_0_54_1_" class="odd" style="display:none;"><td class="entry"><span style="width:80px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="structgpu_1_1xetla_1_1group_1_1softmax__t_3_01softmax__policy__bwd_3_01dtype__in___00_01dtype__ab5a920ee52ce6ba0689e24d1285f5566.html" target="_self">get_barrier_count</a></td><td class="desc"></td></tr>
<tr id="row_0_0_0_54_2_" class="odd" style="display:none;"><td class="entry"><span style="width:80px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="structgpu_1_1xetla_1_1group_1_1softmax__t_3_01softmax__policy__bwd_3_01dtype__in___00_01dtype__a41429c63d93cb078a73a411866c2d1db.html" target="_self">get_slm_size</a></td><td class="desc"></td></tr>
<tr id="row_0_0_0_55_" class="odd" style="display:none;"><td class="entry"><span style="width:48px;display:inline-block;">&#160;</span><span id="arr_0_0_0_55_" class="arrow" onclick="toggleFolder('0_0_0_55_')">&#9658;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="classgpu_1_1xetla_1_1group_1_1softmax__t_3_01softmax__policy__fwd_3_01dtype__acc___00_01gpu__arc90582f6f8cb5a09b900a35996a4b06fd.html" target="_self">softmax_t&lt; softmax_policy_fwd&lt; dtype_acc_, gpu_arch::Xe &gt;, tile_shape_ &gt;</a></td><td class="desc"></td></tr>
<tr id="row_0_0_0_55_0_" class="odd" style="display:none;"><td class="entry"><span style="width:80px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="structgpu_1_1xetla_1_1group_1_1softmax__t_3_01softmax__policy__fwd_3_01dtype__acc___00_01gpu__arc1ca9e3f8a02e7a4314cb145131d3c75.html" target="_self">arguments_t</a></td><td class="desc"></td></tr>
<tr id="row_0_0_0_55_1_" class="odd" style="display:none;"><td class="entry"><span style="width:80px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="structgpu_1_1xetla_1_1group_1_1softmax__t_3_01softmax__policy__fwd_3_01dtype__acc___00_01gpu__ar7588689606780024e885d76ccdd3efc5.html" target="_self">get_barrier_count</a></td><td class="desc"></td></tr>
<tr id="row_0_0_0_55_2_" class="odd" style="display:none;"><td class="entry"><span style="width:80px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="structgpu_1_1xetla_1_1group_1_1softmax__t_3_01softmax__policy__fwd_3_01dtype__acc___00_01gpu__ara933eeb15d678005bf66882086c74f5d.html" target="_self">get_slm_size</a></td><td class="desc"></td></tr>
<tr id="row_0_0_0_56_" class="odd" style="display:none;"><td class="entry"><span style="width:64px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="structgpu_1_1xetla_1_1group_1_1tile__shape__t.html" target="_self">tile_shape_t</a></td><td class="desc">Workgroup level tile shape description </td></tr>
<tr id="row_0_0_0_57_" class="odd" style="display:none;"><td class="entry"><span style="width:64px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="structgpu_1_1xetla_1_1group_1_1xetla__row__reduction__fused__op__arguments__t.html" target="_self">xetla_row_reduction_fused_op_arguments_t</a></td><td class="desc"></td></tr>
<tr id="row_0_0_1_" class="odd"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span id="arr_0_0_1_" class="arrow" onclick="toggleFolder('0_0_1_')">&#9658;</span><span class="icona"><span class="icon">N</span></span><a class="el" href="namespacegpu_1_1xetla_1_1kernel.html" target="_self">kernel</a></td><td class="desc"></td></tr>
<tr id="row_0_0_1_0_" class="even" style="display:none;"><td class="entry"><span style="width:64px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="structgpu_1_1xetla_1_1kernel_1_1data__transformer__attr__t.html" target="_self">data_transformer_attr_t</a></td><td class="desc"></td></tr>
<tr id="row_0_0_1_1_" class="even" style="display:none;"><td class="entry"><span style="width:64px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="structgpu_1_1xetla_1_1kernel_1_1dispatch__policy__default.html" target="_self">dispatch_policy_default</a></td><td class="desc">Default GEMM implementation </td></tr>
<tr id="row_0_0_1_2_" class="even" style="display:none;"><td class="entry"><span style="width:64px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="structgpu_1_1xetla_1_1kernel_1_1dispatch__policy__kslicing.html" target="_self">dispatch_policy_kslicing</a></td><td class="desc">Kslicing GEMM implementation </td></tr>
<tr id="row_0_0_1_3_" class="even" style="display:none;"><td class="entry"><span style="width:64px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="classgpu_1_1xetla_1_1kernel_1_1gemm__t.html" target="_self">gemm_t</a></td><td class="desc">GEMM functor </td></tr>
<tr id="row_0_0_1_4_" class="even" style="display:none;"><td class="entry"><span style="width:48px;display:inline-block;">&#160;</span><span id="arr_0_0_1_4_" class="arrow" onclick="toggleFolder('0_0_1_4_')">&#9658;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="classgpu_1_1xetla_1_1kernel_1_1gemm__t_3_01dispatch__policy__default_3_01gpu__arch_1_1Xe_01_4_0051d16bedb91f5891d70e390cac9b64a4.html" target="_self">gemm_t&lt; dispatch_policy_default&lt; gpu_arch::Xe &gt;, brgemm_t_, epilogue_t_ &gt;</a></td><td class="desc">Default GEMM functor, specialized for Xe architecture </td></tr>
<tr id="row_0_0_1_4_0_" class="even" style="display:none;"><td class="entry"><span style="width:80px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="structgpu_1_1xetla_1_1kernel_1_1gemm__t_3_01dispatch__policy__default_3_01gpu__arch_1_1Xe_01_4_0db93540e69047ebd206bbd99ad0d08b4.html" target="_self">arguments_t</a></td><td class="desc">GEMM arguments </td></tr>
<tr id="row_0_0_1_5_" class="even" style="display:none;"><td class="entry"><span style="width:48px;display:inline-block;">&#160;</span><span id="arr_0_0_1_5_" class="arrow" onclick="toggleFolder('0_0_1_5_')">&#9658;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="classgpu_1_1xetla_1_1kernel_1_1gemm__t_3_01dispatch__policy__kslicing_3_01global__kslicing__ratiae9f80c882ba18776d69f655bbd0163d.html" target="_self">gemm_t&lt; dispatch_policy_kslicing&lt; global_kslicing_ratio_, local_kslicing_ratio_, gpu_arch::Xe &gt;, brgemm_t_, epilogue_t_ &gt;</a></td><td class="desc">Is the GEMM functor, specialized in kslicing dispatch policy and Xe architecture </td></tr>
<tr id="row_0_0_1_5_0_" class="even" style="display:none;"><td class="entry"><span style="width:80px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="structgpu_1_1xetla_1_1kernel_1_1gemm__t_3_01dispatch__policy__kslicing_3_01global__kslicing__rata2435eaf6b4dc1a469620cfab2d21f0a.html" target="_self">arguments_t</a></td><td class="desc">GEMM arguments </td></tr>
<tr id="row_0_0_1_6_" class="even" style="display:none;"><td class="entry"><span style="width:64px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="structgpu_1_1xetla_1_1kernel_1_1layer__norm__attr__t.html" target="_self">layer_norm_attr_t</a></td><td class="desc">Sets up attribute of the layer norm </td></tr>
<tr id="row_0_0_1_7_" class="even" style="display:none;"><td class="entry"><span style="width:64px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="structgpu_1_1xetla_1_1kernel_1_1layer__norm__bwd__t.html" target="_self">layer_norm_bwd_t</a></td><td class="desc"></td></tr>
<tr id="row_0_0_1_8_" class="even" style="display:none;"><td class="entry"><span style="width:48px;display:inline-block;">&#160;</span><span id="arr_0_0_1_8_" class="arrow" onclick="toggleFolder('0_0_1_8_')">&#9658;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="structgpu_1_1xetla_1_1kernel_1_1layer__norm__bwd__t_3_01dtype__x___00_01dtype__y___00_01dtype__w5e223ea0bd3a3851e47c460f10bccc84.html" target="_self">layer_norm_bwd_t&lt; dtype_x_, dtype_y_, dtype_weight_, dtype_acc_, layer_norm_attr_, gpu_arch::Xe, ln_bwd_fused_op_ &gt;</a></td><td class="desc"></td></tr>
<tr id="row_0_0_1_8_0_" class="even" style="display:none;"><td class="entry"><span style="width:80px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="structgpu_1_1xetla_1_1kernel_1_1layer__norm__bwd__t_3_01dtype__x___00_01dtype__y___00_01dtype__w8c870e0747f737257129382bb64d56e0.html" target="_self">arguments_t</a></td><td class="desc"></td></tr>
<tr id="row_0_0_1_8_1_" class="even" style="display:none;"><td class="entry"><span style="width:80px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="structgpu_1_1xetla_1_1kernel_1_1layer__norm__bwd__t_3_01dtype__x___00_01dtype__y___00_01dtype__wc6027ac29965333ffa97f8b5703c2982.html" target="_self">get_barrier_count</a></td><td class="desc"></td></tr>
<tr id="row_0_0_1_8_2_" class="even" style="display:none;"><td class="entry"><span style="width:80px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="structgpu_1_1xetla_1_1kernel_1_1layer__norm__bwd__t_3_01dtype__x___00_01dtype__y___00_01dtype__wd8d91116cddf28aca893d04fd21e65d8.html" target="_self">get_slm_size</a></td><td class="desc"></td></tr>
<tr id="row_0_0_1_9_" class="even" style="display:none;"><td class="entry"><span style="width:64px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="structgpu_1_1xetla_1_1kernel_1_1layer__norm__fwd__t.html" target="_self">layer_norm_fwd_t</a></td><td class="desc"></td></tr>
<tr id="row_0_0_1_10_" class="even" style="display:none;"><td class="entry"><span style="width:48px;display:inline-block;">&#160;</span><span id="arr_0_0_1_10_" class="arrow" onclick="toggleFolder('0_0_1_10_')">&#9658;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="structgpu_1_1xetla_1_1kernel_1_1layer__norm__fwd__t_3_01dtype__x___00_01dtype__y___00_01dtype__wf6b635a4d65490f92949ed8f8e6c9766.html" target="_self">layer_norm_fwd_t&lt; dtype_x_, dtype_y_, dtype_weight_, dtype_acc_, layer_norm_attr_, store_for_bwd_, gpu_arch::Xe, ln_fwd_fused_op_ &gt;</a></td><td class="desc"></td></tr>
<tr id="row_0_0_1_10_0_" class="even" style="display:none;"><td class="entry"><span style="width:80px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="structgpu_1_1xetla_1_1kernel_1_1layer__norm__fwd__t_3_01dtype__x___00_01dtype__y___00_01dtype__w678e01627b39f80350d654b1d9c8f6b0.html" target="_self">arguments_t</a></td><td class="desc"></td></tr>
<tr id="row_0_0_1_10_1_" class="even" style="display:none;"><td class="entry"><span style="width:80px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="structgpu_1_1xetla_1_1kernel_1_1layer__norm__fwd__t_3_01dtype__x___00_01dtype__y___00_01dtype__wd08696fa56c321e029984c701d4f5730.html" target="_self">get_barrier_count</a></td><td class="desc"></td></tr>
<tr id="row_0_0_1_10_2_" class="even" style="display:none;"><td class="entry"><span style="width:80px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="structgpu_1_1xetla_1_1kernel_1_1layer__norm__fwd__t_3_01dtype__x___00_01dtype__y___00_01dtype__w1fae1b1d7e31ebc935e4665707a2f860.html" target="_self">get_slm_size</a></td><td class="desc"></td></tr>
<tr id="row_0_0_1_10_3_" class="even" style="display:none;"><td class="entry"><span style="width:80px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="structgpu_1_1xetla_1_1kernel_1_1layer__norm__fwd__t_3_01dtype__x___00_01dtype__y___00_01dtype__w1874b19073e1f423699cbfc0c66a9c60.html" target="_self">parallel_mu_m2_t</a></td><td class="desc"></td></tr>
<tr id="row_0_0_1_10_4_" class="even" style="display:none;"><td class="entry"><span style="width:80px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="structgpu_1_1xetla_1_1kernel_1_1layer__norm__fwd__t_3_01dtype__x___00_01dtype__y___00_01dtype__w34b86ab2795b16851d713a3deae4a27a.html" target="_self">parallel_mu_m2_t&lt; T, 1, N &gt;</a></td><td class="desc"></td></tr>
<tr id="row_0_0_1_11_" class="even" style="display:none;"><td class="entry"><span style="width:64px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="structgpu_1_1xetla_1_1kernel_1_1row__reduction__attr__t.html" target="_self">row_reduction_attr_t</a></td><td class="desc">Sets up attribute of the row reduction </td></tr>
<tr id="row_0_0_1_12_" class="even" style="display:none;"><td class="entry"><span style="width:64px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="structgpu_1_1xetla_1_1kernel_1_1xetla__data__transformer.html" target="_self">xetla_data_transformer</a></td><td class="desc">Is the data_transformer functor </td></tr>
<tr id="row_0_0_1_13_" class="even" style="display:none;"><td class="entry"><span style="width:48px;display:inline-block;">&#160;</span><span id="arr_0_0_1_13_" class="arrow" onclick="toggleFolder('0_0_1_13_')">&#9658;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="structgpu_1_1xetla_1_1kernel_1_1xetla__data__transformer_3_01dtype__in___00_01dtype__out___00_014a477369ffef328160ffcdf09316fb24.html" target="_self">xetla_data_transformer&lt; dtype_in_, dtype_out_, dtype_compute_, data_transformer_attr_, mem_layout_in_, need_fp8_op, gpu_arch::Xe &gt;</a></td><td class="desc">Is the data_transformer functor for Xe Each time, each thread will load sg_tile_m x sg_tile_n data into register and do the data convert </td></tr>
<tr id="row_0_0_1_13_0_" class="even" style="display:none;"><td class="entry"><span style="width:80px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="structgpu_1_1xetla_1_1kernel_1_1xetla__data__transformer_3_01dtype__in___00_01dtype__out___00_01eee9a0dbc5ed89980f008e699edc33af.html" target="_self">arguments_t</a></td><td class="desc">Arguments for gemm::run </td></tr>
<tr id="row_0_0_1_13_1_" class="even" style="display:none;"><td class="entry"><span style="width:80px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="structgpu_1_1xetla_1_1kernel_1_1xetla__data__transformer_3_01dtype__in___00_01dtype__out___00_015454549f3796976cb10fe3722d61088d.html" target="_self">get_barrier_count</a></td><td class="desc"></td></tr>
<tr id="row_0_0_1_13_2_" class="even" style="display:none;"><td class="entry"><span style="width:80px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="structgpu_1_1xetla_1_1kernel_1_1xetla__data__transformer_3_01dtype__in___00_01dtype__out___00_01999440d6b40b8e03d91fb5048cb93856.html" target="_self">get_slm_size</a></td><td class="desc"></td></tr>
<tr id="row_0_0_1_14_" class="even" style="display:none;"><td class="entry"><span style="width:48px;display:inline-block;">&#160;</span><span id="arr_0_0_1_14_" class="arrow" onclick="toggleFolder('0_0_1_14_')">&#9658;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="structgpu_1_1xetla_1_1kernel_1_1xetla__mha__attn__reg__bwd__t.html" target="_self">xetla_mha_attn_reg_bwd_t</a></td><td class="desc"></td></tr>
<tr id="row_0_0_1_14_0_" class="even" style="display:none;"><td class="entry"><span style="width:80px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="structgpu_1_1xetla_1_1kernel_1_1xetla__mha__attn__reg__bwd__t_1_1arguments__t.html" target="_self">arguments_t</a></td><td class="desc">Arguments for xetla_softmax_bwd_t::run </td></tr>
<tr id="row_0_0_1_15_" class="even" style="display:none;"><td class="entry"><span style="width:48px;display:inline-block;">&#160;</span><span id="arr_0_0_1_15_" class="arrow" onclick="toggleFolder('0_0_1_15_')">&#9658;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="structgpu_1_1xetla_1_1kernel_1_1xetla__mha__attn__reg__fwd__t.html" target="_self">xetla_mha_attn_reg_fwd_t</a></td><td class="desc"></td></tr>
<tr id="row_0_0_1_15_0_" class="even" style="display:none;"><td class="entry"><span style="width:80px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="structgpu_1_1xetla_1_1kernel_1_1xetla__mha__attn__reg__fwd__t_1_1arguments__t.html" target="_self">arguments_t</a></td><td class="desc">Arguments for xetla_softmax_fwd_t::run </td></tr>
<tr id="row_0_0_1_16_" class="even" style="display:none;"><td class="entry"><span style="width:48px;display:inline-block;">&#160;</span><span id="arr_0_0_1_16_" class="arrow" onclick="toggleFolder('0_0_1_16_')">&#9658;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="structgpu_1_1xetla_1_1kernel_1_1xetla__mha__core__attn__bwd__t.html" target="_self">xetla_mha_core_attn_bwd_t</a></td><td class="desc"></td></tr>
<tr id="row_0_0_1_16_0_" class="even" style="display:none;"><td class="entry"><span style="width:80px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="structgpu_1_1xetla_1_1kernel_1_1xetla__mha__core__attn__bwd__t_1_1arguments__t.html" target="_self">arguments_t</a></td><td class="desc">Arguments for xetla_softmax_bwd_t::run </td></tr>
<tr id="row_0_0_1_17_" class="even" style="display:none;"><td class="entry"><span style="width:48px;display:inline-block;">&#160;</span><span id="arr_0_0_1_17_" class="arrow" onclick="toggleFolder('0_0_1_17_')">&#9658;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="structgpu_1_1xetla_1_1kernel_1_1xetla__mha__core__attn__fwd__t.html" target="_self">xetla_mha_core_attn_fwd_t</a></td><td class="desc"></td></tr>
<tr id="row_0_0_1_17_0_" class="even" style="display:none;"><td class="entry"><span style="width:80px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="structgpu_1_1xetla_1_1kernel_1_1xetla__mha__core__attn__fwd__t_1_1arguments__t.html" target="_self">arguments_t</a></td><td class="desc">Arguments for xetla_softmax_fwd_t::run </td></tr>
<tr id="row_0_0_1_18_" class="even" style="display:none;"><td class="entry"><span style="width:64px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="structgpu_1_1xetla_1_1kernel_1_1xetla__row__reduction__t.html" target="_self">xetla_row_reduction_t</a></td><td class="desc">Is the row_reduction functor </td></tr>
<tr id="row_0_0_1_19_" class="even" style="display:none;"><td class="entry"><span style="width:48px;display:inline-block;">&#160;</span><span id="arr_0_0_1_19_" class="arrow" onclick="toggleFolder('0_0_1_19_')">&#9658;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="structgpu_1_1xetla_1_1kernel_1_1xetla__row__reduction__t_3_01dtype__in___00_01dtype__out___00_01cd72c8b824c01ad6c9039a9957986bd1.html" target="_self">xetla_row_reduction_t&lt; dtype_in_, dtype_out_, dtype_acc_, reduction_attr_, gpu_arch::Xe, fused_op_t_ &gt;</a></td><td class="desc">Is the row_reduction functor for Xe The idea is threads in group will cooperatively process matrix_m x wg_tile_n </td></tr>
<tr id="row_0_0_1_19_0_" class="even" style="display:none;"><td class="entry"><span style="width:80px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="structgpu_1_1xetla_1_1kernel_1_1xetla__row__reduction__t_3_01dtype__in___00_01dtype__out___00_01d703f0733f6648ba84e612999daf0ef3.html" target="_self">arguments_t</a></td><td class="desc"></td></tr>
<tr id="row_0_0_1_19_1_" class="even" style="display:none;"><td class="entry"><span style="width:80px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="structgpu_1_1xetla_1_1kernel_1_1xetla__row__reduction__t_3_01dtype__in___00_01dtype__out___00_01ef61a28dd8e024a554c3d6b6a7c91b5a.html" target="_self">get_barrier_count</a></td><td class="desc"></td></tr>
<tr id="row_0_0_1_19_2_" class="even" style="display:none;"><td class="entry"><span style="width:80px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="structgpu_1_1xetla_1_1kernel_1_1xetla__row__reduction__t_3_01dtype__in___00_01dtype__out___00_012cbcb158999a8b0a10ed2f46addec6df.html" target="_self">get_slm_size</a></td><td class="desc"></td></tr>
<tr id="row_0_0_2_" class="even"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span id="arr_0_0_2_" class="arrow" onclick="toggleFolder('0_0_2_')">&#9658;</span><span class="icona"><span class="icon">N</span></span><a class="el" href="namespacegpu_1_1xetla_1_1subgroup.html" target="_self">subgroup</a></td><td class="desc"></td></tr>
<tr id="row_0_0_2_0_" class="odd" style="display:none;"><td class="entry"><span style="width:48px;display:inline-block;">&#160;</span><span id="arr_0_0_2_0_" class="arrow" onclick="toggleFolder('0_0_2_0_')">&#9658;</span><span class="icona"><span class="icon">N</span></span><a class="el" href="namespacegpu_1_1xetla_1_1subgroup_1_1detail.html" target="_self">detail</a></td><td class="desc"></td></tr>
<tr id="row_0_0_2_0_0_" class="odd" style="display:none;"><td class="entry"><span style="width:80px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="structgpu_1_1xetla_1_1subgroup_1_1detail_1_1check__load__type.html" target="_self">check_load_type</a></td><td class="desc"></td></tr>
<tr id="row_0_0_2_0_1_" class="odd" style="display:none;"><td class="entry"><span style="width:80px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="structgpu_1_1xetla_1_1subgroup_1_1detail_1_1check__prefetch__type.html" target="_self">check_prefetch_type</a></td><td class="desc"></td></tr>
<tr id="row_0_0_2_0_2_" class="odd" style="display:none;"><td class="entry"><span style="width:80px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="structgpu_1_1xetla_1_1subgroup_1_1detail_1_1check__store__type.html" target="_self">check_store_type</a></td><td class="desc"></td></tr>
<tr id="row_0_0_2_0_3_" class="odd" style="display:none;"><td class="entry"><span style="width:80px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="structgpu_1_1xetla_1_1subgroup_1_1detail_1_1gcd.html" target="_self">gcd</a></td><td class="desc"></td></tr>
<tr id="row_0_0_2_0_4_" class="odd" style="display:none;"><td class="entry"><span style="width:80px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="structgpu_1_1xetla_1_1subgroup_1_1detail_1_1gcd_3_01a_00_010_01_4.html" target="_self">gcd&lt; a, 0 &gt;</a></td><td class="desc"></td></tr>
<tr id="row_0_0_2_0_5_" class="odd" style="display:none;"><td class="entry"><span style="width:80px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="structgpu_1_1xetla_1_1subgroup_1_1detail_1_1NextPowerOf2.html" target="_self">NextPowerOf2</a></td><td class="desc">Compute next power of 2 of a constexpr with guaranteed compile-time evaluation </td></tr>
<tr id="row_0_0_2_0_6_" class="odd" style="display:none;"><td class="entry"><span style="width:80px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="structgpu_1_1xetla_1_1subgroup_1_1detail_1_1NextPowerOf2_3_01N_00_01K_00_01false_01_4.html" target="_self">NextPowerOf2&lt; N, K, false &gt;</a></td><td class="desc"></td></tr>
<tr id="row_0_0_2_0_7_" class="odd" style="display:none;"><td class="entry"><span style="width:80px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="structgpu_1_1xetla_1_1subgroup_1_1detail_1_1NextPowerOf2_3_01N_00_01K_00_01true_01_4.html" target="_self">NextPowerOf2&lt; N, K, true &gt;</a></td><td class="desc"></td></tr>
<tr id="row_0_0_2_1_" class="odd" style="display:none;"><td class="entry"><span style="width:64px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="structgpu_1_1xetla_1_1subgroup_1_1bias__add__op__t.html" target="_self">bias_add_op_t</a></td><td class="desc">Is the bias_add op functor </td></tr>
<tr id="row_0_0_2_2_" class="odd" style="display:none;"><td class="entry"><span style="width:48px;display:inline-block;">&#160;</span><span id="arr_0_0_2_2_" class="arrow" onclick="toggleFolder('0_0_2_2_')">&#9658;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="structgpu_1_1xetla_1_1subgroup_1_1bias__add__op__t_3_01dtype__bias___00_01gpu__arch_1_1Xe_01_4.html" target="_self">bias_add_op_t&lt; dtype_bias_, gpu_arch::Xe &gt;</a></td><td class="desc">Is the bias_add op functor, specialized for Xe architecture </td></tr>
<tr id="row_0_0_2_2_0_" class="odd" style="display:none;"><td class="entry"><span style="width:80px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="structgpu_1_1xetla_1_1subgroup_1_1bias__add__op__t_3_01dtype__bias___00_01gpu__arch_1_1Xe_01_4_1_1arguments__t.html" target="_self">arguments_t</a></td><td class="desc"></td></tr>
<tr id="row_0_0_2_3_" class="odd" style="display:none;"><td class="entry"><span style="width:64px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="structgpu_1_1xetla_1_1subgroup_1_1chained__tile__op__arg__t.html" target="_self">chained_tile_op_arg_t</a></td><td class="desc"></td></tr>
<tr id="row_0_0_2_4_" class="odd" style="display:none;"><td class="entry"><span style="width:64px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="structgpu_1_1xetla_1_1subgroup_1_1chained__tile__op__arg__t_3_01idx_00_01curr__args__t_00_01remain__args__t_8_8_8_01_4.html" target="_self">chained_tile_op_arg_t&lt; idx, curr_args_t, remain_args_t... &gt;</a></td><td class="desc"></td></tr>
<tr id="row_0_0_2_5_" class="odd" style="display:none;"><td class="entry"><span style="width:64px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="structgpu_1_1xetla_1_1subgroup_1_1chained__tile__op__t.html" target="_self">chained_tile_op_t</a></td><td class="desc"></td></tr>
<tr id="row_0_0_2_6_" class="odd" style="display:none;"><td class="entry"><span style="width:64px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="structgpu_1_1xetla_1_1subgroup_1_1dropout__op__t.html" target="_self">dropout_op_t</a></td><td class="desc">Is the dropout op functor </td></tr>
<tr id="row_0_0_2_7_" class="odd" style="display:none;"><td class="entry"><span style="width:48px;display:inline-block;">&#160;</span><span id="arr_0_0_2_7_" class="arrow" onclick="toggleFolder('0_0_2_7_')">&#9658;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="structgpu_1_1xetla_1_1subgroup_1_1dropout__op__t_3_01dtype__mask___00_01gpu__arch_1_1Xe_01_4.html" target="_self">dropout_op_t&lt; dtype_mask_, gpu_arch::Xe &gt;</a></td><td class="desc">Is the dropout op functor, specialized for Xe architecture </td></tr>
<tr id="row_0_0_2_7_0_" class="odd" style="display:none;"><td class="entry"><span style="width:80px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="structgpu_1_1xetla_1_1subgroup_1_1dropout__op__t_3_01dtype__mask___00_01gpu__arch_1_1Xe_01_4_1_1arguments__t.html" target="_self">arguments_t</a></td><td class="desc"></td></tr>
<tr id="row_0_0_2_8_" class="odd" style="display:none;"><td class="entry"><span style="width:64px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="structgpu_1_1xetla_1_1subgroup_1_1elemwise__reduce__op__t.html" target="_self">elemwise_reduce_op_t</a></td><td class="desc">Is the element-wise reduce op functor </td></tr>
<tr id="row_0_0_2_9_" class="odd" style="display:none;"><td class="entry"><span style="width:48px;display:inline-block;">&#160;</span><span id="arr_0_0_2_9_" class="arrow" onclick="toggleFolder('0_0_2_9_')">&#9658;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="structgpu_1_1xetla_1_1subgroup_1_1elemwise__reduce__op__t_3_01reduce__kind___00_01dtype__in___00_01gpu__arch_1_1Xe_01_4.html" target="_self">elemwise_reduce_op_t&lt; reduce_kind_, dtype_in_, gpu_arch::Xe &gt;</a></td><td class="desc">Is the element-wise reduce op functor, specialized for Xe architecture </td></tr>
<tr id="row_0_0_2_9_0_" class="odd" style="display:none;"><td class="entry"><span style="width:80px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="structgpu_1_1xetla_1_1subgroup_1_1elemwise__reduce__op__t_3_01reduce__kind___00_01dtype__in___00b3307d6d66a79c31b4e821c4e0de2150.html" target="_self">arguments_t</a></td><td class="desc"></td></tr>
<tr id="row_0_0_2_10_" class="odd" style="display:none;"><td class="entry"><span style="width:64px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="structgpu_1_1xetla_1_1subgroup_1_1gelu__bwd__op__t.html" target="_self">gelu_bwd_op_t</a></td><td class="desc">Is the element-wise gelu backward op functor </td></tr>
<tr id="row_0_0_2_11_" class="odd" style="display:none;"><td class="entry"><span style="width:48px;display:inline-block;">&#160;</span><span id="arr_0_0_2_11_" class="arrow" onclick="toggleFolder('0_0_2_11_')">&#9658;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="structgpu_1_1xetla_1_1subgroup_1_1gelu__bwd__op__t_3_01dtype__in___00_01gpu__arch_1_1Xe_01_4.html" target="_self">gelu_bwd_op_t&lt; dtype_in_, gpu_arch::Xe &gt;</a></td><td class="desc">Is the element-wise gelu backward op functor, specialized for Xe architecture </td></tr>
<tr id="row_0_0_2_11_0_" class="odd" style="display:none;"><td class="entry"><span style="width:80px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="structgpu_1_1xetla_1_1subgroup_1_1gelu__bwd__op__t_3_01dtype__in___00_01gpu__arch_1_1Xe_01_4_1_1arguments__t.html" target="_self">arguments_t</a></td><td class="desc"></td></tr>
<tr id="row_0_0_2_12_" class="odd" style="display:none;"><td class="entry"><span style="width:48px;display:inline-block;">&#160;</span><span id="arr_0_0_2_12_" class="arrow" onclick="toggleFolder('0_0_2_12_')">&#9658;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="structgpu_1_1xetla_1_1subgroup_1_1gelu__fwd__op__t.html" target="_self">gelu_fwd_op_t</a></td><td class="desc">Is the element-wise gelu inference forward op functor </td></tr>
<tr id="row_0_0_2_12_0_" class="odd" style="display:none;"><td class="entry"><span style="width:80px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="structgpu_1_1xetla_1_1subgroup_1_1gelu__fwd__op__t_1_1arguments__t.html" target="_self">arguments_t</a></td><td class="desc"></td></tr>
<tr id="row_0_0_2_13_" class="odd" style="display:none;"><td class="entry"><span style="width:64px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="structgpu_1_1xetla_1_1subgroup_1_1gelu__fwd__w__op__t.html" target="_self">gelu_fwd_w_op_t</a></td><td class="desc">Is the element-wise gelu training forward op functor </td></tr>
<tr id="row_0_0_2_14_" class="odd" style="display:none;"><td class="entry"><span style="width:48px;display:inline-block;">&#160;</span><span id="arr_0_0_2_14_" class="arrow" onclick="toggleFolder('0_0_2_14_')">&#9658;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="structgpu_1_1xetla_1_1subgroup_1_1gelu__fwd__w__op__t_3_01dtype__out___00_01gpu__arch_1_1Xe_01_4.html" target="_self">gelu_fwd_w_op_t&lt; dtype_out_, gpu_arch::Xe &gt;</a></td><td class="desc">Is the element-wise gelu training forward op functor, specialized for Xe architecture </td></tr>
<tr id="row_0_0_2_14_0_" class="odd" style="display:none;"><td class="entry"><span style="width:80px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="structgpu_1_1xetla_1_1subgroup_1_1gelu__fwd__w__op__t_3_01dtype__out___00_01gpu__arch_1_1Xe_01_4_1_1arguments__t.html" target="_self">arguments_t</a></td><td class="desc"></td></tr>
<tr id="row_0_0_2_15_" class="odd" style="display:none;"><td class="entry"><span style="width:64px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="structgpu_1_1xetla_1_1subgroup_1_1get__load__block__size__auto.html" target="_self">get_load_block_size_auto</a></td><td class="desc"></td></tr>
<tr id="row_0_0_2_16_" class="odd" style="display:none;"><td class="entry"><span style="width:64px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="structgpu_1_1xetla_1_1subgroup_1_1get__load__block__size__auto_3_01dtype_00_01tile__size__x_00_043561ddbe884fdfdc5805813b0293052.html" target="_self">get_load_block_size_auto&lt; dtype, tile_size_x, tile_size_y, gpu_arch::Xe, mem_layout::row_major, reg_layout::tiled &gt;</a></td><td class="desc"></td></tr>
<tr id="row_0_0_2_17_" class="odd" style="display:none;"><td class="entry"><span style="width:64px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="structgpu_1_1xetla_1_1subgroup_1_1get__store__block__size__auto.html" target="_self">get_store_block_size_auto</a></td><td class="desc"></td></tr>
<tr id="row_0_0_2_18_" class="odd" style="display:none;"><td class="entry"><span style="width:64px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="structgpu_1_1xetla_1_1subgroup_1_1get__store__block__size__auto_3_01dtype_00_01tile__size__x_00_7188bde0744e02dc2363bd5e8a330d24.html" target="_self">get_store_block_size_auto&lt; dtype, tile_size_x, tile_size_y, gpu_arch::Xe, mem_layout::row_major, reg_layout::tiled &gt;</a></td><td class="desc"></td></tr>
<tr id="row_0_0_2_19_" class="odd" style="display:none;"><td class="entry"><span style="width:64px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="structgpu_1_1xetla_1_1subgroup_1_1mem__payload__t.html" target="_self">mem_payload_t</a></td><td class="desc">Is to illustrate the memory information </td></tr>
<tr id="row_0_0_2_20_" class="odd" style="display:none;"><td class="entry"><span style="width:64px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="structgpu_1_1xetla_1_1subgroup_1_1mem__payload__t_3_01dtype___00_01tile__desc___00_01msg__type_1d44935cfd2d9fbcb517f77b34aee250d.html" target="_self">mem_payload_t&lt; dtype_, tile_desc_, msg_type::atomic_add, mem_layout::row_major, mem_space::global, gpu_arch::Xe &gt;</a></td><td class="desc">Is to describe the global memory surface for atomic store For atomic store, we need to prepare necessary information for each simd channel </td></tr>
<tr id="row_0_0_2_21_" class="odd" style="display:none;"><td class="entry"><span style="width:64px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="structgpu_1_1xetla_1_1subgroup_1_1mem__payload__t_3_01dtype___00_01tile__desc___00_01msg__type_147e897667466bee4b1df4af591b57456.html" target="_self">mem_payload_t&lt; dtype_, tile_desc_, msg_type::block_1d, mem_layout::row_major, mem_space::global, gpu_arch::Xe &gt;</a></td><td class="desc">Is to describe the global memory surface for block-1d load/store For a block-1d payload message we need to set the base address and offset of surface </td></tr>
<tr id="row_0_0_2_22_" class="odd" style="display:none;"><td class="entry"><span style="width:64px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="structgpu_1_1xetla_1_1subgroup_1_1mem__payload__t_3_01dtype___00_01tile__desc___00_01msg__type_1f0a2e0555f50e1106c25d511b2ef330c.html" target="_self">mem_payload_t&lt; dtype_, tile_desc_, msg_type::block_1d, mem_layout::row_major, mem_space::local, gpu_arch::Xe &gt;</a></td><td class="desc">Is to describe the shared local memory surface for block-1d load/store </td></tr>
<tr id="row_0_0_2_23_" class="odd" style="display:none;"><td class="entry"><span style="width:64px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="structgpu_1_1xetla_1_1subgroup_1_1mem__payload__t_3_01dtype___00_01tile__desc___00_01msg__type_18465855538f8a6320758be5c96a1b436.html" target="_self">mem_payload_t&lt; dtype_, tile_desc_, msg_type::block_2d, mem_layout_, mem_space::global, gpu_arch::Xe &gt;</a></td><td class="desc">Is to describe the global memory surface for block-2d load/store for each block in one tile, a payload message is prepared here </td></tr>
<tr id="row_0_0_2_24_" class="odd" style="display:none;"><td class="entry"><span style="width:64px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="structgpu_1_1xetla_1_1subgroup_1_1mem__payload__t_3_01dtype___00_01tile__desc___00_01msg__type_1a7116e3500e7d436cd40eb16a8981457.html" target="_self">mem_payload_t&lt; dtype_, tile_desc_, msg_type::scatter, mem_layout::row_major, mem_space::local, gpu_arch::Xe &gt;</a></td><td class="desc">Is to describe the shared local memory surface for scatter load/store </td></tr>
<tr id="row_0_0_2_25_" class="odd" style="display:none;"><td class="entry"><span style="width:64px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="structgpu_1_1xetla_1_1subgroup_1_1mem__payload__t_3_01dtype___00_01tile__desc__t_3_01tile__size_12caaae346d41f6005357bdd14a3a96e.html" target="_self">mem_payload_t&lt; dtype_, tile_desc_t&lt; tile_size_x_, tile_size_y_, block_size_x_, block_size_y_, reg_layout::vnni_tiled_col_major &gt;, msg_type::scatter, mem_layout::row_major, mem_space::local, gpu_arch::Xe &gt;</a></td><td class="desc">Is to describe the shared local memory surface for scattering store </td></tr>
<tr id="row_0_0_2_26_" class="odd" style="display:none;"><td class="entry"><span style="width:64px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="structgpu_1_1xetla_1_1subgroup_1_1msg__type__query.html" target="_self">msg_type_query</a></td><td class="desc"></td></tr>
<tr id="row_0_0_2_27_" class="odd" style="display:none;"><td class="entry"><span style="width:48px;display:inline-block;">&#160;</span><span id="arr_0_0_2_27_" class="arrow" onclick="toggleFolder('0_0_2_27_')">&#9658;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="structgpu_1_1xetla_1_1subgroup_1_1none__op__t.html" target="_self">none_op_t</a></td><td class="desc">Is none op functor, for placeholder purpose </td></tr>
<tr id="row_0_0_2_27_0_" class="odd" style="display:none;"><td class="entry"><span style="width:80px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="structgpu_1_1xetla_1_1subgroup_1_1none__op__t_1_1arguments__t.html" target="_self">arguments_t</a></td><td class="desc"></td></tr>
<tr id="row_0_0_2_28_" class="odd" style="display:none;"><td class="entry"><span style="width:48px;display:inline-block;">&#160;</span><span id="arr_0_0_2_28_" class="arrow" onclick="toggleFolder('0_0_2_28_')">&#9658;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="structgpu_1_1xetla_1_1subgroup_1_1polynomial__op__t.html" target="_self">polynomial_op_t</a></td><td class="desc"></td></tr>
<tr id="row_0_0_2_28_0_" class="odd" style="display:none;"><td class="entry"><span style="width:80px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="structgpu_1_1xetla_1_1subgroup_1_1polynomial__op__t_1_1arguments__t.html" target="_self">arguments_t</a></td><td class="desc"></td></tr>
<tr id="row_0_0_2_29_" class="odd" style="display:none;"><td class="entry"><span style="width:64px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="structgpu_1_1xetla_1_1subgroup_1_1prefetch__payload__t.html" target="_self">prefetch_payload_t</a></td><td class="desc">Is to illustrate the memory information to prefetch data to cache </td></tr>
<tr id="row_0_0_2_30_" class="odd" style="display:none;"><td class="entry"><span style="width:64px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="structgpu_1_1xetla_1_1subgroup_1_1prefetch__payload__t_3_01dtype___00_01tile__desc___00_01mem__l07cbb4a3da2d2f362ea2b0be0bf263d1.html" target="_self">prefetch_payload_t&lt; dtype_, tile_desc_, mem_layout_, mem_space::local, cooperative_num_, gpu_arch::Xe &gt;</a></td><td class="desc">Is to describe the memory infomation to prefetch data to cache data located in shared local memory, nothing will do </td></tr>
<tr id="row_0_0_2_31_" class="odd" style="display:none;"><td class="entry"><span style="width:64px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="structgpu_1_1xetla_1_1subgroup_1_1prefetch__payload__t_3_01dtype___00_01tile__desc__t_3_01tile__06c116c495cc183ecda05a11c0297a5c.html" target="_self">prefetch_payload_t&lt; dtype_, tile_desc_t&lt; tile_size_x_, 1, block_size_x_, 1, reg_layout_ &gt;, mem_layout_, mem_space::global, cooperative_num_, gpu_arch::Xe &gt;</a></td><td class="desc">Is to describe the memory memory to prefetch data to cache data in global memory will be prefetched into 1d tile </td></tr>
<tr id="row_0_0_2_32_" class="odd" style="display:none;"><td class="entry"><span style="width:64px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="structgpu_1_1xetla_1_1subgroup_1_1prefetch__payload__t_3_01dtype___00_01tile__desc__t_3_01tile__eae11e2a5dc03b57aba8e7fbf8cb8116.html" target="_self">prefetch_payload_t&lt; dtype_, tile_desc_t&lt; tile_size_x_, tile_size_y_, block_size_x_, block_size_y_, reg_layout_ &gt;, mem_layout_, mem_space::global, cooperative_num_, gpu_arch::Xe &gt;</a></td><td class="desc">Is to describe the global memory surface to prefetch data to cache data in global memory will be prefetched into 2d tile </td></tr>
<tr id="row_0_0_2_33_" class="odd" style="display:none;"><td class="entry"><span style="width:64px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="structgpu_1_1xetla_1_1subgroup_1_1quant__op__t.html" target="_self">quant_op_t</a></td><td class="desc">Is the quantization op functor </td></tr>
<tr id="row_0_0_2_34_" class="odd" style="display:none;"><td class="entry"><span style="width:48px;display:inline-block;">&#160;</span><span id="arr_0_0_2_34_" class="arrow" onclick="toggleFolder('0_0_2_34_')">&#9658;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="structgpu_1_1xetla_1_1subgroup_1_1quant__op__t_3_01dtype__offset__scale___00_01gpu__arch_1_1Xe_01_4.html" target="_self">quant_op_t&lt; dtype_offset_scale_, gpu_arch::Xe &gt;</a></td><td class="desc">Is the quantization op functor, specialized for Xe architecture </td></tr>
<tr id="row_0_0_2_34_0_" class="odd" style="display:none;"><td class="entry"><span style="width:80px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="structgpu_1_1xetla_1_1subgroup_1_1quant__op__t_3_01dtype__offset__scale___00_01gpu__arch_1_1Xe_01_4_1_1arguments__t.html" target="_self">arguments_t</a></td><td class="desc"></td></tr>
<tr id="row_0_0_2_35_" class="odd" style="display:none;"><td class="entry"><span style="width:48px;display:inline-block;">&#160;</span><span id="arr_0_0_2_35_" class="arrow" onclick="toggleFolder('0_0_2_35_')">&#9658;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="structgpu_1_1xetla_1_1subgroup_1_1relu__op__t.html" target="_self">relu_op_t</a></td><td class="desc">Is the element-wise relu op functor </td></tr>
<tr id="row_0_0_2_35_0_" class="odd" style="display:none;"><td class="entry"><span style="width:80px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="structgpu_1_1xetla_1_1subgroup_1_1relu__op__t_1_1arguments__t.html" target="_self">arguments_t</a></td><td class="desc"></td></tr>
<tr id="row_0_0_2_36_" class="odd" style="display:none;"><td class="entry"><span style="width:64px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="structgpu_1_1xetla_1_1subgroup_1_1rng__dropout__op__t.html" target="_self">rng_dropout_op_t</a></td><td class="desc">Is the random number generator and dropout op functor </td></tr>
<tr id="row_0_0_2_37_" class="odd" style="display:none;"><td class="entry"><span style="width:48px;display:inline-block;">&#160;</span><span id="arr_0_0_2_37_" class="arrow" onclick="toggleFolder('0_0_2_37_')">&#9658;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="structgpu_1_1xetla_1_1subgroup_1_1rng__dropout__op__t_3_01dtype__mask___00_01gpu__arch_1_1Xe_01_4.html" target="_self">rng_dropout_op_t&lt; dtype_mask_, gpu_arch::Xe &gt;</a></td><td class="desc">Is the random number generator and dropout op functor, specialized for Xe architecture </td></tr>
<tr id="row_0_0_2_37_0_" class="odd" style="display:none;"><td class="entry"><span style="width:80px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="structgpu_1_1xetla_1_1subgroup_1_1rng__dropout__op__t_3_01dtype__mask___00_01gpu__arch_1_1Xe_01_4_1_1arguments__t.html" target="_self">arguments_t</a></td><td class="desc"></td></tr>
<tr id="row_0_0_2_38_" class="odd" style="display:none;"><td class="entry"><span style="width:64px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="structgpu_1_1xetla_1_1subgroup_1_1scalar__mul__op__t.html" target="_self">scalar_mul_op_t</a></td><td class="desc">Is the scalar_multiply op functor </td></tr>
<tr id="row_0_0_2_39_" class="odd" style="display:none;"><td class="entry"><span style="width:48px;display:inline-block;">&#160;</span><span id="arr_0_0_2_39_" class="arrow" onclick="toggleFolder('0_0_2_39_')">&#9658;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="structgpu_1_1xetla_1_1subgroup_1_1scalar__mul__op__t_3_01dtype__in___00_01gpu__arch_1_1Xe_01_4.html" target="_self">scalar_mul_op_t&lt; dtype_in_, gpu_arch::Xe &gt;</a></td><td class="desc">Is the scalar_multiply op functor, specialized for Xe architecture </td></tr>
<tr id="row_0_0_2_39_0_" class="odd" style="display:none;"><td class="entry"><span style="width:80px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="structgpu_1_1xetla_1_1subgroup_1_1scalar__mul__op__t_3_01dtype__in___00_01gpu__arch_1_1Xe_01_4_1_1arguments__t.html" target="_self">arguments_t</a></td><td class="desc"></td></tr>
<tr id="row_0_0_2_40_" class="odd" style="display:none;"><td class="entry"><span style="width:64px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="structgpu_1_1xetla_1_1subgroup_1_1tile__desc__t.html" target="_self">tile_desc_t</a></td><td class="desc">Is to illustrate the tile information about a sub matrix </td></tr>
<tr id="row_0_0_2_41_" class="odd" style="display:none;"><td class="entry"><span style="width:64px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="structgpu_1_1xetla_1_1subgroup_1_1tile__div.html" target="_self">tile_div</a></td><td class="desc"></td></tr>
<tr id="row_0_0_2_42_" class="odd" style="display:none;"><td class="entry"><span style="width:64px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="structgpu_1_1xetla_1_1subgroup_1_1tile__minus.html" target="_self">tile_minus</a></td><td class="desc"></td></tr>
<tr id="row_0_0_2_43_" class="odd" style="display:none;"><td class="entry"><span style="width:64px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="structgpu_1_1xetla_1_1subgroup_1_1tile__mma__t.html" target="_self">tile_mma_t</a></td><td class="desc">Is the xetla tile mma operation definition API </td></tr>
<tr id="row_0_0_2_44_" class="odd" style="display:none;"><td class="entry"><span style="width:64px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="structgpu_1_1xetla_1_1subgroup_1_1tile__mma__t_3_01matA__t___00_01matB__t___00_01matAcc__src__t_5e326f93053a5dc419a1202cd6d31c87.html" target="_self">tile_mma_t&lt; matA_t_, matB_t_, matAcc_src_t_, matAcc_dst_t_, mma_engine::fpu, gpu_arch::Xe &gt;</a></td><td class="desc">Is the tile mma operation functor, specialized for Xe and fpu engine </td></tr>
<tr id="row_0_0_2_45_" class="odd" style="display:none;"><td class="entry"><span style="width:64px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="structgpu_1_1xetla_1_1subgroup_1_1tile__mma__t_3_01matA__t___00_01matB__t___00_01matAcc__src__t_7f67d172949e9727b2f7953429f66a95.html" target="_self">tile_mma_t&lt; matA_t_, matB_t_, matAcc_src_t_, matAcc_dst_t_, mma_engine::xmx, gpu_arch::Xe &gt;</a></td><td class="desc">Is the tile mma operation functor, specialized for Xe and matrix engine </td></tr>
<tr id="row_0_0_2_46_" class="odd" style="display:none;"><td class="entry"><span style="width:64px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="structgpu_1_1xetla_1_1subgroup_1_1tile__op__arg__helper__t.html" target="_self">tile_op_arg_helper_t</a></td><td class="desc"></td></tr>
<tr id="row_0_0_2_47_" class="odd" style="display:none;"><td class="entry"><span style="width:64px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="structgpu_1_1xetla_1_1subgroup_1_1tile__t.html" target="_self">tile_t</a></td><td class="desc">Is a struct contains some register file </td></tr>
<tr id="row_0_0_3_" class="odd"><td class="entry"><span style="width:48px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="structgpu_1_1xetla_1_1arch__attr__t.html" target="_self">arch_attr_t</a></td><td class="desc"></td></tr>
<tr id="row_0_0_4_" class="even"><td class="entry"><span style="width:48px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="structgpu_1_1xetla_1_1bf16.html" target="_self">bf16</a></td><td class="desc">Xetla <a class="el" href="structgpu_1_1xetla_1_1bf16.html" title="xetla bf16 data type.">bf16</a> data type </td></tr>
<tr id="row_0_0_5_" class="odd"><td class="entry"><span style="width:48px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="structgpu_1_1xetla_1_1dropout__fwd__t.html" target="_self">dropout_fwd_t</a></td><td class="desc"></td></tr>
<tr id="row_0_0_6_" class="even"><td class="entry"><span style="width:48px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="structgpu_1_1xetla_1_1get__uint__type.html" target="_self">get_uint_type</a></td><td class="desc">Get the unit representation based on Size </td></tr>
<tr id="row_0_0_7_" class="odd"><td class="entry"><span style="width:48px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="structgpu_1_1xetla_1_1is__host__callable.html" target="_self">is_host_callable</a></td><td class="desc"></td></tr>
<tr id="row_0_0_8_" class="even"><td class="entry"><span style="width:48px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="structgpu_1_1xetla_1_1is__host__callable_3_01T_00_01std_1_1enable__if__t_3_01T_1_1host__callable_0a_0atrue_01_4_01_4.html" target="_self">is_host_callable&lt; T, std::enable_if_t&lt; T::host_callable==true &gt; &gt;</a></td><td class="desc"></td></tr>
<tr id="row_0_0_9_" class="odd"><td class="entry"><span style="width:48px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="structgpu_1_1xetla_1_1is__internal__type.html" target="_self">is_internal_type</a></td><td class="desc">Used to check if the type is xetla internal data type </td></tr>
<tr id="row_0_0_10_" class="even"><td class="entry"><span style="width:48px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="structgpu_1_1xetla_1_1load__store__attr__t.html" target="_self">load_store_attr_t</a></td><td class="desc"></td></tr>
<tr id="row_0_0_11_" class="odd"><td class="entry"><span style="width:48px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="structgpu_1_1xetla_1_1load__store__attr__t_3_01gpu__arch_1_1Xe_01_4.html" target="_self">load_store_attr_t&lt; gpu_arch::Xe &gt;</a></td><td class="desc"></td></tr>
<tr id="row_0_0_12_" class="even"><td class="entry"><span style="width:48px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="structgpu_1_1xetla_1_1mem__base__t.html" target="_self">mem_base_t</a></td><td class="desc"></td></tr>
<tr id="row_0_0_13_" class="odd"><td class="entry"><span style="width:48px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="structgpu_1_1xetla_1_1mem__base__t_3_01dtype___00_01mem__space_1_1global_01_4.html" target="_self">mem_base_t&lt; dtype_, mem_space::global &gt;</a></td><td class="desc"></td></tr>
<tr id="row_0_0_14_" class="even"><td class="entry"><span style="width:48px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="structgpu_1_1xetla_1_1mem__base__t_3_01dtype___00_01mem__space_1_1local_01_4.html" target="_self">mem_base_t&lt; dtype_, mem_space::local &gt;</a></td><td class="desc"></td></tr>
<tr id="row_0_0_15_" class="odd"><td class="entry"><span style="width:48px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="structgpu_1_1xetla_1_1mem__coord__t.html" target="_self">mem_coord_t</a></td><td class="desc"></td></tr>
<tr id="row_0_0_16_" class="even"><td class="entry"><span style="width:48px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="structgpu_1_1xetla_1_1mem__coord__t_3_012_01_4.html" target="_self">mem_coord_t&lt; 2 &gt;</a></td><td class="desc"></td></tr>
<tr id="row_0_0_17_" class="odd"><td class="entry"><span style="width:48px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="structgpu_1_1xetla_1_1mem__desc__t.html" target="_self">mem_desc_t</a></td><td class="desc"></td></tr>
<tr id="row_0_0_18_" class="even"><td class="entry"><span style="width:48px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="structgpu_1_1xetla_1_1mem__desc__t_3_01dtype___00_01layout___00_01space___00_012_01_4.html" target="_self">mem_desc_t&lt; dtype_, layout_, space_, 2 &gt;</a></td><td class="desc"></td></tr>
<tr id="row_0_0_19_" class="odd"><td class="entry"><span style="width:48px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="structgpu_1_1xetla_1_1mem__shape__t.html" target="_self">mem_shape_t</a></td><td class="desc"></td></tr>
<tr id="row_0_0_20_" class="even"><td class="entry"><span style="width:48px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="structgpu_1_1xetla_1_1mem__shape__t_3_012_01_4.html" target="_self">mem_shape_t&lt; 2 &gt;</a></td><td class="desc"></td></tr>
<tr id="row_0_0_21_" class="odd"><td class="entry"><span style="width:48px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="structgpu_1_1xetla_1_1mma__attr__t.html" target="_self">mma_attr_t</a></td><td class="desc"></td></tr>
<tr id="row_0_0_22_" class="even"><td class="entry"><span style="width:48px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="structgpu_1_1xetla_1_1mma__attr__t_3_01gpu__arch_1_1Xe_01_4.html" target="_self">mma_attr_t&lt; gpu_arch::Xe &gt;</a></td><td class="desc"></td></tr>
<tr id="row_0_0_23_" class="odd"><td class="entry"><span style="width:48px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="structgpu_1_1xetla_1_1native__type.html" target="_self">native_type</a></td><td class="desc">Set the native data type of T </td></tr>
<tr id="row_0_0_24_" class="even"><td class="entry"><span style="width:48px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="structgpu_1_1xetla_1_1native__type_3_01bf16_01_4.html" target="_self">native_type&lt; bf16 &gt;</a></td><td class="desc">Set bfloat16 as the native data type of <a class="el" href="structgpu_1_1xetla_1_1bf16.html" title="xetla bf16 data type.">bf16</a> </td></tr>
<tr id="row_0_0_25_" class="odd"><td class="entry"><span style="width:48px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="structgpu_1_1xetla_1_1native__type_3_01tf32_01_4.html" target="_self">native_type&lt; tf32 &gt;</a></td><td class="desc">Set uint32_t as the native data type of <a class="el" href="structgpu_1_1xetla_1_1tf32.html" title="xetla tf32 data type.">tf32</a> </td></tr>
<tr id="row_0_0_26_" class="even"><td class="entry"><span style="width:48px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="structgpu_1_1xetla_1_1register__attr__t.html" target="_self">register_attr_t</a></td><td class="desc"></td></tr>
<tr id="row_0_0_27_" class="odd"><td class="entry"><span style="width:48px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="structgpu_1_1xetla_1_1register__attr__t_3_01gpu__arch_1_1Xe_00_01grf__mode_1_1double__grf_01_4.html" target="_self">register_attr_t&lt; gpu_arch::Xe, grf_mode::double_grf &gt;</a></td><td class="desc"></td></tr>
<tr id="row_0_0_28_" class="even"><td class="entry"><span style="width:48px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="structgpu_1_1xetla_1_1result__overwrite.html" target="_self">result_overwrite</a></td><td class="desc">Result will be overwritten </td></tr>
<tr id="row_0_0_29_" class="odd"><td class="entry"><span style="width:48px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="structgpu_1_1xetla_1_1result__reduce__sum.html" target="_self">result_reduce_sum</a></td><td class="desc">Result will be summed up with old data in memory </td></tr>
<tr id="row_0_0_30_" class="even"><td class="entry"><span style="width:48px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="structgpu_1_1xetla_1_1tf32.html" target="_self">tf32</a></td><td class="desc">Xetla <a class="el" href="structgpu_1_1xetla_1_1tf32.html" title="xetla tf32 data type.">tf32</a> data type </td></tr>
<tr id="row_0_0_31_" class="odd"><td class="entry"><span style="width:48px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="structgpu_1_1xetla_1_1uint__type.html" target="_self">uint_type</a></td><td class="desc">Get the unit representation of type T </td></tr>
<tr id="row_0_0_32_" class="even"><td class="entry"><span style="width:48px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="structgpu_1_1xetla_1_1work__group__t.html" target="_self">work_group_t</a></td><td class="desc">Define a workgroup scope for a specific problem shape </td></tr>
<tr id="row_0_0_33_" class="odd"><td class="entry"><span style="width:48px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="classgpu_1_1xetla_1_1xetla__exec__item.html" target="_self">xetla_exec_item</a></td><td class="desc">The item struct to explict identify the group / local id information </td></tr>
<tr id="row_0_0_34_" class="even"><td class="entry"><span style="width:48px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="structgpu_1_1xetla_1_1xetla__nbarrier__t.html" target="_self">xetla_nbarrier_t</a></td><td class="desc">Xetla nbarrier definition API </td></tr>
<tr id="row_0_0_35_" class="odd"><td class="entry"><span style="width:48px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="structgpu_1_1xetla_1_1xetla__rand__t.html" target="_self">xetla_rand_t</a></td><td class="desc"></td></tr>
<tr id="row_0_0_36_" class="even"><td class="entry"><span style="width:48px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="classgpu_1_1xetla_1_1xettp__saturation__off__tag.html" target="_self">xettp_saturation_off_tag</a></td><td class="desc"></td></tr>
<tr id="row_0_0_37_" class="odd"><td class="entry"><span style="width:48px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="classgpu_1_1xetla_1_1xettp__saturation__on__tag.html" target="_self">xettp_saturation_on_tag</a></td><td class="desc"></td></tr>
<tr id="row_1_" class="even"><td class="entry"><span style="width:0px;display:inline-block;">&#160;</span><span id="arr_1_" class="arrow" onclick="toggleFolder('1_')">&#9660;</span><span class="icona"><span class="icon">N</span></span><a class="el" href="namespacesycl.html" target="_self">sycl</a></td><td class="desc"></td></tr>
<tr id="row_1_0_" class="odd"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="structsycl_1_1is__device__copyable_3_01T_00_01std_1_1enable__if__t_3_01gpu_1_1xetla_1_1is__host_cf13af5cc49ff51c2d56dc67f2e77257.html" target="_self">is_device_copyable&lt; T, std::enable_if_t&lt; gpu::xetla::is_host_callable&lt; T &gt;::value &gt; &gt;</a></td><td class="desc"></td></tr>
<tr id="row_2_" class="even"><td class="entry"><span style="width:16px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="structfused__config__t.html" target="_self">fused_config_t</a></td><td class="desc"></td></tr>
<tr id="row_3_" class="odd"><td class="entry"><span style="width:16px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="classgru__config__t.html" target="_self">gru_config_t</a></td><td class="desc"></td></tr>
<tr id="row_4_" class="even"><td class="entry"><span style="width:16px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="structgru__layer.html" target="_self">gru_layer</a></td><td class="desc"></td></tr>
<tr id="row_5_" class="odd"><td class="entry"><span style="width:16px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="structkernel__xcoder__gru__fusion.html" target="_self">kernel_xcoder_gru_fusion</a></td><td class="desc"></td></tr>
<tr id="row_6_" class="even"><td class="entry"><span style="width:0px;display:inline-block;">&#160;</span><span id="arr_6_" class="arrow" onclick="toggleFolder('6_')">&#9660;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="structxetla__softmax__fwd__t.html" target="_self">xetla_softmax_fwd_t</a></td><td class="desc"></td></tr>
<tr id="row_6_0_" class="odd"><td class="entry"><span style="width:32px;display:inline-block;">&#160;</span><span class="icona"><span class="icon">C</span></span><a class="el" href="structxetla__softmax__fwd__t_1_1arguments__t.html" target="_self">arguments_t</a></td><td class="desc"></td></tr>
</table>
</div><!-- directory -->
</div><!-- contents -->
</div><!-- doc-content -->
<!-- start footer part -->
<div id="nav-path" class="navpath"><!-- id is needed for treeview function! -->
  <ul>
    <li class="footer">Generated by <a href="https://www.doxygen.org/index.html"><img class="footer" src="doxygen.svg" width="104" height="31" alt="doxygen"/></a> 1.9.5 </li>
  </ul>
</div>
</body>
</html>
