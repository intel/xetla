<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "https://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" lang="en-US">
<head>
<meta http-equiv="Content-Type" content="text/xhtml;charset=UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=11"/>
<meta name="generator" content="Doxygen 1.9.5"/>
<meta name="viewport" content="width=device-width, initial-scale=1"/>
<title>XeTLA: Tensor load store API</title>
<link href="tabs.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="jquery.js"></script>
<script type="text/javascript" src="dynsections.js"></script>
<link href="navtree.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="resize.js"></script>
<script type="text/javascript" src="navtreedata.js"></script>
<script type="text/javascript" src="navtree.js"></script>
<link href="search/search.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="search/searchdata.js"></script>
<script type="text/javascript" src="search/search.js"></script>
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:d3d9a9a6595521f9666a5e94cc830dab83b65699&amp;dn=expat.txt MIT */
  $(document).ready(function() { init_search(); });
/* @license-end */
</script>
<script type="text/x-mathjax-config">
MathJax.Hub.Config({
  extensions: ["tex2jax.js"],
  jax: ["input/TeX","output/HTML-CSS"],
});
</script>
<script type="text/javascript" async="async" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js"></script>
<link href="doxygen.css" rel="stylesheet" type="text/css" />
</head>
<body>
<div id="top"><!-- do not remove this div, it is closed by doxygen! -->
<div id="titlearea">
<table cellspacing="0" cellpadding="0">
 <tbody>
 <tr id="projectrow">
  <td id="projectalign">
   <div id="projectname">XeTLA<span id="projectnumber">&#160;v0.3.2</span>
   </div>
   <div id="projectbrief">IntelÂ® Xe Templates for Linear Algebra - API Definition Document</div>
  </td>
    <td>        <div id="MSearchBox" class="MSearchBoxInactive">
        <span class="left">
          <span id="MSearchSelect"                onmouseover="return searchBox.OnSearchSelectShow()"                onmouseout="return searchBox.OnSearchSelectHide()">&#160;</span>
          <input type="text" id="MSearchField" value="" placeholder="Search" accesskey="S"
               onfocus="searchBox.OnSearchFieldFocus(true)" 
               onblur="searchBox.OnSearchFieldFocus(false)" 
               onkeyup="searchBox.OnSearchFieldChange(event)"/>
          </span><span class="right">
            <a id="MSearchClose" href="javascript:searchBox.CloseResultsWindow()"><img id="MSearchCloseImg" border="0" src="search/close.svg" alt=""/></a>
          </span>
        </div>
</td>
 </tr>
 </tbody>
</table>
</div>
<!-- end header part -->
<!-- Generated by Doxygen 1.9.5 -->
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:d3d9a9a6595521f9666a5e94cc830dab83b65699&amp;dn=expat.txt MIT */
var searchBox = new SearchBox("searchBox", "search/",'.html');
/* @license-end */
</script>
</div><!-- top -->
<div id="side-nav" class="ui-resizable side-nav-resizable">
  <div id="nav-tree">
    <div id="nav-tree-contents">
      <div id="nav-sync" class="sync"></div>
    </div>
  </div>
  <div id="splitbar" style="-moz-user-select:none;" 
       class="ui-resizable-handle">
  </div>
</div>
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:d3d9a9a6595521f9666a5e94cc830dab83b65699&amp;dn=expat.txt MIT */
$(document).ready(function(){initNavTree('group__xetla__util__tensor__load__store.html',''); initResizable(); });
/* @license-end */
</script>
<div id="doc-content">
<!-- window showing the filter options -->
<div id="MSearchSelectWindow"
     onmouseover="return searchBox.OnSearchSelectShow()"
     onmouseout="return searchBox.OnSearchSelectHide()"
     onkeydown="return searchBox.OnSearchSelectKey(event)">
</div>

<!-- iframe showing the search results (closed by default) -->
<div id="MSearchResultsWindow">
<div id="MSearchResults">
<div class="SRPage">
<div id="SRIndex">
<div id="SRResults"></div>
<div class="SRStatus" id="Loading">Loading...</div>
<div class="SRStatus" id="Searching">Searching...</div>
<div class="SRStatus" id="NoMatches">No Matches</div>
</div>
</div>
</div>
</div>

<div class="header">
  <div class="summary">
<a href="#define-members">Macros</a> &#124;
<a href="#typedef-members">Typedefs</a> &#124;
<a href="#func-members">Functions</a>  </div>
  <div class="headertitle"><div class="title">Tensor load store API<div class="ingroups"><a class="el" href="group__xetla__util.html">XeTLA Utility</a></div></div></div>
</div><!--header-->
<div class="contents">

<p>Implements the tensor load store functionality using raw send instructions.  
<a href="#details">More...</a></p>
<div class="dynheader">
Collaboration diagram for Tensor load store API:</div>
<div class="dyncontent">
<div class="center"><img src="group__xetla__util__tensor__load__store.png" border="0" usemap="#agroup____xetla____util____tensor____load____store" alt=""/></div>
<map name="agroup____xetla____util____tensor____load____store" id="agroup____xetla____util____tensor____load____store">
<area shape="rect" href="group__xetla__util.html" title="This is low level API wrapper for utility functions." alt="" coords="5,5,101,31"/>
<area shape="rect" title="Implements the tensor load store functionality using raw send instructions." alt="" coords="149,5,296,31"/>
</map>
</div>
<table class="memberdecls">
<tr class="heading"><td colspan="2"><h2 class="groupheader"><a id="define-members" name="define-members"></a>
Macros</h2></td></tr>
<tr class="memitem:gab54f16379f1e25babd42baece080b167"><td class="memItemLeft" align="right" valign="top">#define&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="group__xetla__util__tensor__load__store.html#gab54f16379f1e25babd42baece080b167">xetla_tdescriptor_ref</a>&#160;&#160;&#160;xetla_vector_ref&lt;uint32_t, 16&gt; <a class="el" href="group__xetla__core__base__types.html#ga126a6fcae520c421efd2419512e9bf70">__REF__</a></td></tr>
<tr class="memdesc:gab54f16379f1e25babd42baece080b167"><td class="mdescLeft">&#160;</td><td class="mdescRight">Alias to xetla_vector&lt;uint32_t, 16&gt; reference.  <a href="group__xetla__util__tensor__load__store.html#gab54f16379f1e25babd42baece080b167">More...</a><br /></td></tr>
<tr class="separator:gab54f16379f1e25babd42baece080b167"><td class="memSeparator" colspan="2">&#160;</td></tr>
</table><table class="memberdecls">
<tr class="heading"><td colspan="2"><h2 class="groupheader"><a id="typedef-members" name="typedef-members"></a>
Typedefs</h2></td></tr>
<tr class="memitem:ga42f510141eb50c17c2b0d1aa1edaf40d"><td class="memItemLeft" align="right" valign="top">using&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="group__xetla__util__tensor__load__store.html#ga42f510141eb50c17c2b0d1aa1edaf40d">gpu::xetla::xetla_tdescriptor</a> = <a class="el" href="group__xetla__core__base__types.html#ga8cf5d016d24c8870706e20c376287e04">xetla_vector</a>&lt; uint32_t, 16 &gt;</td></tr>
<tr class="memdesc:ga42f510141eb50c17c2b0d1aa1edaf40d"><td class="mdescLeft">&#160;</td><td class="mdescRight">Description of nd tensor descriptor for load and store.  <a href="group__xetla__util__tensor__load__store.html#ga42f510141eb50c17c2b0d1aa1edaf40d">More...</a><br /></td></tr>
<tr class="separator:ga42f510141eb50c17c2b0d1aa1edaf40d"><td class="memSeparator" colspan="2">&#160;</td></tr>
</table><table class="memberdecls">
<tr class="heading"><td colspan="2"><h2 class="groupheader"><a id="func-members" name="func-members"></a>
Functions</h2></td></tr>
<tr class="memitem:ga39afcb7e7028fa94d45b3cedc3e1a2b3"><td class="memTemplParams" colspan="2">template&lt;typename Ty , uint8_t block_width = 1, uint8_t block_height = 1, uint8_t array_len = 1&gt; </td></tr>
<tr class="memitem:ga39afcb7e7028fa94d45b3cedc3e1a2b3"><td class="memTemplItemLeft" align="right" valign="top"><a class="el" href="common_2core_2common_8hpp.html#a9ed53999886ec13b86a4fe2e0fc16765">__XETLA_API</a> void&#160;</td><td class="memTemplItemRight" valign="bottom"><a class="el" href="group__xetla__util__tensor__load__store.html#ga39afcb7e7028fa94d45b3cedc3e1a2b3">gpu::xetla::xetla_fill_tdesc</a> (xetla_vector_ref&lt; uint32_t, 16 &gt; <a class="el" href="group__xetla__core__base__types.html#ga126a6fcae520c421efd2419512e9bf70">__REF__</a> tdesc, Ty *p, int tensor_width, int tensor_height, int tensor_pitch, int offset_x, int offset_y)</td></tr>
<tr class="memdesc:ga39afcb7e7028fa94d45b3cedc3e1a2b3"><td class="mdescLeft">&#160;</td><td class="mdescRight">Tensor descriptor construction(global memory version).  <a href="group__xetla__util__tensor__load__store.html#ga39afcb7e7028fa94d45b3cedc3e1a2b3">More...</a><br /></td></tr>
<tr class="separator:ga39afcb7e7028fa94d45b3cedc3e1a2b3"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ga9aae00877c6ebd577ab3afa3717af917"><td class="memTemplParams" colspan="2">template&lt;typename Ty &gt; </td></tr>
<tr class="memitem:ga9aae00877c6ebd577ab3afa3717af917"><td class="memTemplItemLeft" align="right" valign="top"><a class="el" href="common_2core_2common_8hpp.html#a9ed53999886ec13b86a4fe2e0fc16765">__XETLA_API</a> void&#160;</td><td class="memTemplItemRight" valign="bottom"><a class="el" href="group__xetla__util__tensor__load__store.html#ga9aae00877c6ebd577ab3afa3717af917">gpu::xetla::xetla_fill_tdesc</a> (xetla_vector_ref&lt; uint32_t, 16 &gt; <a class="el" href="group__xetla__core__base__types.html#ga126a6fcae520c421efd2419512e9bf70">__REF__</a> tdesc, uint32_t base_address, int tensor_width, int tensor_height, int tensor_pitch, int offset_x, int offset_y)</td></tr>
<tr class="memdesc:ga9aae00877c6ebd577ab3afa3717af917"><td class="mdescLeft">&#160;</td><td class="mdescRight">Tensor descriptor construction(local memory version).  <a href="group__xetla__util__tensor__load__store.html#ga9aae00877c6ebd577ab3afa3717af917">More...</a><br /></td></tr>
<tr class="separator:ga9aae00877c6ebd577ab3afa3717af917"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:gab7c1fda0870b32e289606ba2db79bb62"><td class="memTemplParams" colspan="2">template&lt;typename Ty , uint8_t block_width = 1, uint8_t block_height = 1, uint8_t array_len = 1&gt; </td></tr>
<tr class="memitem:gab7c1fda0870b32e289606ba2db79bb62"><td class="memTemplItemLeft" align="right" valign="top"><a class="el" href="common_2core_2common_8hpp.html#a9ed53999886ec13b86a4fe2e0fc16765">__XETLA_API</a> <a class="el" href="group__xetla__util__tensor__load__store.html#ga42f510141eb50c17c2b0d1aa1edaf40d">xetla_tdescriptor</a>&#160;</td><td class="memTemplItemRight" valign="bottom"><a class="el" href="group__xetla__util__tensor__load__store.html#gab7c1fda0870b32e289606ba2db79bb62">gpu::xetla::xetla_get_tdesc</a> (Ty *p, int tensor_width, int tensor_height, int tensor_pitch, int offset_x, int offset_y)</td></tr>
<tr class="memdesc:gab7c1fda0870b32e289606ba2db79bb62"><td class="mdescLeft">&#160;</td><td class="mdescRight">Generate a new tensor descriptor(global memory version).  <a href="group__xetla__util__tensor__load__store.html#gab7c1fda0870b32e289606ba2db79bb62">More...</a><br /></td></tr>
<tr class="separator:gab7c1fda0870b32e289606ba2db79bb62"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ga56fc07f5418c4adffe8739901f236849"><td class="memTemplParams" colspan="2">template&lt;typename Ty &gt; </td></tr>
<tr class="memitem:ga56fc07f5418c4adffe8739901f236849"><td class="memTemplItemLeft" align="right" valign="top"><a class="el" href="common_2core_2common_8hpp.html#a9ed53999886ec13b86a4fe2e0fc16765">__XETLA_API</a> <a class="el" href="group__xetla__util__tensor__load__store.html#ga42f510141eb50c17c2b0d1aa1edaf40d">xetla_tdescriptor</a>&#160;</td><td class="memTemplItemRight" valign="bottom"><a class="el" href="group__xetla__util__tensor__load__store.html#ga56fc07f5418c4adffe8739901f236849">gpu::xetla::xetla_get_tdesc</a> (uint32_t base_address, int tensor_width, int tensor_height, int tensor_pitch, int offset_x, int offset_y)</td></tr>
<tr class="memdesc:ga56fc07f5418c4adffe8739901f236849"><td class="mdescLeft">&#160;</td><td class="mdescRight">Generate a new tensor descriptor(local memory version).  <a href="group__xetla__util__tensor__load__store.html#ga56fc07f5418c4adffe8739901f236849">More...</a><br /></td></tr>
<tr class="separator:ga56fc07f5418c4adffe8739901f236849"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:gaa762b4f5a5a2b2ee9accee5b0af3e40c"><td class="memItemLeft" align="right" valign="top"><a class="el" href="common_2core_2common_8hpp.html#a9ed53999886ec13b86a4fe2e0fc16765">__XETLA_API</a> void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="group__xetla__util__tensor__load__store.html#gaa762b4f5a5a2b2ee9accee5b0af3e40c">gpu::xetla::xetla_update_tdesc_offsetx</a> (xetla_vector_ref&lt; uint32_t, 16 &gt; <a class="el" href="group__xetla__core__base__types.html#ga126a6fcae520c421efd2419512e9bf70">__REF__</a> tdesc, int32_t doffset_x)</td></tr>
<tr class="memdesc:gaa762b4f5a5a2b2ee9accee5b0af3e40c"><td class="mdescLeft">&#160;</td><td class="mdescRight">Update the x coordinate in the given tensor descriptor.  <a href="group__xetla__util__tensor__load__store.html#gaa762b4f5a5a2b2ee9accee5b0af3e40c">More...</a><br /></td></tr>
<tr class="separator:gaa762b4f5a5a2b2ee9accee5b0af3e40c"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:gae779bb3a3626f9c8e36dbc330e269c39"><td class="memItemLeft" align="right" valign="top"><a class="el" href="common_2core_2common_8hpp.html#a9ed53999886ec13b86a4fe2e0fc16765">__XETLA_API</a> void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="group__xetla__util__tensor__load__store.html#gae779bb3a3626f9c8e36dbc330e269c39">gpu::xetla::xetla_update_tdesc_offsety</a> (xetla_vector_ref&lt; uint32_t, 16 &gt; <a class="el" href="group__xetla__core__base__types.html#ga126a6fcae520c421efd2419512e9bf70">__REF__</a> tdesc, int32_t doffset_y)</td></tr>
<tr class="memdesc:gae779bb3a3626f9c8e36dbc330e269c39"><td class="mdescLeft">&#160;</td><td class="mdescRight">Update the y coordinate in the given tensor descriptor.  <a href="group__xetla__util__tensor__load__store.html#gae779bb3a3626f9c8e36dbc330e269c39">More...</a><br /></td></tr>
<tr class="separator:gae779bb3a3626f9c8e36dbc330e269c39"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:gaeecc58189c2cb085251223db2f4737da"><td class="memTemplParams" colspan="2">template&lt;typename Ty , uint32_t N, <a class="el" href="namespacegpu_1_1xetla.html#a23ee6c8b836eb63360633951d75d7e30">cache_hint</a> L1H = cache_hint::none, <a class="el" href="namespacegpu_1_1xetla.html#a23ee6c8b836eb63360633951d75d7e30">cache_hint</a> L3H = cache_hint::none, bool transpose = false, bool transform = false&gt; </td></tr>
<tr class="memitem:gaeecc58189c2cb085251223db2f4737da"><td class="memTemplItemLeft" align="right" valign="top"><a class="el" href="common_2core_2common_8hpp.html#a9ed53999886ec13b86a4fe2e0fc16765">__XETLA_API</a> <a class="el" href="group__xetla__core__base__types.html#ga8cf5d016d24c8870706e20c376287e04">xetla_vector</a>&lt; Ty, N &gt;&#160;</td><td class="memTemplItemRight" valign="bottom"><a class="el" href="group__xetla__util__tensor__load__store.html#gaeecc58189c2cb085251223db2f4737da">gpu::xetla::xetla_tload_global</a> (<a class="el" href="group__xetla__util__tensor__load__store.html#ga42f510141eb50c17c2b0d1aa1edaf40d">xetla_tdescriptor</a> tdesc)</td></tr>
<tr class="memdesc:gaeecc58189c2cb085251223db2f4737da"><td class="mdescLeft">&#160;</td><td class="mdescRight">Tensor load API.  <a href="group__xetla__util__tensor__load__store.html#gaeecc58189c2cb085251223db2f4737da">More...</a><br /></td></tr>
<tr class="separator:gaeecc58189c2cb085251223db2f4737da"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:gadeb20d3aecaea1a2fa1c64e99f7c0919"><td class="memTemplParams" colspan="2">template&lt;typename Ty , uint32_t N, <a class="el" href="namespacegpu_1_1xetla.html#a23ee6c8b836eb63360633951d75d7e30">cache_hint</a> L1H = cache_hint::none, <a class="el" href="namespacegpu_1_1xetla.html#a23ee6c8b836eb63360633951d75d7e30">cache_hint</a> L3H = cache_hint::none&gt; </td></tr>
<tr class="memitem:gadeb20d3aecaea1a2fa1c64e99f7c0919"><td class="memTemplItemLeft" align="right" valign="top"><a class="el" href="common_2core_2common_8hpp.html#a9ed53999886ec13b86a4fe2e0fc16765">__XETLA_API</a> void&#160;</td><td class="memTemplItemRight" valign="bottom"><a class="el" href="group__xetla__util__tensor__load__store.html#gadeb20d3aecaea1a2fa1c64e99f7c0919">gpu::xetla::xetla_tstore_global</a> (<a class="el" href="group__xetla__util__tensor__load__store.html#ga42f510141eb50c17c2b0d1aa1edaf40d">xetla_tdescriptor</a> tdesc, <a class="el" href="group__xetla__core__base__types.html#ga8cf5d016d24c8870706e20c376287e04">xetla_vector</a>&lt; Ty, N &gt; data)</td></tr>
<tr class="memdesc:gadeb20d3aecaea1a2fa1c64e99f7c0919"><td class="mdescLeft">&#160;</td><td class="mdescRight">Tensor store API.  <a href="group__xetla__util__tensor__load__store.html#gadeb20d3aecaea1a2fa1c64e99f7c0919">More...</a><br /></td></tr>
<tr class="separator:gadeb20d3aecaea1a2fa1c64e99f7c0919"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ga20cb0deb00796b1e7099082c08c3c68c"><td class="memTemplParams" colspan="2">template&lt;typename Ty , <a class="el" href="namespacegpu_1_1xetla.html#a23ee6c8b836eb63360633951d75d7e30">cache_hint</a> L1H = cache_hint::cached, <a class="el" href="namespacegpu_1_1xetla.html#a23ee6c8b836eb63360633951d75d7e30">cache_hint</a> L3H = cache_hint::cached&gt; </td></tr>
<tr class="memitem:ga20cb0deb00796b1e7099082c08c3c68c"><td class="memTemplItemLeft" align="right" valign="top"><a class="el" href="common_2core_2common_8hpp.html#a9ed53999886ec13b86a4fe2e0fc16765">__XETLA_API</a> void&#160;</td><td class="memTemplItemRight" valign="bottom"><a class="el" href="group__xetla__util__tensor__load__store.html#ga20cb0deb00796b1e7099082c08c3c68c">gpu::xetla::xetla_tprefetch_global</a> (<a class="el" href="group__xetla__util__tensor__load__store.html#ga42f510141eb50c17c2b0d1aa1edaf40d">xetla_tdescriptor</a> tdesc)</td></tr>
<tr class="memdesc:ga20cb0deb00796b1e7099082c08c3c68c"><td class="mdescLeft">&#160;</td><td class="mdescRight">Tensor prefetch API.  <a href="group__xetla__util__tensor__load__store.html#ga20cb0deb00796b1e7099082c08c3c68c">More...</a><br /></td></tr>
<tr class="separator:ga20cb0deb00796b1e7099082c08c3c68c"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ga8bd042e28e68f5e0bed3f378d57d4223"><td class="memTemplParams" colspan="2">template&lt;typename Ty , uint32_t N, <a class="el" href="namespacegpu_1_1xetla.html#a23ee6c8b836eb63360633951d75d7e30">cache_hint</a> L1H = cache_hint::none, <a class="el" href="namespacegpu_1_1xetla.html#a23ee6c8b836eb63360633951d75d7e30">cache_hint</a> L3H = cache_hint::none, <a class="el" href="namespacegpu_1_1xetla.html#a98afdf633baaa5ce76b93f0a2ffbba66">atomic_op</a> Op&gt; </td></tr>
<tr class="memitem:ga8bd042e28e68f5e0bed3f378d57d4223"><td class="memTemplItemLeft" align="right" valign="top"><a class="el" href="common_2core_2common_8hpp.html#a9ed53999886ec13b86a4fe2e0fc16765">__XETLA_API</a> void&#160;</td><td class="memTemplItemRight" valign="bottom"><a class="el" href="group__xetla__util__tensor__load__store.html#ga8bd042e28e68f5e0bed3f378d57d4223">gpu::xetla::xetla_tatomic_store_global</a> (<a class="el" href="group__xetla__core__base__types.html#ga8cf5d016d24c8870706e20c376287e04">xetla_vector</a>&lt; uint64_t, N &gt; address, <a class="el" href="group__xetla__core__base__types.html#ga8cf5d016d24c8870706e20c376287e04">xetla_vector</a>&lt; Ty, N &gt; data, <a class="el" href="group__xetla__core__base__types.html#gaf7f6ada235a6c3ab30aa12c97f5d7459">xetla_mask</a>&lt; N &gt; pred=1)</td></tr>
<tr class="memdesc:ga8bd042e28e68f5e0bed3f378d57d4223"><td class="mdescLeft">&#160;</td><td class="mdescRight">Tensor atomic store API.  <a href="group__xetla__util__tensor__load__store.html#ga8bd042e28e68f5e0bed3f378d57d4223">More...</a><br /></td></tr>
<tr class="separator:ga8bd042e28e68f5e0bed3f378d57d4223"><td class="memSeparator" colspan="2">&#160;</td></tr>
</table>
<a name="details" id="details"></a><h2 class="groupheader">Detailed Description</h2>
<p >Implements the tensor load store functionality using raw send instructions. </p>
<h2 class="groupheader">Macro Definition Documentation</h2>
<a id="gab54f16379f1e25babd42baece080b167" name="gab54f16379f1e25babd42baece080b167"></a>
<h2 class="memtitle"><span class="permalink"><a href="#gab54f16379f1e25babd42baece080b167">&#9670;&#160;</a></span>xetla_tdescriptor_ref</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">#define xetla_tdescriptor_ref&#160;&#160;&#160;xetla_vector_ref&lt;uint32_t, 16&gt; <a class="el" href="group__xetla__core__base__types.html#ga126a6fcae520c421efd2419512e9bf70">__REF__</a></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Alias to xetla_vector&lt;uint32_t, 16&gt; reference. </p>

</div>
</div>
<h2 class="groupheader">Typedef Documentation</h2>
<a id="ga42f510141eb50c17c2b0d1aa1edaf40d" name="ga42f510141eb50c17c2b0d1aa1edaf40d"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ga42f510141eb50c17c2b0d1aa1edaf40d">&#9670;&#160;</a></span>xetla_tdescriptor</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">using <a class="el" href="group__xetla__util__tensor__load__store.html#ga42f510141eb50c17c2b0d1aa1edaf40d">gpu::xetla::xetla_tdescriptor</a> = typedef <a class="el" href="group__xetla__core__base__types.html#ga8cf5d016d24c8870706e20c376287e04">xetla_vector</a>&lt;uint32_t, 16&gt;</td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Description of nd tensor descriptor for load and store. </p>
<p >Structure is defined in <a href="https://gfxspecs.intel.com/Predator/Home/Index/63986">here</a>. </p>

</div>
</div>
<h2 class="groupheader">Function Documentation</h2>
<a id="ga39afcb7e7028fa94d45b3cedc3e1a2b3" name="ga39afcb7e7028fa94d45b3cedc3e1a2b3"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ga39afcb7e7028fa94d45b3cedc3e1a2b3">&#9670;&#160;</a></span>xetla_fill_tdesc() <span class="overload">[1/2]</span></h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;typename Ty , uint8_t block_width = 1, uint8_t block_height = 1, uint8_t array_len = 1&gt; </div>
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="common_2core_2common_8hpp.html#a9ed53999886ec13b86a4fe2e0fc16765">__XETLA_API</a> void gpu::xetla::xetla_fill_tdesc </td>
          <td>(</td>
          <td class="paramtype">xetla_vector_ref&lt; uint32_t, 16 &gt; <a class="el" href="group__xetla__core__base__types.html#ga126a6fcae520c421efd2419512e9bf70">__REF__</a>&#160;</td>
          <td class="paramname"><em>tdesc</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">Ty *&#160;</td>
          <td class="paramname"><em>p</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int&#160;</td>
          <td class="paramname"><em>tensor_width</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int&#160;</td>
          <td class="paramname"><em>tensor_height</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int&#160;</td>
          <td class="paramname"><em>tensor_pitch</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int&#160;</td>
          <td class="paramname"><em>offset_x</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int&#160;</td>
          <td class="paramname"><em>offset_y</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Tensor descriptor construction(global memory version). </p>
<p >Constructs a tensor descriptor based on the given arguments, check <a href="https://gfxspecs.intel.com/Predator/Home/Index/63986">here</a> for more details. </p><dl class="tparams"><dt>Template Parameters</dt><dd>
  <table class="tparams">
    <tr><td class="paramname">Ty</td><td>is the data type per element. </td></tr>
    <tr><td class="paramname">block_width</td><td>is the width of the block to be loaded. </td></tr>
    <tr><td class="paramname">block_height</td><td>is the height of the block to be loaded. </td></tr>
    <tr><td class="paramname">array_len</td><td>is the array length of the block to be loaded. </td></tr>
  </table>
  </dd>
</dl>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">tdesc</td><td>[in|out] is the reference of tensor descriptor. </td></tr>
    <tr><td class="paramname">p</td><td>[in] is the base address pointer of the tensor. </td></tr>
    <tr><td class="paramname">tensor_width</td><td>[in] is the width of the tensor. </td></tr>
    <tr><td class="paramname">tensor_height</td><td>[in] is the height of the tensor. </td></tr>
    <tr><td class="paramname">tensor_pitch</td><td>[in] is the pitch(physical width of tensor in memory). </td></tr>
    <tr><td class="paramname">offset_x</td><td>[in] is the x coordinate of the start point. </td></tr>
    <tr><td class="paramname">offset_y</td><td>[in] is the y coordinate of the start point. </td></tr>
  </table>
  </dd>
</dl>

</div>
</div>
<a id="ga9aae00877c6ebd577ab3afa3717af917" name="ga9aae00877c6ebd577ab3afa3717af917"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ga9aae00877c6ebd577ab3afa3717af917">&#9670;&#160;</a></span>xetla_fill_tdesc() <span class="overload">[2/2]</span></h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;typename Ty &gt; </div>
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="common_2core_2common_8hpp.html#a9ed53999886ec13b86a4fe2e0fc16765">__XETLA_API</a> void gpu::xetla::xetla_fill_tdesc </td>
          <td>(</td>
          <td class="paramtype">xetla_vector_ref&lt; uint32_t, 16 &gt; <a class="el" href="group__xetla__core__base__types.html#ga126a6fcae520c421efd2419512e9bf70">__REF__</a>&#160;</td>
          <td class="paramname"><em>tdesc</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">uint32_t&#160;</td>
          <td class="paramname"><em>base_address</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int&#160;</td>
          <td class="paramname"><em>tensor_width</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int&#160;</td>
          <td class="paramname"><em>tensor_height</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int&#160;</td>
          <td class="paramname"><em>tensor_pitch</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int&#160;</td>
          <td class="paramname"><em>offset_x</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int&#160;</td>
          <td class="paramname"><em>offset_y</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Tensor descriptor construction(local memory version). </p>
<p >Constructs a tensor descriptor based on the given arguments, keep the same format as the global memory version. </p><dl class="tparams"><dt>Template Parameters</dt><dd>
  <table class="tparams">
    <tr><td class="paramname">Ty</td><td>is the data type per element. </td></tr>
  </table>
  </dd>
</dl>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">tdesc</td><td>[in|out] is the reference of tensor descriptor. </td></tr>
    <tr><td class="paramname">base_address</td><td>[in] is the local memory base address of the tensor. </td></tr>
    <tr><td class="paramname">tensor_width</td><td>[in] is the width of the tensor. </td></tr>
    <tr><td class="paramname">tensor_height</td><td>[in] is the height of the tensor. </td></tr>
    <tr><td class="paramname">tensor_pitch</td><td>[in] is the pitch(physical width of tensor in memory). </td></tr>
    <tr><td class="paramname">offset_x</td><td>[in] is the x coordinate of the start point. </td></tr>
    <tr><td class="paramname">offset_y</td><td>[in] is the y coordinate of the start point. </td></tr>
  </table>
  </dd>
</dl>

</div>
</div>
<a id="gab7c1fda0870b32e289606ba2db79bb62" name="gab7c1fda0870b32e289606ba2db79bb62"></a>
<h2 class="memtitle"><span class="permalink"><a href="#gab7c1fda0870b32e289606ba2db79bb62">&#9670;&#160;</a></span>xetla_get_tdesc() <span class="overload">[1/2]</span></h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;typename Ty , uint8_t block_width = 1, uint8_t block_height = 1, uint8_t array_len = 1&gt; </div>
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="common_2core_2common_8hpp.html#a9ed53999886ec13b86a4fe2e0fc16765">__XETLA_API</a> <a class="el" href="group__xetla__util__tensor__load__store.html#ga42f510141eb50c17c2b0d1aa1edaf40d">xetla_tdescriptor</a> gpu::xetla::xetla_get_tdesc </td>
          <td>(</td>
          <td class="paramtype">Ty *&#160;</td>
          <td class="paramname"><em>p</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int&#160;</td>
          <td class="paramname"><em>tensor_width</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int&#160;</td>
          <td class="paramname"><em>tensor_height</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int&#160;</td>
          <td class="paramname"><em>tensor_pitch</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int&#160;</td>
          <td class="paramname"><em>offset_x</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int&#160;</td>
          <td class="paramname"><em>offset_y</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Generate a new tensor descriptor(global memory version). </p>
<p >Generate a tensor descriptor based on the given arguments, check <a href="https://gfxspecs.intel.com/Predator/Home/Index/63986">here</a> for more details. </p><dl class="tparams"><dt>Template Parameters</dt><dd>
  <table class="tparams">
    <tr><td class="paramname">Ty</td><td>is the data type per element. </td></tr>
    <tr><td class="paramname">block_width</td><td>is the width of the block to be loaded. </td></tr>
    <tr><td class="paramname">block_height</td><td>is the height of the block to be loaded. </td></tr>
    <tr><td class="paramname">array_len</td><td>is the array length of the block to be loaded. </td></tr>
  </table>
  </dd>
</dl>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">p</td><td>[in] is the base address pointer of the tensor. </td></tr>
    <tr><td class="paramname">tensor_width</td><td>[in] is the width of the tensor. </td></tr>
    <tr><td class="paramname">tensor_height</td><td>[in] is the height of the tensor. </td></tr>
    <tr><td class="paramname">tensor_pitch</td><td>[in] is the pitch(physical width of tensor in memory). </td></tr>
    <tr><td class="paramname">offset_x</td><td>[in] is the x coordinate of the start point. </td></tr>
    <tr><td class="paramname">offset_y</td><td>[in] is the y coordinate of the start point. </td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>return a new tensor </dd></dl>

</div>
</div>
<a id="ga56fc07f5418c4adffe8739901f236849" name="ga56fc07f5418c4adffe8739901f236849"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ga56fc07f5418c4adffe8739901f236849">&#9670;&#160;</a></span>xetla_get_tdesc() <span class="overload">[2/2]</span></h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;typename Ty &gt; </div>
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="common_2core_2common_8hpp.html#a9ed53999886ec13b86a4fe2e0fc16765">__XETLA_API</a> <a class="el" href="group__xetla__util__tensor__load__store.html#ga42f510141eb50c17c2b0d1aa1edaf40d">xetla_tdescriptor</a> gpu::xetla::xetla_get_tdesc </td>
          <td>(</td>
          <td class="paramtype">uint32_t&#160;</td>
          <td class="paramname"><em>base_address</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int&#160;</td>
          <td class="paramname"><em>tensor_width</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int&#160;</td>
          <td class="paramname"><em>tensor_height</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int&#160;</td>
          <td class="paramname"><em>tensor_pitch</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int&#160;</td>
          <td class="paramname"><em>offset_x</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int&#160;</td>
          <td class="paramname"><em>offset_y</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Generate a new tensor descriptor(local memory version). </p>
<p >Constructs a tensor descriptor based on the given arguments, keep the same format as the global memory version. </p><dl class="tparams"><dt>Template Parameters</dt><dd>
  <table class="tparams">
    <tr><td class="paramname">Ty</td><td>is the data type per element. </td></tr>
  </table>
  </dd>
</dl>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">base_address</td><td>[in] is the local memory base address of the tensor. </td></tr>
    <tr><td class="paramname">tensor_width</td><td>[in] is the width of the tensor. </td></tr>
    <tr><td class="paramname">tensor_height</td><td>[in] is the height of the tensor. </td></tr>
    <tr><td class="paramname">tensor_pitch</td><td>[in] is the pitch(physical width of tensor in memory). </td></tr>
    <tr><td class="paramname">offset_x</td><td>[in] is the x coordinate of the start point. </td></tr>
    <tr><td class="paramname">offset_y</td><td>[in] is the y coordinate of the start point. </td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>return a new tensor descriptor </dd></dl>

</div>
</div>
<a id="ga8bd042e28e68f5e0bed3f378d57d4223" name="ga8bd042e28e68f5e0bed3f378d57d4223"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ga8bd042e28e68f5e0bed3f378d57d4223">&#9670;&#160;</a></span>xetla_tatomic_store_global()</h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;typename Ty , uint32_t N, <a class="el" href="namespacegpu_1_1xetla.html#a23ee6c8b836eb63360633951d75d7e30">cache_hint</a> L1H = cache_hint::none, <a class="el" href="namespacegpu_1_1xetla.html#a23ee6c8b836eb63360633951d75d7e30">cache_hint</a> L3H = cache_hint::none, <a class="el" href="namespacegpu_1_1xetla.html#a98afdf633baaa5ce76b93f0a2ffbba66">atomic_op</a> Op&gt; </div>
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="common_2core_2common_8hpp.html#a9ed53999886ec13b86a4fe2e0fc16765">__XETLA_API</a> void gpu::xetla::xetla_tatomic_store_global </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="group__xetla__core__base__types.html#ga8cf5d016d24c8870706e20c376287e04">xetla_vector</a>&lt; uint64_t, N &gt;&#160;</td>
          <td class="paramname"><em>address</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="group__xetla__core__base__types.html#ga8cf5d016d24c8870706e20c376287e04">xetla_vector</a>&lt; Ty, N &gt;&#160;</td>
          <td class="paramname"><em>data</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="group__xetla__core__base__types.html#gaf7f6ada235a6c3ab30aa12c97f5d7459">xetla_mask</a>&lt; N &gt;&#160;</td>
          <td class="paramname"><em>pred</em> = <code>1</code>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Tensor atomic store API. </p>
<p >Tensor atomic store API is to store a n-d (e.g. n=2) tensor into global. Check <a href="https://gfxspecs.intel.com/Predator/Home/Index/53548">here</a> for more details. </p><dl class="tparams"><dt>Template Parameters</dt><dd>
  <table class="tparams">
    <tr><td class="paramname">Ty</td><td>is the data type per element. </td></tr>
    <tr><td class="paramname">N</td><td>is the number of elements to store. </td></tr>
    <tr><td class="paramname">L1H</td><td>is L1 cache hint. </td></tr>
    <tr><td class="paramname">L3H</td><td>is L3 cache hint. </td></tr>
  </table>
  </dd>
</dl>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">address</td><td>[in] is is the 64bit address for each channel. </td></tr>
    <tr><td class="paramname">data</td><td>[in] is tensor data to store. </td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>none. </dd></dl>
<p >only support 64bit address</p>

</div>
</div>
<a id="gaeecc58189c2cb085251223db2f4737da" name="gaeecc58189c2cb085251223db2f4737da"></a>
<h2 class="memtitle"><span class="permalink"><a href="#gaeecc58189c2cb085251223db2f4737da">&#9670;&#160;</a></span>xetla_tload_global()</h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;typename Ty , uint32_t N, <a class="el" href="namespacegpu_1_1xetla.html#a23ee6c8b836eb63360633951d75d7e30">cache_hint</a> L1H = cache_hint::none, <a class="el" href="namespacegpu_1_1xetla.html#a23ee6c8b836eb63360633951d75d7e30">cache_hint</a> L3H = cache_hint::none, bool transpose = false, bool transform = false&gt; </div>
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="common_2core_2common_8hpp.html#a9ed53999886ec13b86a4fe2e0fc16765">__XETLA_API</a> <a class="el" href="group__xetla__core__base__types.html#ga8cf5d016d24c8870706e20c376287e04">xetla_vector</a>&lt; Ty, N &gt; gpu::xetla::xetla_tload_global </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="group__xetla__util__tensor__load__store.html#ga42f510141eb50c17c2b0d1aa1edaf40d">xetla_tdescriptor</a>&#160;</td>
          <td class="paramname"><em>tdesc</em></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Tensor load API. </p>
<p >This is tensor load API from global to registers. Check <a href="https://gfxspecs.intel.com/Predator/Home/Index/53680">here</a> for more details. </p><dl class="tparams"><dt>Template Parameters</dt><dd>
  <table class="tparams">
    <tr><td class="paramname">Ty</td><td>is the data type per element. </td></tr>
    <tr><td class="paramname">N</td><td>is the total number of elements to load. </td></tr>
    <tr><td class="paramname">L1H</td><td>is L1$ cache hint. </td></tr>
    <tr><td class="paramname">L3H</td><td>is L3$ cache hint. </td></tr>
    <tr><td class="paramname">transpose</td><td>is a flag to indicate whether the data is transposed during load. </td></tr>
    <tr><td class="paramname">transform</td><td>is a flag to indicate whether the data is transformed (data pack inside dword) during load. </td></tr>
  </table>
  </dd>
</dl>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">tdesc</td><td>[in] is tensor descriptor including tensor base address, tensor dimensions, block size, etc. </td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>xetla_vector is data returned from the load. </dd></dl>

</div>
</div>
<a id="ga20cb0deb00796b1e7099082c08c3c68c" name="ga20cb0deb00796b1e7099082c08c3c68c"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ga20cb0deb00796b1e7099082c08c3c68c">&#9670;&#160;</a></span>xetla_tprefetch_global()</h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;typename Ty , <a class="el" href="namespacegpu_1_1xetla.html#a23ee6c8b836eb63360633951d75d7e30">cache_hint</a> L1H = cache_hint::cached, <a class="el" href="namespacegpu_1_1xetla.html#a23ee6c8b836eb63360633951d75d7e30">cache_hint</a> L3H = cache_hint::cached&gt; </div>
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="common_2core_2common_8hpp.html#a9ed53999886ec13b86a4fe2e0fc16765">__XETLA_API</a> void gpu::xetla::xetla_tprefetch_global </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="group__xetla__util__tensor__load__store.html#ga42f510141eb50c17c2b0d1aa1edaf40d">xetla_tdescriptor</a>&#160;</td>
          <td class="paramname"><em>tdesc</em></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Tensor prefetch API. </p>
<p >This is tensor prefetch API from global memory to L1$/L3$. Check <a href="https://gfxspecs.intel.com/Predator/Home/Index/53680">here</a> for more details. </p><dl class="tparams"><dt>Template Parameters</dt><dd>
  <table class="tparams">
    <tr><td class="paramname">Ty</td><td>is the data type per element. </td></tr>
    <tr><td class="paramname">L1H</td><td>is L1$ cache hit. </td></tr>
    <tr><td class="paramname">L3H</td><td>is L3$ cache hit. </td></tr>
  </table>
  </dd>
</dl>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">tdesc</td><td>is tensor descriptor including tensor base address, tensor dimensions, block size, etc. </td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>none. </dd></dl>

</div>
</div>
<a id="gadeb20d3aecaea1a2fa1c64e99f7c0919" name="gadeb20d3aecaea1a2fa1c64e99f7c0919"></a>
<h2 class="memtitle"><span class="permalink"><a href="#gadeb20d3aecaea1a2fa1c64e99f7c0919">&#9670;&#160;</a></span>xetla_tstore_global()</h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;typename Ty , uint32_t N, <a class="el" href="namespacegpu_1_1xetla.html#a23ee6c8b836eb63360633951d75d7e30">cache_hint</a> L1H = cache_hint::none, <a class="el" href="namespacegpu_1_1xetla.html#a23ee6c8b836eb63360633951d75d7e30">cache_hint</a> L3H = cache_hint::none&gt; </div>
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="common_2core_2common_8hpp.html#a9ed53999886ec13b86a4fe2e0fc16765">__XETLA_API</a> void gpu::xetla::xetla_tstore_global </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="group__xetla__util__tensor__load__store.html#ga42f510141eb50c17c2b0d1aa1edaf40d">xetla_tdescriptor</a>&#160;</td>
          <td class="paramname"><em>tdesc</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="group__xetla__core__base__types.html#ga8cf5d016d24c8870706e20c376287e04">xetla_vector</a>&lt; Ty, N &gt;&#160;</td>
          <td class="paramname"><em>data</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Tensor store API. </p>
<p >Tensor store API is to store a n-d (e.g. n=2) tensor into global using tensor descriptor. Check <a href="https://gfxspecs.intel.com/Predator/Home/Index/53530">here</a> for more details. </p><dl class="tparams"><dt>Template Parameters</dt><dd>
  <table class="tparams">
    <tr><td class="paramname">Ty</td><td>is the data type per element. </td></tr>
    <tr><td class="paramname">N</td><td>is the number of elements to store. </td></tr>
    <tr><td class="paramname">L1H</td><td>is L1 cache hint. </td></tr>
    <tr><td class="paramname">L3H</td><td>is L3 cache hint. </td></tr>
  </table>
  </dd>
</dl>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">tdesc</td><td>[in] is tensor descriptor including tensor base address, tensor dimensions, block size, etc. </td></tr>
    <tr><td class="paramname">data</td><td>[in] is tensor data to store. </td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>none. </dd></dl>

</div>
</div>
<a id="gaa762b4f5a5a2b2ee9accee5b0af3e40c" name="gaa762b4f5a5a2b2ee9accee5b0af3e40c"></a>
<h2 class="memtitle"><span class="permalink"><a href="#gaa762b4f5a5a2b2ee9accee5b0af3e40c">&#9670;&#160;</a></span>xetla_update_tdesc_offsetx()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="common_2core_2common_8hpp.html#a9ed53999886ec13b86a4fe2e0fc16765">__XETLA_API</a> void gpu::xetla::xetla_update_tdesc_offsetx </td>
          <td>(</td>
          <td class="paramtype">xetla_vector_ref&lt; uint32_t, 16 &gt; <a class="el" href="group__xetla__core__base__types.html#ga126a6fcae520c421efd2419512e9bf70">__REF__</a>&#160;</td>
          <td class="paramname"><em>tdesc</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int32_t&#160;</td>
          <td class="paramname"><em>doffset_x</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Update the x coordinate in the given tensor descriptor. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">tdesc</td><td>[in|our] is the reference of tensor descriptor. </td></tr>
    <tr><td class="paramname">doffset_x</td><td>[in] is the offset (in number of data elements) in x direction. </td></tr>
  </table>
  </dd>
</dl>

</div>
</div>
<a id="gae779bb3a3626f9c8e36dbc330e269c39" name="gae779bb3a3626f9c8e36dbc330e269c39"></a>
<h2 class="memtitle"><span class="permalink"><a href="#gae779bb3a3626f9c8e36dbc330e269c39">&#9670;&#160;</a></span>xetla_update_tdesc_offsety()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="common_2core_2common_8hpp.html#a9ed53999886ec13b86a4fe2e0fc16765">__XETLA_API</a> void gpu::xetla::xetla_update_tdesc_offsety </td>
          <td>(</td>
          <td class="paramtype">xetla_vector_ref&lt; uint32_t, 16 &gt; <a class="el" href="group__xetla__core__base__types.html#ga126a6fcae520c421efd2419512e9bf70">__REF__</a>&#160;</td>
          <td class="paramname"><em>tdesc</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int32_t&#160;</td>
          <td class="paramname"><em>doffset_y</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Update the y coordinate in the given tensor descriptor. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">tdesc</td><td>[in|our] is the reference of tensor descriptor. </td></tr>
    <tr><td class="paramname">doffset_y</td><td>[in] is the offset (in number of data elements) in y direction. </td></tr>
  </table>
  </dd>
</dl>

</div>
</div>
</div><!-- contents -->
</div><!-- doc-content -->
<!-- start footer part -->
<div id="nav-path" class="navpath"><!-- id is needed for treeview function! -->
  <ul>
    <li class="footer">Generated by <a href="https://www.doxygen.org/index.html"><img class="footer" src="doxygen.svg" width="104" height="31" alt="doxygen"/></a> 1.9.5 </li>
  </ul>
</div>
</body>
</html>
