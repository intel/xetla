<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "https://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" lang="en-US">
<head>
<meta http-equiv="Content-Type" content="text/xhtml;charset=UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=11"/>
<meta name="generator" content="Doxygen 1.9.7"/>
<meta name="viewport" content="width=device-width, initial-scale=1"/>
<title>XeTLA: gpu::xetla::kernel::multi_layer_perceptron_t&lt; gemm_layer1_t_, epilogue_layer1_t_, gemm_layer2_t_, epilogue_layer2_t_, arch_tag_ &gt;::arguments_t Struct Reference</title>
<link href="tabs.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="jquery.js"></script>
<script type="text/javascript" src="dynsections.js"></script>
<link href="navtree.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="resize.js"></script>
<script type="text/javascript" src="navtreedata.js"></script>
<script type="text/javascript" src="navtree.js"></script>
<link href="search/search.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="search/searchdata.js"></script>
<script type="text/javascript" src="search/search.js"></script>
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:d3d9a9a6595521f9666a5e94cc830dab83b65699&amp;dn=expat.txt MIT */
  $(document).ready(function() { init_search(); });
/* @license-end */
</script>
<script type="text/x-mathjax-config">
MathJax.Hub.Config({
  extensions: ["tex2jax.js"],
  jax: ["input/TeX","output/HTML-CSS"],
});
</script>
<script type="text/javascript" async="async" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js"></script>
<link href="doxygen.css" rel="stylesheet" type="text/css" />
</head>
<body>
<div id="top"><!-- do not remove this div, it is closed by doxygen! -->
<div id="titlearea">
<table cellspacing="0" cellpadding="0">
 <tbody>
 <tr id="projectrow">
  <td id="projectalign">
   <div id="projectname">XeTLA<span id="projectnumber">&#160;v0.3.6</span>
   </div>
   <div id="projectbrief">IntelÂ® Xe Templates for Linear Algebra - API Definition Document</div>
  </td>
    <td>        <div id="MSearchBox" class="MSearchBoxInactive">
        <span class="left">
          <span id="MSearchSelect"                onmouseover="return searchBox.OnSearchSelectShow()"                onmouseout="return searchBox.OnSearchSelectHide()">&#160;</span>
          <input type="text" id="MSearchField" value="" placeholder="Search" accesskey="S"
               onfocus="searchBox.OnSearchFieldFocus(true)" 
               onblur="searchBox.OnSearchFieldFocus(false)" 
               onkeyup="searchBox.OnSearchFieldChange(event)"/>
          </span><span class="right">
            <a id="MSearchClose" href="javascript:searchBox.CloseResultsWindow()"><img id="MSearchCloseImg" border="0" src="search/close.svg" alt=""/></a>
          </span>
        </div>
</td>
 </tr>
 </tbody>
</table>
</div>
<!-- end header part -->
<!-- Generated by Doxygen 1.9.7 -->
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:d3d9a9a6595521f9666a5e94cc830dab83b65699&amp;dn=expat.txt MIT */
var searchBox = new SearchBox("searchBox", "search/",'.html');
/* @license-end */
</script>
</div><!-- top -->
<div id="side-nav" class="ui-resizable side-nav-resizable">
  <div id="nav-tree">
    <div id="nav-tree-contents">
      <div id="nav-sync" class="sync"></div>
    </div>
  </div>
  <div id="splitbar" style="-moz-user-select:none;" 
       class="ui-resizable-handle">
  </div>
</div>
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:d3d9a9a6595521f9666a5e94cc830dab83b65699&amp;dn=expat.txt MIT */
$(document).ready(function(){initNavTree('structgpu_1_1xetla_1_1kernel_1_1multi__layer__perceptron__t_1_1arguments__t.html',''); initResizable(); });
/* @license-end */
</script>
<div id="doc-content">
<!-- window showing the filter options -->
<div id="MSearchSelectWindow"
     onmouseover="return searchBox.OnSearchSelectShow()"
     onmouseout="return searchBox.OnSearchSelectHide()"
     onkeydown="return searchBox.OnSearchSelectKey(event)">
</div>

<!-- iframe showing the search results (closed by default) -->
<div id="MSearchResultsWindow">
<div id="MSearchResults">
<div class="SRPage">
<div id="SRIndex">
<div id="SRResults"></div>
<div class="SRStatus" id="Loading">Loading...</div>
<div class="SRStatus" id="Searching">Searching...</div>
<div class="SRStatus" id="NoMatches">No Matches</div>
</div>
</div>
</div>
</div>

<div class="header">
  <div class="summary">
<a href="#pub-methods">Public Member Functions</a> &#124;
<a href="#pub-attribs">Public Attributes</a> &#124;
<a href="#pub-static-attribs">Static Public Attributes</a> &#124;
<a href="structgpu_1_1xetla_1_1kernel_1_1multi__layer__perceptron__t_1_1arguments__t-members.html">List of all members</a>  </div>
  <div class="headertitle"><div class="title">gpu::xetla::kernel::multi_layer_perceptron_t&lt; gemm_layer1_t_, epilogue_layer1_t_, gemm_layer2_t_, epilogue_layer2_t_, arch_tag_ &gt;::arguments_t Struct Reference</div></div>
</div><!--header-->
<div class="contents">

<p><code>#include &lt;<a class="el" href="multi__layer__perceptron_8hpp_source.html">multi_layer_perceptron.hpp</a>&gt;</code></p>
<table class="memberdecls">
<tr class="heading"><td colspan="2"><h2 class="groupheader"><a id="pub-methods" name="pub-methods"></a>
Public Member Functions</h2></td></tr>
<tr class="memitem:a9c071518dfdda52addd7e79d65d9fdc7"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="structgpu_1_1xetla_1_1kernel_1_1multi__layer__perceptron__t_1_1arguments__t.html#a9c071518dfdda52addd7e79d65d9fdc7">arguments_t</a> ()=default</td></tr>
<tr class="memdesc:a9c071518dfdda52addd7e79d65d9fdc7"><td class="mdescLeft">&#160;</td><td class="mdescRight">Constructs arguments with default method.  <br /></td></tr>
<tr class="separator:a9c071518dfdda52addd7e79d65d9fdc7"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aa1dcfc0edb3bd7d1a0a6d53a8ea398c6"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="structgpu_1_1xetla_1_1kernel_1_1multi__layer__perceptron__t_1_1arguments__t.html#aa1dcfc0edb3bd7d1a0a6d53a8ea398c6">arguments_t</a> (uint32_t matrix_m_layer1_, uint32_t matrix_k_layer1_, uint32_t matrix_n_layer1_, uint32_t matrix_m_layer2_, uint32_t matrix_k_layer2_, uint32_t matrix_n_layer2_, matA_base_t matA_base_, uint32_t matA_ld_, matW_base_t matW_base_, uint32_t matW_ld_, matB_base_t matB_base_, uint32_t matB_ld_, matV_base_t matV_base_, uint32_t matV_ld_, matC_base_t matC_base_, uint32_t matC_ld_, epilogue_layer1_args_t epilogue_layer1_args_={}, epilogue_layer2_args_t epilogue_layer2_args_={})</td></tr>
<tr class="memdesc:aa1dcfc0edb3bd7d1a0a6d53a8ea398c6"><td class="mdescLeft">&#160;</td><td class="mdescRight">Constructs arguments with initialization list.  <br /></td></tr>
<tr class="separator:aa1dcfc0edb3bd7d1a0a6d53a8ea398c6"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a323dba496f3d94bd6393803363f5495b"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="structgpu_1_1xetla_1_1kernel_1_1multi__layer__perceptron__t_1_1arguments__t.html#a323dba496f3d94bd6393803363f5495b">arguments_t</a> (const <a class="el" href="structgpu_1_1xetla_1_1kernel_1_1multi__layer__perceptron__t_1_1arguments__t.html">arguments_t</a> &amp;args)</td></tr>
<tr class="separator:a323dba496f3d94bd6393803363f5495b"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a5b8234058a0fc53b828fe8a5b775c745"><td class="memItemLeft" align="right" valign="top"><a class="el" href="structgpu_1_1xetla_1_1kernel_1_1multi__layer__perceptron__t_1_1arguments__t.html">arguments_t</a> &amp;&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="structgpu_1_1xetla_1_1kernel_1_1multi__layer__perceptron__t_1_1arguments__t.html#a5b8234058a0fc53b828fe8a5b775c745">operator=</a> (const <a class="el" href="structgpu_1_1xetla_1_1kernel_1_1multi__layer__perceptron__t_1_1arguments__t.html">arguments_t</a> &amp;args)</td></tr>
<tr class="separator:a5b8234058a0fc53b828fe8a5b775c745"><td class="memSeparator" colspan="2">&#160;</td></tr>
</table><table class="memberdecls">
<tr class="heading"><td colspan="2"><h2 class="groupheader"><a id="pub-attribs" name="pub-attribs"></a>
Public Attributes</h2></td></tr>
<tr class="memitem:ab3c792d427920ed20cb402bc8223ae29"><td class="memItemLeft" align="right" valign="top">uint32_t&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="structgpu_1_1xetla_1_1kernel_1_1multi__layer__perceptron__t_1_1arguments__t.html#ab3c792d427920ed20cb402bc8223ae29">matrix_m_layer1</a></td></tr>
<tr class="memdesc:ab3c792d427920ed20cb402bc8223ae29"><td class="mdescLeft">&#160;</td><td class="mdescRight">Is the size of the m dimension of the matrix multiplication (m x k x n).  <br /></td></tr>
<tr class="separator:ab3c792d427920ed20cb402bc8223ae29"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aead83a750ccc88a178cdc1042e0cfce0"><td class="memItemLeft" align="right" valign="top">uint32_t&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="structgpu_1_1xetla_1_1kernel_1_1multi__layer__perceptron__t_1_1arguments__t.html#aead83a750ccc88a178cdc1042e0cfce0">matrix_k_layer1</a></td></tr>
<tr class="memdesc:aead83a750ccc88a178cdc1042e0cfce0"><td class="mdescLeft">&#160;</td><td class="mdescRight">Is the size of the k dimension of the matrix multiplication (m x k x n).  <br /></td></tr>
<tr class="separator:aead83a750ccc88a178cdc1042e0cfce0"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a335aecaba47cae65a1cd8b31f1661b9e"><td class="memItemLeft" align="right" valign="top">uint32_t&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="structgpu_1_1xetla_1_1kernel_1_1multi__layer__perceptron__t_1_1arguments__t.html#a335aecaba47cae65a1cd8b31f1661b9e">matrix_n_layer1</a></td></tr>
<tr class="memdesc:a335aecaba47cae65a1cd8b31f1661b9e"><td class="mdescLeft">&#160;</td><td class="mdescRight">Is the size of the n dimension of the matrix multiplication (m x k x n).  <br /></td></tr>
<tr class="separator:a335aecaba47cae65a1cd8b31f1661b9e"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aef9efcc59fb1bbe7467b18b9c08e4d33"><td class="memItemLeft" align="right" valign="top">uint32_t&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="structgpu_1_1xetla_1_1kernel_1_1multi__layer__perceptron__t_1_1arguments__t.html#aef9efcc59fb1bbe7467b18b9c08e4d33">matrix_m_layer2</a></td></tr>
<tr class="memdesc:aef9efcc59fb1bbe7467b18b9c08e4d33"><td class="mdescLeft">&#160;</td><td class="mdescRight">Is the size of the m dimension of the matrix multiplication (m x k x n).  <br /></td></tr>
<tr class="separator:aef9efcc59fb1bbe7467b18b9c08e4d33"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a3976a9380912899d97166e975f1bb890"><td class="memItemLeft" align="right" valign="top">uint32_t&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="structgpu_1_1xetla_1_1kernel_1_1multi__layer__perceptron__t_1_1arguments__t.html#a3976a9380912899d97166e975f1bb890">matrix_k_layer2</a></td></tr>
<tr class="memdesc:a3976a9380912899d97166e975f1bb890"><td class="mdescLeft">&#160;</td><td class="mdescRight">Is the size of the k dimension of the matrix multiplication (m x k x n).  <br /></td></tr>
<tr class="separator:a3976a9380912899d97166e975f1bb890"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ac1ac28d34fa31ab762db419d06ab0ae9"><td class="memItemLeft" align="right" valign="top">uint32_t&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="structgpu_1_1xetla_1_1kernel_1_1multi__layer__perceptron__t_1_1arguments__t.html#ac1ac28d34fa31ab762db419d06ab0ae9">matrix_n_layer2</a></td></tr>
<tr class="memdesc:ac1ac28d34fa31ab762db419d06ab0ae9"><td class="mdescLeft">&#160;</td><td class="mdescRight">Is the size of the n dimension of the matrix multiplication (m x k x n).  <br /></td></tr>
<tr class="separator:ac1ac28d34fa31ab762db419d06ab0ae9"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aba9580be6af8992d25ff3437f8843a77"><td class="memItemLeft" align="right" valign="top">uint32_t&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="structgpu_1_1xetla_1_1kernel_1_1multi__layer__perceptron__t_1_1arguments__t.html#aba9580be6af8992d25ff3437f8843a77">matA_ld</a></td></tr>
<tr class="memdesc:aba9580be6af8992d25ff3437f8843a77"><td class="mdescLeft">&#160;</td><td class="mdescRight">Is the leading dimension (pitch) size of the matrix A in memory.  <br /></td></tr>
<tr class="separator:aba9580be6af8992d25ff3437f8843a77"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a45270a4a4503907ba01eddafd9c782cf"><td class="memItemLeft" align="right" valign="top">uint32_t&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="structgpu_1_1xetla_1_1kernel_1_1multi__layer__perceptron__t_1_1arguments__t.html#a45270a4a4503907ba01eddafd9c782cf">matW_ld</a></td></tr>
<tr class="memdesc:a45270a4a4503907ba01eddafd9c782cf"><td class="mdescLeft">&#160;</td><td class="mdescRight">Is the leading dimension (pitch) size of the matrix W in memory.  <br /></td></tr>
<tr class="separator:a45270a4a4503907ba01eddafd9c782cf"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a4a637946c29de864d58c6480f025db5a"><td class="memItemLeft" align="right" valign="top">uint32_t&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="structgpu_1_1xetla_1_1kernel_1_1multi__layer__perceptron__t_1_1arguments__t.html#a4a637946c29de864d58c6480f025db5a">matB_ld</a></td></tr>
<tr class="memdesc:a4a637946c29de864d58c6480f025db5a"><td class="mdescLeft">&#160;</td><td class="mdescRight">Is the leading dimension (pitch) size of the matrix B in memory.  <br /></td></tr>
<tr class="separator:a4a637946c29de864d58c6480f025db5a"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a2366ad40e00748c1b2073188ae99bae2"><td class="memItemLeft" align="right" valign="top">uint32_t&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="structgpu_1_1xetla_1_1kernel_1_1multi__layer__perceptron__t_1_1arguments__t.html#a2366ad40e00748c1b2073188ae99bae2">matV_ld</a></td></tr>
<tr class="memdesc:a2366ad40e00748c1b2073188ae99bae2"><td class="mdescLeft">&#160;</td><td class="mdescRight">Is the leading dimension (pitch) size of the matrix V in memory.  <br /></td></tr>
<tr class="separator:a2366ad40e00748c1b2073188ae99bae2"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ad69534113c5b5152fa8a138747f7d495"><td class="memItemLeft" align="right" valign="top">uint32_t&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="structgpu_1_1xetla_1_1kernel_1_1multi__layer__perceptron__t_1_1arguments__t.html#ad69534113c5b5152fa8a138747f7d495">matC_ld</a></td></tr>
<tr class="memdesc:ad69534113c5b5152fa8a138747f7d495"><td class="mdescLeft">&#160;</td><td class="mdescRight">Is the leading dimension (pitch) size of the matrix C in memory.  <br /></td></tr>
<tr class="separator:ad69534113c5b5152fa8a138747f7d495"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a5fda77606fe58b5d53d550ed34b4a2d4"><td class="memItemLeft" align="right" valign="top">matA_base_t&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="structgpu_1_1xetla_1_1kernel_1_1multi__layer__perceptron__t_1_1arguments__t.html#a5fda77606fe58b5d53d550ed34b4a2d4">matA_base</a></td></tr>
<tr class="memdesc:a5fda77606fe58b5d53d550ed34b4a2d4"><td class="mdescLeft">&#160;</td><td class="mdescRight">Is the base address of matrix A.  <br /></td></tr>
<tr class="separator:a5fda77606fe58b5d53d550ed34b4a2d4"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:af4548433ffc312572582aa9e2c03a951"><td class="memItemLeft" align="right" valign="top">matW_base_t&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="structgpu_1_1xetla_1_1kernel_1_1multi__layer__perceptron__t_1_1arguments__t.html#af4548433ffc312572582aa9e2c03a951">matW_base</a></td></tr>
<tr class="memdesc:af4548433ffc312572582aa9e2c03a951"><td class="mdescLeft">&#160;</td><td class="mdescRight">Is the base address of matrix W.  <br /></td></tr>
<tr class="separator:af4548433ffc312572582aa9e2c03a951"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ad3105ce6a4045eac6e0551109e9cacb5"><td class="memItemLeft" align="right" valign="top">matB_base_t&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="structgpu_1_1xetla_1_1kernel_1_1multi__layer__perceptron__t_1_1arguments__t.html#ad3105ce6a4045eac6e0551109e9cacb5">matB_base</a></td></tr>
<tr class="memdesc:ad3105ce6a4045eac6e0551109e9cacb5"><td class="mdescLeft">&#160;</td><td class="mdescRight">Is the base address of matrix B.  <br /></td></tr>
<tr class="separator:ad3105ce6a4045eac6e0551109e9cacb5"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a2eda487e9bfcdad56512b65457b86e04"><td class="memItemLeft" align="right" valign="top">matV_base_t&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="structgpu_1_1xetla_1_1kernel_1_1multi__layer__perceptron__t_1_1arguments__t.html#a2eda487e9bfcdad56512b65457b86e04">matV_base</a></td></tr>
<tr class="memdesc:a2eda487e9bfcdad56512b65457b86e04"><td class="mdescLeft">&#160;</td><td class="mdescRight">Is the base address of matrix V.  <br /></td></tr>
<tr class="separator:a2eda487e9bfcdad56512b65457b86e04"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a435cad40919fa0fe6754c73bf9a33e97"><td class="memItemLeft" align="right" valign="top">matC_base_t&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="structgpu_1_1xetla_1_1kernel_1_1multi__layer__perceptron__t_1_1arguments__t.html#a435cad40919fa0fe6754c73bf9a33e97">matC_base</a></td></tr>
<tr class="memdesc:a435cad40919fa0fe6754c73bf9a33e97"><td class="mdescLeft">&#160;</td><td class="mdescRight">Is the base address of matrix C.  <br /></td></tr>
<tr class="separator:a435cad40919fa0fe6754c73bf9a33e97"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:af4a6d92bdba7adad25528260c153f7e4"><td class="memItemLeft" align="right" valign="top">epilogue_layer1_args_t&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="structgpu_1_1xetla_1_1kernel_1_1multi__layer__perceptron__t_1_1arguments__t.html#af4a6d92bdba7adad25528260c153f7e4">epilogue_layer1_args</a></td></tr>
<tr class="memdesc:af4a6d92bdba7adad25528260c153f7e4"><td class="mdescLeft">&#160;</td><td class="mdescRight">Is the epilogue arguments of first gemm.  <br /></td></tr>
<tr class="separator:af4a6d92bdba7adad25528260c153f7e4"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a33bf79d6189b6435980c78dae1800e79"><td class="memItemLeft" align="right" valign="top">epilogue_layer2_args_t&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="structgpu_1_1xetla_1_1kernel_1_1multi__layer__perceptron__t_1_1arguments__t.html#a33bf79d6189b6435980c78dae1800e79">epilogue_layer2_args</a></td></tr>
<tr class="memdesc:a33bf79d6189b6435980c78dae1800e79"><td class="mdescLeft">&#160;</td><td class="mdescRight">Is the epilogue arguments of second gemm.  <br /></td></tr>
<tr class="separator:a33bf79d6189b6435980c78dae1800e79"><td class="memSeparator" colspan="2">&#160;</td></tr>
</table><table class="memberdecls">
<tr class="heading"><td colspan="2"><h2 class="groupheader"><a id="pub-static-attribs" name="pub-static-attribs"></a>
Static Public Attributes</h2></td></tr>
<tr class="memitem:af19426b54c8d14d90d51c527c0b12f43"><td class="memItemLeft" align="right" valign="top">static constexpr bool&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="structgpu_1_1xetla_1_1kernel_1_1multi__layer__perceptron__t_1_1arguments__t.html#af19426b54c8d14d90d51c527c0b12f43">host_callable</a> = true</td></tr>
<tr class="memdesc:af19426b54c8d14d90d51c527c0b12f43"><td class="mdescLeft">&#160;</td><td class="mdescRight">Set for device copyable.  <br /></td></tr>
<tr class="separator:af19426b54c8d14d90d51c527c0b12f43"><td class="memSeparator" colspan="2">&#160;</td></tr>
</table>
<h2 class="groupheader">Constructor &amp; Destructor Documentation</h2>
<a id="a9c071518dfdda52addd7e79d65d9fdc7" name="a9c071518dfdda52addd7e79d65d9fdc7"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a9c071518dfdda52addd7e79d65d9fdc7">&#9670;&#160;</a></span>arguments_t() <span class="overload">[1/3]</span></h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;typename gemm_layer1_t_ , typename epilogue_layer1_t_ , typename gemm_layer2_t_ , typename epilogue_layer2_t_ , <a class="el" href="namespacegpu_1_1xetla.html#aa5a2713edb27d6fed88a3c61673556f1">gpu_arch</a> arch_tag_&gt; </div>
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="classgpu_1_1xetla_1_1kernel_1_1multi__layer__perceptron__t.html">gpu::xetla::kernel::multi_layer_perceptron_t</a>&lt; gemm_layer1_t_, epilogue_layer1_t_, gemm_layer2_t_, epilogue_layer2_t_, arch_tag_ &gt;::arguments_t::arguments_t </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">inline</span><span class="mlabel">default</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>Constructs arguments with default method. </p>

</div>
</div>
<a id="aa1dcfc0edb3bd7d1a0a6d53a8ea398c6" name="aa1dcfc0edb3bd7d1a0a6d53a8ea398c6"></a>
<h2 class="memtitle"><span class="permalink"><a href="#aa1dcfc0edb3bd7d1a0a6d53a8ea398c6">&#9670;&#160;</a></span>arguments_t() <span class="overload">[2/3]</span></h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;typename gemm_layer1_t_ , typename epilogue_layer1_t_ , typename gemm_layer2_t_ , typename epilogue_layer2_t_ , <a class="el" href="namespacegpu_1_1xetla.html#aa5a2713edb27d6fed88a3c61673556f1">gpu_arch</a> arch_tag_&gt; </div>
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="classgpu_1_1xetla_1_1kernel_1_1multi__layer__perceptron__t.html">gpu::xetla::kernel::multi_layer_perceptron_t</a>&lt; gemm_layer1_t_, epilogue_layer1_t_, gemm_layer2_t_, epilogue_layer2_t_, arch_tag_ &gt;::arguments_t::arguments_t </td>
          <td>(</td>
          <td class="paramtype">uint32_t&#160;</td>
          <td class="paramname"><em>matrix_m_layer1_</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">uint32_t&#160;</td>
          <td class="paramname"><em>matrix_k_layer1_</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">uint32_t&#160;</td>
          <td class="paramname"><em>matrix_n_layer1_</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">uint32_t&#160;</td>
          <td class="paramname"><em>matrix_m_layer2_</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">uint32_t&#160;</td>
          <td class="paramname"><em>matrix_k_layer2_</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">uint32_t&#160;</td>
          <td class="paramname"><em>matrix_n_layer2_</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">matA_base_t&#160;</td>
          <td class="paramname"><em>matA_base_</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">uint32_t&#160;</td>
          <td class="paramname"><em>matA_ld_</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">matW_base_t&#160;</td>
          <td class="paramname"><em>matW_base_</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">uint32_t&#160;</td>
          <td class="paramname"><em>matW_ld_</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">matB_base_t&#160;</td>
          <td class="paramname"><em>matB_base_</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">uint32_t&#160;</td>
          <td class="paramname"><em>matB_ld_</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">matV_base_t&#160;</td>
          <td class="paramname"><em>matV_base_</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">uint32_t&#160;</td>
          <td class="paramname"><em>matV_ld_</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">matC_base_t&#160;</td>
          <td class="paramname"><em>matC_base_</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">uint32_t&#160;</td>
          <td class="paramname"><em>matC_ld_</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">epilogue_layer1_args_t&#160;</td>
          <td class="paramname"><em>epilogue_layer1_args_</em> = <code>{}</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">epilogue_layer2_args_t&#160;</td>
          <td class="paramname"><em>epilogue_layer2_args_</em> = <code>{}</code>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">inline</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>Constructs arguments with initialization list. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">matrix_m_layer1_</td><td>Is the size of the m dimension of the matrix multiplication (m x k x n). </td></tr>
    <tr><td class="paramname">matrix_k_layer1_</td><td>Is the size of the k dimension of the matrix multiplication (m x k x n). </td></tr>
    <tr><td class="paramname">matrix_n_layer1_</td><td>Is the size of the n dimension of the matrix multiplication (m x k x n). </td></tr>
    <tr><td class="paramname">matrix_m_layer2_</td><td>Is the size of the m dimension of the matrix multiplication (m x k x n). </td></tr>
    <tr><td class="paramname">matrix_k_layer2_</td><td>Is the size of the k dimension of the matrix multiplication (m x k x n). </td></tr>
    <tr><td class="paramname">matrix_n_layer2_</td><td>Is the size of the n dimension of the matrix multiplication (m x k x n). </td></tr>
    <tr><td class="paramname">matA_base_</td><td>Is the base address of matrix A. </td></tr>
    <tr><td class="paramname">matA_ld_</td><td>Is the leading dimension (pitch) size of the matrix A in memory. </td></tr>
    <tr><td class="paramname">matW_base_</td><td>Is the base address of matrix W. </td></tr>
    <tr><td class="paramname">matW_ld_</td><td>Is the leading dimension (pitch) size of the matrix W in memory. </td></tr>
    <tr><td class="paramname">matB_base_</td><td>Is the base address of matrix B. </td></tr>
    <tr><td class="paramname">matB_ld_</td><td>Is the leading dimension (pitch) size of the matrix B in memory. </td></tr>
    <tr><td class="paramname">matV_base_</td><td>Is the base address of matrix V. </td></tr>
    <tr><td class="paramname">matV_ld_</td><td>Is the leading dimension (pitch) size of the matrix V in memory. </td></tr>
    <tr><td class="paramname">matC_base_</td><td>Is the base address of matrix C. </td></tr>
    <tr><td class="paramname">matC_ld_</td><td>Is the leading dimension (pitch) size of the matrix C in memory. </td></tr>
    <tr><td class="paramname">epilogue_layer1_args_</td><td>Is the epilogue arguments of first gemm. </td></tr>
    <tr><td class="paramname">epilogue_layer2_args_</td><td>Is the epilogue arguments of second gemm. </td></tr>
  </table>
  </dd>
</dl>

</div>
</div>
<a id="a323dba496f3d94bd6393803363f5495b" name="a323dba496f3d94bd6393803363f5495b"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a323dba496f3d94bd6393803363f5495b">&#9670;&#160;</a></span>arguments_t() <span class="overload">[3/3]</span></h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;typename gemm_layer1_t_ , typename epilogue_layer1_t_ , typename gemm_layer2_t_ , typename epilogue_layer2_t_ , <a class="el" href="namespacegpu_1_1xetla.html#aa5a2713edb27d6fed88a3c61673556f1">gpu_arch</a> arch_tag_&gt; </div>
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="classgpu_1_1xetla_1_1kernel_1_1multi__layer__perceptron__t.html">gpu::xetla::kernel::multi_layer_perceptron_t</a>&lt; gemm_layer1_t_, epilogue_layer1_t_, gemm_layer2_t_, epilogue_layer2_t_, arch_tag_ &gt;::arguments_t::arguments_t </td>
          <td>(</td>
          <td class="paramtype">const <a class="el" href="structgpu_1_1xetla_1_1kernel_1_1multi__layer__perceptron__t_1_1arguments__t.html">arguments_t</a> &amp;&#160;</td>
          <td class="paramname"><em>args</em></td><td>)</td>
          <td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">inline</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

</div>
</div>
<h2 class="groupheader">Member Function Documentation</h2>
<a id="a5b8234058a0fc53b828fe8a5b775c745" name="a5b8234058a0fc53b828fe8a5b775c745"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a5b8234058a0fc53b828fe8a5b775c745">&#9670;&#160;</a></span>operator=()</h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;typename gemm_layer1_t_ , typename epilogue_layer1_t_ , typename gemm_layer2_t_ , typename epilogue_layer2_t_ , <a class="el" href="namespacegpu_1_1xetla.html#aa5a2713edb27d6fed88a3c61673556f1">gpu_arch</a> arch_tag_&gt; </div>
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="structgpu_1_1xetla_1_1kernel_1_1multi__layer__perceptron__t_1_1arguments__t.html">arguments_t</a> &amp; <a class="el" href="classgpu_1_1xetla_1_1kernel_1_1multi__layer__perceptron__t.html">gpu::xetla::kernel::multi_layer_perceptron_t</a>&lt; gemm_layer1_t_, epilogue_layer1_t_, gemm_layer2_t_, epilogue_layer2_t_, arch_tag_ &gt;::arguments_t::operator= </td>
          <td>(</td>
          <td class="paramtype">const <a class="el" href="structgpu_1_1xetla_1_1kernel_1_1multi__layer__perceptron__t_1_1arguments__t.html">arguments_t</a> &amp;&#160;</td>
          <td class="paramname"><em>args</em></td><td>)</td>
          <td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">inline</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

</div>
</div>
<h2 class="groupheader">Member Data Documentation</h2>
<a id="af4a6d92bdba7adad25528260c153f7e4" name="af4a6d92bdba7adad25528260c153f7e4"></a>
<h2 class="memtitle"><span class="permalink"><a href="#af4a6d92bdba7adad25528260c153f7e4">&#9670;&#160;</a></span>epilogue_layer1_args</h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;typename gemm_layer1_t_ , typename epilogue_layer1_t_ , typename gemm_layer2_t_ , typename epilogue_layer2_t_ , <a class="el" href="namespacegpu_1_1xetla.html#aa5a2713edb27d6fed88a3c61673556f1">gpu_arch</a> arch_tag_&gt; </div>
      <table class="memname">
        <tr>
          <td class="memname">epilogue_layer1_args_t <a class="el" href="classgpu_1_1xetla_1_1kernel_1_1multi__layer__perceptron__t.html">gpu::xetla::kernel::multi_layer_perceptron_t</a>&lt; gemm_layer1_t_, epilogue_layer1_t_, gemm_layer2_t_, epilogue_layer2_t_, arch_tag_ &gt;::arguments_t::epilogue_layer1_args</td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Is the epilogue arguments of first gemm. </p>

</div>
</div>
<a id="a33bf79d6189b6435980c78dae1800e79" name="a33bf79d6189b6435980c78dae1800e79"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a33bf79d6189b6435980c78dae1800e79">&#9670;&#160;</a></span>epilogue_layer2_args</h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;typename gemm_layer1_t_ , typename epilogue_layer1_t_ , typename gemm_layer2_t_ , typename epilogue_layer2_t_ , <a class="el" href="namespacegpu_1_1xetla.html#aa5a2713edb27d6fed88a3c61673556f1">gpu_arch</a> arch_tag_&gt; </div>
      <table class="memname">
        <tr>
          <td class="memname">epilogue_layer2_args_t <a class="el" href="classgpu_1_1xetla_1_1kernel_1_1multi__layer__perceptron__t.html">gpu::xetla::kernel::multi_layer_perceptron_t</a>&lt; gemm_layer1_t_, epilogue_layer1_t_, gemm_layer2_t_, epilogue_layer2_t_, arch_tag_ &gt;::arguments_t::epilogue_layer2_args</td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Is the epilogue arguments of second gemm. </p>

</div>
</div>
<a id="af19426b54c8d14d90d51c527c0b12f43" name="af19426b54c8d14d90d51c527c0b12f43"></a>
<h2 class="memtitle"><span class="permalink"><a href="#af19426b54c8d14d90d51c527c0b12f43">&#9670;&#160;</a></span>host_callable</h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;typename gemm_layer1_t_ , typename epilogue_layer1_t_ , typename gemm_layer2_t_ , typename epilogue_layer2_t_ , <a class="el" href="namespacegpu_1_1xetla.html#aa5a2713edb27d6fed88a3c61673556f1">gpu_arch</a> arch_tag_&gt; </div>
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">constexpr bool <a class="el" href="classgpu_1_1xetla_1_1kernel_1_1multi__layer__perceptron__t.html">gpu::xetla::kernel::multi_layer_perceptron_t</a>&lt; gemm_layer1_t_, epilogue_layer1_t_, gemm_layer2_t_, epilogue_layer2_t_, arch_tag_ &gt;::arguments_t::host_callable = true</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">static</span><span class="mlabel">constexpr</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>Set for device copyable. </p>

</div>
</div>
<a id="a5fda77606fe58b5d53d550ed34b4a2d4" name="a5fda77606fe58b5d53d550ed34b4a2d4"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a5fda77606fe58b5d53d550ed34b4a2d4">&#9670;&#160;</a></span>matA_base</h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;typename gemm_layer1_t_ , typename epilogue_layer1_t_ , typename gemm_layer2_t_ , typename epilogue_layer2_t_ , <a class="el" href="namespacegpu_1_1xetla.html#aa5a2713edb27d6fed88a3c61673556f1">gpu_arch</a> arch_tag_&gt; </div>
      <table class="memname">
        <tr>
          <td class="memname">matA_base_t <a class="el" href="classgpu_1_1xetla_1_1kernel_1_1multi__layer__perceptron__t.html">gpu::xetla::kernel::multi_layer_perceptron_t</a>&lt; gemm_layer1_t_, epilogue_layer1_t_, gemm_layer2_t_, epilogue_layer2_t_, arch_tag_ &gt;::arguments_t::matA_base</td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Is the base address of matrix A. </p>

</div>
</div>
<a id="aba9580be6af8992d25ff3437f8843a77" name="aba9580be6af8992d25ff3437f8843a77"></a>
<h2 class="memtitle"><span class="permalink"><a href="#aba9580be6af8992d25ff3437f8843a77">&#9670;&#160;</a></span>matA_ld</h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;typename gemm_layer1_t_ , typename epilogue_layer1_t_ , typename gemm_layer2_t_ , typename epilogue_layer2_t_ , <a class="el" href="namespacegpu_1_1xetla.html#aa5a2713edb27d6fed88a3c61673556f1">gpu_arch</a> arch_tag_&gt; </div>
      <table class="memname">
        <tr>
          <td class="memname">uint32_t <a class="el" href="classgpu_1_1xetla_1_1kernel_1_1multi__layer__perceptron__t.html">gpu::xetla::kernel::multi_layer_perceptron_t</a>&lt; gemm_layer1_t_, epilogue_layer1_t_, gemm_layer2_t_, epilogue_layer2_t_, arch_tag_ &gt;::arguments_t::matA_ld</td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Is the leading dimension (pitch) size of the matrix A in memory. </p>

</div>
</div>
<a id="ad3105ce6a4045eac6e0551109e9cacb5" name="ad3105ce6a4045eac6e0551109e9cacb5"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ad3105ce6a4045eac6e0551109e9cacb5">&#9670;&#160;</a></span>matB_base</h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;typename gemm_layer1_t_ , typename epilogue_layer1_t_ , typename gemm_layer2_t_ , typename epilogue_layer2_t_ , <a class="el" href="namespacegpu_1_1xetla.html#aa5a2713edb27d6fed88a3c61673556f1">gpu_arch</a> arch_tag_&gt; </div>
      <table class="memname">
        <tr>
          <td class="memname">matB_base_t <a class="el" href="classgpu_1_1xetla_1_1kernel_1_1multi__layer__perceptron__t.html">gpu::xetla::kernel::multi_layer_perceptron_t</a>&lt; gemm_layer1_t_, epilogue_layer1_t_, gemm_layer2_t_, epilogue_layer2_t_, arch_tag_ &gt;::arguments_t::matB_base</td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Is the base address of matrix B. </p>

</div>
</div>
<a id="a4a637946c29de864d58c6480f025db5a" name="a4a637946c29de864d58c6480f025db5a"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a4a637946c29de864d58c6480f025db5a">&#9670;&#160;</a></span>matB_ld</h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;typename gemm_layer1_t_ , typename epilogue_layer1_t_ , typename gemm_layer2_t_ , typename epilogue_layer2_t_ , <a class="el" href="namespacegpu_1_1xetla.html#aa5a2713edb27d6fed88a3c61673556f1">gpu_arch</a> arch_tag_&gt; </div>
      <table class="memname">
        <tr>
          <td class="memname">uint32_t <a class="el" href="classgpu_1_1xetla_1_1kernel_1_1multi__layer__perceptron__t.html">gpu::xetla::kernel::multi_layer_perceptron_t</a>&lt; gemm_layer1_t_, epilogue_layer1_t_, gemm_layer2_t_, epilogue_layer2_t_, arch_tag_ &gt;::arguments_t::matB_ld</td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Is the leading dimension (pitch) size of the matrix B in memory. </p>

</div>
</div>
<a id="a435cad40919fa0fe6754c73bf9a33e97" name="a435cad40919fa0fe6754c73bf9a33e97"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a435cad40919fa0fe6754c73bf9a33e97">&#9670;&#160;</a></span>matC_base</h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;typename gemm_layer1_t_ , typename epilogue_layer1_t_ , typename gemm_layer2_t_ , typename epilogue_layer2_t_ , <a class="el" href="namespacegpu_1_1xetla.html#aa5a2713edb27d6fed88a3c61673556f1">gpu_arch</a> arch_tag_&gt; </div>
      <table class="memname">
        <tr>
          <td class="memname">matC_base_t <a class="el" href="classgpu_1_1xetla_1_1kernel_1_1multi__layer__perceptron__t.html">gpu::xetla::kernel::multi_layer_perceptron_t</a>&lt; gemm_layer1_t_, epilogue_layer1_t_, gemm_layer2_t_, epilogue_layer2_t_, arch_tag_ &gt;::arguments_t::matC_base</td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Is the base address of matrix C. </p>

</div>
</div>
<a id="ad69534113c5b5152fa8a138747f7d495" name="ad69534113c5b5152fa8a138747f7d495"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ad69534113c5b5152fa8a138747f7d495">&#9670;&#160;</a></span>matC_ld</h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;typename gemm_layer1_t_ , typename epilogue_layer1_t_ , typename gemm_layer2_t_ , typename epilogue_layer2_t_ , <a class="el" href="namespacegpu_1_1xetla.html#aa5a2713edb27d6fed88a3c61673556f1">gpu_arch</a> arch_tag_&gt; </div>
      <table class="memname">
        <tr>
          <td class="memname">uint32_t <a class="el" href="classgpu_1_1xetla_1_1kernel_1_1multi__layer__perceptron__t.html">gpu::xetla::kernel::multi_layer_perceptron_t</a>&lt; gemm_layer1_t_, epilogue_layer1_t_, gemm_layer2_t_, epilogue_layer2_t_, arch_tag_ &gt;::arguments_t::matC_ld</td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Is the leading dimension (pitch) size of the matrix C in memory. </p>

</div>
</div>
<a id="aead83a750ccc88a178cdc1042e0cfce0" name="aead83a750ccc88a178cdc1042e0cfce0"></a>
<h2 class="memtitle"><span class="permalink"><a href="#aead83a750ccc88a178cdc1042e0cfce0">&#9670;&#160;</a></span>matrix_k_layer1</h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;typename gemm_layer1_t_ , typename epilogue_layer1_t_ , typename gemm_layer2_t_ , typename epilogue_layer2_t_ , <a class="el" href="namespacegpu_1_1xetla.html#aa5a2713edb27d6fed88a3c61673556f1">gpu_arch</a> arch_tag_&gt; </div>
      <table class="memname">
        <tr>
          <td class="memname">uint32_t <a class="el" href="classgpu_1_1xetla_1_1kernel_1_1multi__layer__perceptron__t.html">gpu::xetla::kernel::multi_layer_perceptron_t</a>&lt; gemm_layer1_t_, epilogue_layer1_t_, gemm_layer2_t_, epilogue_layer2_t_, arch_tag_ &gt;::arguments_t::matrix_k_layer1</td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Is the size of the k dimension of the matrix multiplication (m x k x n). </p>

</div>
</div>
<a id="a3976a9380912899d97166e975f1bb890" name="a3976a9380912899d97166e975f1bb890"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a3976a9380912899d97166e975f1bb890">&#9670;&#160;</a></span>matrix_k_layer2</h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;typename gemm_layer1_t_ , typename epilogue_layer1_t_ , typename gemm_layer2_t_ , typename epilogue_layer2_t_ , <a class="el" href="namespacegpu_1_1xetla.html#aa5a2713edb27d6fed88a3c61673556f1">gpu_arch</a> arch_tag_&gt; </div>
      <table class="memname">
        <tr>
          <td class="memname">uint32_t <a class="el" href="classgpu_1_1xetla_1_1kernel_1_1multi__layer__perceptron__t.html">gpu::xetla::kernel::multi_layer_perceptron_t</a>&lt; gemm_layer1_t_, epilogue_layer1_t_, gemm_layer2_t_, epilogue_layer2_t_, arch_tag_ &gt;::arguments_t::matrix_k_layer2</td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Is the size of the k dimension of the matrix multiplication (m x k x n). </p>

</div>
</div>
<a id="ab3c792d427920ed20cb402bc8223ae29" name="ab3c792d427920ed20cb402bc8223ae29"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ab3c792d427920ed20cb402bc8223ae29">&#9670;&#160;</a></span>matrix_m_layer1</h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;typename gemm_layer1_t_ , typename epilogue_layer1_t_ , typename gemm_layer2_t_ , typename epilogue_layer2_t_ , <a class="el" href="namespacegpu_1_1xetla.html#aa5a2713edb27d6fed88a3c61673556f1">gpu_arch</a> arch_tag_&gt; </div>
      <table class="memname">
        <tr>
          <td class="memname">uint32_t <a class="el" href="classgpu_1_1xetla_1_1kernel_1_1multi__layer__perceptron__t.html">gpu::xetla::kernel::multi_layer_perceptron_t</a>&lt; gemm_layer1_t_, epilogue_layer1_t_, gemm_layer2_t_, epilogue_layer2_t_, arch_tag_ &gt;::arguments_t::matrix_m_layer1</td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Is the size of the m dimension of the matrix multiplication (m x k x n). </p>

</div>
</div>
<a id="aef9efcc59fb1bbe7467b18b9c08e4d33" name="aef9efcc59fb1bbe7467b18b9c08e4d33"></a>
<h2 class="memtitle"><span class="permalink"><a href="#aef9efcc59fb1bbe7467b18b9c08e4d33">&#9670;&#160;</a></span>matrix_m_layer2</h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;typename gemm_layer1_t_ , typename epilogue_layer1_t_ , typename gemm_layer2_t_ , typename epilogue_layer2_t_ , <a class="el" href="namespacegpu_1_1xetla.html#aa5a2713edb27d6fed88a3c61673556f1">gpu_arch</a> arch_tag_&gt; </div>
      <table class="memname">
        <tr>
          <td class="memname">uint32_t <a class="el" href="classgpu_1_1xetla_1_1kernel_1_1multi__layer__perceptron__t.html">gpu::xetla::kernel::multi_layer_perceptron_t</a>&lt; gemm_layer1_t_, epilogue_layer1_t_, gemm_layer2_t_, epilogue_layer2_t_, arch_tag_ &gt;::arguments_t::matrix_m_layer2</td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Is the size of the m dimension of the matrix multiplication (m x k x n). </p>

</div>
</div>
<a id="a335aecaba47cae65a1cd8b31f1661b9e" name="a335aecaba47cae65a1cd8b31f1661b9e"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a335aecaba47cae65a1cd8b31f1661b9e">&#9670;&#160;</a></span>matrix_n_layer1</h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;typename gemm_layer1_t_ , typename epilogue_layer1_t_ , typename gemm_layer2_t_ , typename epilogue_layer2_t_ , <a class="el" href="namespacegpu_1_1xetla.html#aa5a2713edb27d6fed88a3c61673556f1">gpu_arch</a> arch_tag_&gt; </div>
      <table class="memname">
        <tr>
          <td class="memname">uint32_t <a class="el" href="classgpu_1_1xetla_1_1kernel_1_1multi__layer__perceptron__t.html">gpu::xetla::kernel::multi_layer_perceptron_t</a>&lt; gemm_layer1_t_, epilogue_layer1_t_, gemm_layer2_t_, epilogue_layer2_t_, arch_tag_ &gt;::arguments_t::matrix_n_layer1</td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Is the size of the n dimension of the matrix multiplication (m x k x n). </p>

</div>
</div>
<a id="ac1ac28d34fa31ab762db419d06ab0ae9" name="ac1ac28d34fa31ab762db419d06ab0ae9"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ac1ac28d34fa31ab762db419d06ab0ae9">&#9670;&#160;</a></span>matrix_n_layer2</h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;typename gemm_layer1_t_ , typename epilogue_layer1_t_ , typename gemm_layer2_t_ , typename epilogue_layer2_t_ , <a class="el" href="namespacegpu_1_1xetla.html#aa5a2713edb27d6fed88a3c61673556f1">gpu_arch</a> arch_tag_&gt; </div>
      <table class="memname">
        <tr>
          <td class="memname">uint32_t <a class="el" href="classgpu_1_1xetla_1_1kernel_1_1multi__layer__perceptron__t.html">gpu::xetla::kernel::multi_layer_perceptron_t</a>&lt; gemm_layer1_t_, epilogue_layer1_t_, gemm_layer2_t_, epilogue_layer2_t_, arch_tag_ &gt;::arguments_t::matrix_n_layer2</td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Is the size of the n dimension of the matrix multiplication (m x k x n). </p>

</div>
</div>
<a id="a2eda487e9bfcdad56512b65457b86e04" name="a2eda487e9bfcdad56512b65457b86e04"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a2eda487e9bfcdad56512b65457b86e04">&#9670;&#160;</a></span>matV_base</h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;typename gemm_layer1_t_ , typename epilogue_layer1_t_ , typename gemm_layer2_t_ , typename epilogue_layer2_t_ , <a class="el" href="namespacegpu_1_1xetla.html#aa5a2713edb27d6fed88a3c61673556f1">gpu_arch</a> arch_tag_&gt; </div>
      <table class="memname">
        <tr>
          <td class="memname">matV_base_t <a class="el" href="classgpu_1_1xetla_1_1kernel_1_1multi__layer__perceptron__t.html">gpu::xetla::kernel::multi_layer_perceptron_t</a>&lt; gemm_layer1_t_, epilogue_layer1_t_, gemm_layer2_t_, epilogue_layer2_t_, arch_tag_ &gt;::arguments_t::matV_base</td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Is the base address of matrix V. </p>

</div>
</div>
<a id="a2366ad40e00748c1b2073188ae99bae2" name="a2366ad40e00748c1b2073188ae99bae2"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a2366ad40e00748c1b2073188ae99bae2">&#9670;&#160;</a></span>matV_ld</h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;typename gemm_layer1_t_ , typename epilogue_layer1_t_ , typename gemm_layer2_t_ , typename epilogue_layer2_t_ , <a class="el" href="namespacegpu_1_1xetla.html#aa5a2713edb27d6fed88a3c61673556f1">gpu_arch</a> arch_tag_&gt; </div>
      <table class="memname">
        <tr>
          <td class="memname">uint32_t <a class="el" href="classgpu_1_1xetla_1_1kernel_1_1multi__layer__perceptron__t.html">gpu::xetla::kernel::multi_layer_perceptron_t</a>&lt; gemm_layer1_t_, epilogue_layer1_t_, gemm_layer2_t_, epilogue_layer2_t_, arch_tag_ &gt;::arguments_t::matV_ld</td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Is the leading dimension (pitch) size of the matrix V in memory. </p>

</div>
</div>
<a id="af4548433ffc312572582aa9e2c03a951" name="af4548433ffc312572582aa9e2c03a951"></a>
<h2 class="memtitle"><span class="permalink"><a href="#af4548433ffc312572582aa9e2c03a951">&#9670;&#160;</a></span>matW_base</h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;typename gemm_layer1_t_ , typename epilogue_layer1_t_ , typename gemm_layer2_t_ , typename epilogue_layer2_t_ , <a class="el" href="namespacegpu_1_1xetla.html#aa5a2713edb27d6fed88a3c61673556f1">gpu_arch</a> arch_tag_&gt; </div>
      <table class="memname">
        <tr>
          <td class="memname">matW_base_t <a class="el" href="classgpu_1_1xetla_1_1kernel_1_1multi__layer__perceptron__t.html">gpu::xetla::kernel::multi_layer_perceptron_t</a>&lt; gemm_layer1_t_, epilogue_layer1_t_, gemm_layer2_t_, epilogue_layer2_t_, arch_tag_ &gt;::arguments_t::matW_base</td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Is the base address of matrix W. </p>

</div>
</div>
<a id="a45270a4a4503907ba01eddafd9c782cf" name="a45270a4a4503907ba01eddafd9c782cf"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a45270a4a4503907ba01eddafd9c782cf">&#9670;&#160;</a></span>matW_ld</h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;typename gemm_layer1_t_ , typename epilogue_layer1_t_ , typename gemm_layer2_t_ , typename epilogue_layer2_t_ , <a class="el" href="namespacegpu_1_1xetla.html#aa5a2713edb27d6fed88a3c61673556f1">gpu_arch</a> arch_tag_&gt; </div>
      <table class="memname">
        <tr>
          <td class="memname">uint32_t <a class="el" href="classgpu_1_1xetla_1_1kernel_1_1multi__layer__perceptron__t.html">gpu::xetla::kernel::multi_layer_perceptron_t</a>&lt; gemm_layer1_t_, epilogue_layer1_t_, gemm_layer2_t_, epilogue_layer2_t_, arch_tag_ &gt;::arguments_t::matW_ld</td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Is the leading dimension (pitch) size of the matrix W in memory. </p>

</div>
</div>
</div><!-- contents -->
</div><!-- doc-content -->
<!-- start footer part -->
<div id="nav-path" class="navpath"><!-- id is needed for treeview function! -->
  <ul>
    <li class="navelem"><a class="el" href="namespacegpu.html">gpu</a></li><li class="navelem"><a class="el" href="namespacegpu_1_1xetla.html">xetla</a></li><li class="navelem"><a class="el" href="namespacegpu_1_1xetla_1_1kernel.html">kernel</a></li><li class="navelem"><a class="el" href="classgpu_1_1xetla_1_1kernel_1_1multi__layer__perceptron__t.html">multi_layer_perceptron_t</a></li><li class="navelem"><a class="el" href="structgpu_1_1xetla_1_1kernel_1_1multi__layer__perceptron__t_1_1arguments__t.html">arguments_t</a></li>
    <li class="footer">Generated by <a href="https://www.doxygen.org/index.html"><img class="footer" src="doxygen.svg" width="104" height="31" alt="doxygen"/></a> 1.9.7 </li>
  </ul>
</div>
</body>
</html>
